{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "File for Cleaning Taxi Data of the Yellow Taxis.\n",
    "Begin by loading 1 parquet file as pandas dataframe.\n",
    "Look at the dataframe, as a csv and through python.\n",
    "Implement Crisp-DM data cleaning methodology -> Data Quality Report, Data Quality Plan\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TLC = Taxi and Limousine Commission\n",
    "\n",
    "- Yellow = hail or prearrange\n",
    "\n",
    "- Green = Not certain Manhattan Areas (below 110th St. on the West Side, and below 96th St. on the East Side, or at either LaGuardia or JFK airports)\n",
    "\n",
    "- FHV (For Hire Vehicles) = Prearranged, Limousines, Black Cars, Livery (Regular), FHVHV\n",
    "\n",
    "- **FHVHV**/ HVFHV/ HVFHS (For Hire Vehicle High Volume/ High Volume FHV/ High Volume For Hire Service) = \"FHV Bases/ Businesses that dispatch more than 10,000 trips per day\" = Lyft/ Uber/ Juno/ Via\n",
    "\n",
    "- See also:\n",
    "    https://www.nyc.gov/site/tlc/passengers/your-ride.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: DatetimeIndex(['2021-01-31', '2021-02-28', '2021-03-31', '2021-04-30',\n",
      "               '2021-05-31', '2021-06-30', '2021-07-31', '2021-08-31',\n",
      "               '2021-09-30', '2021-10-31', '2021-11-30', '2021-12-31',\n",
      "               '2022-01-31', '2022-02-28', '2022-03-31', '2022-04-30',\n",
      "               '2022-05-31', '2022-06-30', '2022-07-31', '2022-08-31',\n",
      "               '2022-09-30', '2022-10-31', '2022-11-30', '2022-12-31',\n",
      "               '2023-01-31', '2023-02-28', '2023-03-31', '2023-04-30',\n",
      "               '2023-05-31', '2023-06-30', '2023-07-31', '2023-08-31',\n",
      "               '2023-09-30', '2023-10-31', '2023-11-30', '2023-12-31',\n",
      "               '2024-01-31', '2024-02-29', '2024-03-31'],\n",
      "              dtype='datetime64[ns]', freq='ME')\n"
     ]
    }
   ],
   "source": [
    "date_range = pd.date_range(start='2021-01', end='2024-04', freq='ME')\n",
    "print(\"Date range:\", date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(\"Current Working Directory:\", cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\n",
      "Files in directory c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets: ['fhvhv_2021_01.parquet', 'fhvhv_2021_02.parquet', 'fhvhv_2021_03.parquet', 'fhvhv_2021_04.parquet', 'fhvhv_2021_05.parquet', 'fhvhv_2021_06.parquet', 'fhvhv_2021_07.parquet', 'fhvhv_2021_08.parquet', 'fhvhv_2021_09.parquet', 'fhvhv_2021_10.parquet', 'fhvhv_2021_11.parquet', 'fhvhv_2021_12.parquet', 'fhvhv_2022_01.parquet', 'fhvhv_2022_02.parquet', 'fhvhv_2022_03.parquet', 'fhvhv_2022_04.parquet', 'fhvhv_2022_05.parquet', 'fhvhv_2022_06.parquet', 'fhvhv_2022_07.parquet', 'fhvhv_2022_08.parquet', 'fhvhv_2022_09.parquet', 'fhvhv_2022_10.parquet', 'fhvhv_2022_11.parquet', 'fhvhv_2022_12.parquet', 'fhvhv_2023_01.parquet', 'fhvhv_2023_02.parquet', 'fhvhv_2023_03.parquet', 'fhvhv_2023_04.parquet', 'fhvhv_2023_05.parquet', 'fhvhv_2023_06.parquet', 'fhvhv_2023_07.parquet', 'fhvhv_2023_08.parquet', 'fhvhv_2023_09.parquet', 'fhvhv_2023_10.parquet', 'fhvhv_2023_11.parquet', 'fhvhv_2023_12.parquet', 'fhvhv_2024_01.parquet', 'fhvhv_2024_02.parquet', 'fhvhv_2024_03.parquet', 'fhv_2021_01.parquet', 'fhv_2021_02.parquet', 'fhv_2021_03.parquet', 'fhv_2021_04.parquet', 'fhv_2021_05.parquet', 'fhv_2021_06.parquet', 'fhv_2021_07.parquet', 'fhv_2021_08.parquet', 'fhv_2021_09.parquet', 'fhv_2021_10.parquet', 'fhv_2021_11.parquet', 'fhv_2021_12.parquet', 'fhv_2022_01.parquet', 'fhv_2022_02.parquet', 'fhv_2022_03.parquet', 'fhv_2022_04.parquet', 'fhv_2022_05.parquet', 'fhv_2022_06.parquet', 'fhv_2022_07.parquet', 'fhv_2022_08.parquet', 'fhv_2022_09.parquet', 'fhv_2022_10.parquet', 'fhv_2022_11.parquet', 'fhv_2022_12.parquet', 'fhv_2023_01.parquet', 'fhv_2023_02.parquet', 'fhv_2023_03.parquet', 'fhv_2023_04.parquet', 'fhv_2023_05.parquet', 'fhv_2023_06.parquet', 'fhv_2023_07.parquet', 'fhv_2023_08.parquet', 'fhv_2023_09.parquet', 'fhv_2023_10.parquet', 'fhv_2023_11.parquet', 'fhv_2023_12.parquet', 'fhv_2024_01.parquet', 'fhv_2024_02.parquet', 'fhv_2024_03.parquet', 'green_2021_01.parquet', 'green_2021_02.parquet', 'green_2021_03.parquet', 'green_2021_04.parquet', 'green_2021_05.parquet', 'green_2021_06.parquet', 'green_2021_07.parquet', 'green_2021_08.parquet', 'green_2021_09.parquet', 'green_2021_10.parquet', 'green_2021_11.parquet', 'green_2021_12.parquet', 'green_2022_01.parquet', 'green_2022_02.parquet', 'green_2022_03.parquet', 'green_2022_04.parquet', 'green_2022_05.parquet', 'green_2022_06.parquet', 'green_2022_07.parquet', 'green_2022_08.parquet', 'green_2022_09.parquet', 'green_2022_10.parquet', 'green_2022_11.parquet', 'green_2022_12.parquet', 'green_2023_01.parquet', 'green_2023_02.parquet', 'green_2023_03.parquet', 'green_2023_04.parquet', 'green_2023_05.parquet', 'green_2023_06.parquet', 'green_2023_07.parquet', 'green_2023_08.parquet', 'green_2023_09.parquet', 'green_2023_10.parquet', 'green_2023_11.parquet', 'green_2023_12.parquet', 'green_2024_01.parquet', 'green_2024_02.parquet', 'green_2024_03.parquet', 'yellow_2021_01.parquet', 'yellow_2021_02.parquet', 'yellow_2021_03.parquet', 'yellow_2021_04.parquet', 'yellow_2021_05.parquet', 'yellow_2021_06.parquet', 'yellow_2021_07.parquet', 'yellow_2021_08.parquet', 'yellow_2021_09.parquet', 'yellow_2021_10.parquet', 'yellow_2021_11.parquet', 'yellow_2021_12.parquet', 'yellow_2022_01.parquet', 'yellow_2022_02.parquet', 'yellow_2022_03.parquet', 'yellow_2022_04.parquet', 'yellow_2022_05.parquet', 'yellow_2022_06.parquet', 'yellow_2022_07.parquet', 'yellow_2022_08.parquet', 'yellow_2022_09.parquet', 'yellow_2022_10.parquet', 'yellow_2022_11.parquet', 'yellow_2022_12.parquet', 'yellow_2023_01.parquet', 'yellow_2023_02.parquet', 'yellow_2023_03.parquet', 'yellow_2023_04.parquet', 'yellow_2023_05.parquet', 'yellow_2023_06.parquet', 'yellow_2023_07.parquet', 'yellow_2023_08.parquet', 'yellow_2023_09.parquet', 'yellow_2023_10.parquet', 'yellow_2023_11.parquet', 'yellow_2023_12.parquet', 'yellow_2024_01.parquet', 'yellow_2024_02.parquet', 'yellow_2024_03.parquet']\n",
      "156\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(os.getcwd(), \"..\", \"Datasets\", \"taxi_parquets\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(data_dir):\n",
    "    print(f\"Directory {data_dir} does not exist\")\n",
    "else:\n",
    "    # List all files in the directory to check for existence and naming\n",
    "    all_files_in_dir = os.listdir(data_dir)\n",
    "    print(f\"Files in directory {data_dir}: {all_files_in_dir}\")\n",
    "\n",
    "    all_files = []\n",
    "    print(len(all_files_in_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_01*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_01*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_01.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_02*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_02*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_02.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_03*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_03*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_03.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_04*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_04*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_04.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_05*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_05*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_05.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_06*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_06*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_06.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_07*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_07*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_07.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_08*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_08*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_08.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_09*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_09*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_09.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_10*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_10*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_10.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_11*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_11*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_11.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_12*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_12*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_12.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_01*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_01*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_01.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_02*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_02*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_02.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_03*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_03*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_03.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_04*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_04*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_04.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_05*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_05*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_05.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_06*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_06*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_06.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_07*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_07*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_07.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_08*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_08*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_08.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_09*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_09*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_09.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_10*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_10*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_10.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_11*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_11*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_11.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_12*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2022_12*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_12.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_01*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_01*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_01.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_02*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_02*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_02.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_03*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_03*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_03.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_04*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_04*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_04.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_05*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_05*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_05.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_06*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_06*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_06.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_07*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_07*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_07.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_08*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_08*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_08.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_09*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_09*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_09.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_10*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_10*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_10.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_11*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_11*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_11.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_12*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2023_12*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_12.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2024_01*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2024_01*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2024_01.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2024_02*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2024_02*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2024_02.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2024_03*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2024_03*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2024_03.parquet']\n",
      "All files found: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2021_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2022_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2023_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2024_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2024_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\yellow_2024_03.parquet']\n",
      "Number of files found: 39\n"
     ]
    }
   ],
   "source": [
    "all_files = []\n",
    "\n",
    "for date in date_range:\n",
    "    search_pattern = os.path.join(data_dir, f\"yellow_{date.strftime('%Y_%m')}*.parquet\")\n",
    "    print(f\"Searching for files with pattern: {search_pattern}\")\n",
    "    files = glob.glob(search_pattern)\n",
    "    if files:\n",
    "        print(f\"Files found for pattern {search_pattern}: {files}\")\n",
    "    all_files.extend(files)  # Add the found files to the list\n",
    "\n",
    "print(\"All files found:\", all_files)\n",
    "print(\"Number of files found:\", len(all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path for yellow_2021_01: /data-analytics/Datasets/taxi_parquets/yellow_2021_01.parquet\n"
     ]
    }
   ],
   "source": [
    "print(\"File path for yellow_2021_01:\", r\"/data-analytics/Datasets/taxi_parquets/yellow_2021_01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\n",
      "Data Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\n",
      "yellow_2021_01_path: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\yellow_2021_01.parquet\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Begin by loading 1 parquet file as pandas dataframe.\n",
    "Error catching across OSes implemented: cwd, data directory, paths etc.\n",
    "\"\"\"\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(\"Current Working Directory:\", cwd)\n",
    "\n",
    "# Define the directory where the data is located relative to the current working directory\n",
    "print(\"Data Directory:\", data_dir)\n",
    "\n",
    "# Define the file paths relative to the data directory\n",
    "yellow_2021_01_path = os.path.join(data_dir, \"yellow_2021_01.parquet\")\n",
    "\n",
    "# Print the constructed file paths to verify\n",
    "print(\"yellow_2021_01_path:\", yellow_2021_01_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the parquet files using the relative file paths\n",
    "yellow_2021_01 = pd.read_parquet(yellow_2021_01_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory path to save CSV files: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_other\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Save dataframes to CSVs, for alternative and efficient analysis\n",
    "Similar error catching as above\n",
    "\"\"\"\n",
    "\n",
    "directory_path = os.path.join(os.getcwd(), \"..\", \"Datasets\", \"taxi_other\")\n",
    "\n",
    "# Print target directory path (error catching)\n",
    "print(\"Directory path to save CSV files:\", directory_path)\n",
    "\n",
    "# Verify the directory exists\n",
    "if not os.path.isdir(directory_path):\n",
    "    raise OSError(f\"Directory does not exist: '{directory_path}'\")\n",
    "\n",
    "# Define file paths for each CSV\n",
    "yellow_file_path = os.path.join(directory_path, \"yellow_2021_01.csv\")\n",
    "\n",
    "# Save each dataframe to its respective CSV file\n",
    "yellow_2021_01.to_csv(yellow_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_2021_01 = pd.read_parquet(yellow_2021_01_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigating Yellow Taxi Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:16:29</td>\n",
       "      <td>2021-01-01 00:24:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>224</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:00:28</td>\n",
       "      <td>2021-01-01 00:17:28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>95</td>\n",
       "      <td>157</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:12:29</td>\n",
       "      <td>2021-01-01 00:30:34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:39:16</td>\n",
       "      <td>2021-01-01 01:00:13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>97</td>\n",
       "      <td>129</td>\n",
       "      <td>4</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>28.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:26:12</td>\n",
       "      <td>2021-01-01 00:39:46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>263</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2021-01-01 00:30:10   2021-01-01 00:36:12              1.0   \n",
       "1         1  2021-01-01 00:51:20   2021-01-01 00:52:19              1.0   \n",
       "2         1  2021-01-01 00:43:30   2021-01-01 01:11:06              1.0   \n",
       "3         1  2021-01-01 00:15:48   2021-01-01 00:31:01              0.0   \n",
       "4         2  2021-01-01 00:31:49   2021-01-01 00:48:21              1.0   \n",
       "5         1  2021-01-01 00:16:29   2021-01-01 00:24:30              1.0   \n",
       "6         1  2021-01-01 00:00:28   2021-01-01 00:17:28              1.0   \n",
       "7         1  2021-01-01 00:12:29   2021-01-01 00:30:34              1.0   \n",
       "8         1  2021-01-01 00:39:16   2021-01-01 01:00:13              1.0   \n",
       "9         1  2021-01-01 00:26:12   2021-01-01 00:39:46              2.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           2.10         1.0                  N           142            43   \n",
       "1           0.20         1.0                  N           238           151   \n",
       "2          14.70         1.0                  N           132           165   \n",
       "3          10.60         1.0                  N           138           132   \n",
       "4           4.94         1.0                  N            68            33   \n",
       "5           1.60         1.0                  N           224            68   \n",
       "6           4.10         1.0                  N            95           157   \n",
       "7           5.70         1.0                  N            90            40   \n",
       "8           9.10         1.0                  N            97           129   \n",
       "9           2.70         1.0                  N           263           142   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          8.0    3.0      0.5        0.00           0.0   \n",
       "1             2          3.0    0.5      0.5        0.00           0.0   \n",
       "2             1         42.0    0.5      0.5        8.65           0.0   \n",
       "3             1         29.0    0.5      0.5        6.05           0.0   \n",
       "4             1         16.5    0.5      0.5        4.06           0.0   \n",
       "5             1          8.0    3.0      0.5        2.35           0.0   \n",
       "6             2         16.0    0.5      0.5        0.00           0.0   \n",
       "7             2         18.0    3.0      0.5        0.00           0.0   \n",
       "8             4         27.5    0.5      0.5        0.00           0.0   \n",
       "9             1         12.0    3.0      0.5        3.15           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    0.3         11.80                   2.5          NaN  \n",
       "1                    0.3          4.30                   0.0          NaN  \n",
       "2                    0.3         51.95                   0.0          NaN  \n",
       "3                    0.3         36.35                   0.0          NaN  \n",
       "4                    0.3         24.36                   2.5          NaN  \n",
       "5                    0.3         14.15                   2.5          NaN  \n",
       "6                    0.3         17.30                   0.0          NaN  \n",
       "7                    0.3         21.80                   2.5          NaN  \n",
       "8                    0.3         28.80                   0.0          NaN  \n",
       "9                    0.3         18.95                   2.5          NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellow_2021_01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1369769 entries, 0 to 1369768\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count    Dtype         \n",
      "---  ------                 --------------    -----         \n",
      " 0   VendorID               1369769 non-null  int64         \n",
      " 1   tpep_pickup_datetime   1369769 non-null  datetime64[us]\n",
      " 2   tpep_dropoff_datetime  1369769 non-null  datetime64[us]\n",
      " 3   passenger_count        1271417 non-null  float64       \n",
      " 4   trip_distance          1369769 non-null  float64       \n",
      " 5   RatecodeID             1271417 non-null  float64       \n",
      " 6   store_and_fwd_flag     1271417 non-null  object        \n",
      " 7   PULocationID           1369769 non-null  int64         \n",
      " 8   DOLocationID           1369769 non-null  int64         \n",
      " 9   payment_type           1369769 non-null  int64         \n",
      " 10  fare_amount            1369769 non-null  float64       \n",
      " 11  extra                  1369769 non-null  float64       \n",
      " 12  mta_tax                1369769 non-null  float64       \n",
      " 13  tip_amount             1369769 non-null  float64       \n",
      " 14  tolls_amount           1369769 non-null  float64       \n",
      " 15  improvement_surcharge  1369769 non-null  float64       \n",
      " 16  total_amount           1369769 non-null  float64       \n",
      " 17  congestion_surcharge   1271417 non-null  float64       \n",
      " 18  airport_fee            5 non-null        float64       \n",
      "dtypes: datetime64[us](2), float64(12), int64(4), object(1)\n",
      "memory usage: 198.6+ MB\n"
     ]
    }
   ],
   "source": [
    "yellow_2021_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renaming_yellow_to_standard(dfs):\n",
    "    \"\"\" \n",
    "    Functions for renaming the columns of a dataset or list of datasets to standard names, which will ease the cleaning process\n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            df.rename(columns={\n",
    "                'tpep_pickup_datetime': 'pickup_datetime', \n",
    "                'tpep_dropoff_datetime': 'dropoff_datetime', \n",
    "                'PULocationID': 'pickup_zone', \n",
    "                'DOLocationID': 'dropoff_zone'\n",
    "            }, inplace=True)\n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "\n",
    "renaming_yellow_to_standard(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_float_to_int(dfs):\n",
    "    \"\"\" \n",
    "    Function for converting datatypes of specific columns of a DataFrame or list of DataFrames to appropriate types.\n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            if \"RatecodeID\" in df.columns:\n",
    "                df[\"RatecodeID\"] = df[\"RatecodeID\"].fillna(0).astype(\"int\")\n",
    "            if \"passenger_count\" in df.columns:\n",
    "                df[\"passenger_count\"] = df[\"passenger_count\"].fillna(0).astype(\"int\")\n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "\n",
    "convert_float_to_int(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate rows found\n"
     ]
    }
   ],
   "source": [
    "def duplicated_rows(dfs):\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            duplicate_rows = df[df.duplicated()]\n",
    "            if not duplicate_rows.empty:\n",
    "                print(\"Duplicate rows found:\\n\", duplicate_rows)\n",
    "            else:\n",
    "                print(\"No duplicate rows found\")\n",
    "duplicated_rows(yellow_2021_01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count for each unique value in 'passenger_count' column: in\n",
      "passenger_count\n",
      "1    966236\n",
      "2    161671\n",
      "0    125078\n",
      "3     43935\n",
      "5     31089\n",
      "6     25362\n",
      "4     16391\n",
      "7         5\n",
      "8         2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def passenger_counts(dfs):\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            passenger_count_counts = df['passenger_count'].value_counts()\n",
    "            if not passenger_count_counts.empty:\n",
    "                print(\"Count for each unique value in 'passenger_count' column: in\")\n",
    "                print(passenger_count_counts)\n",
    "\n",
    "passenger_counts(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with invalid fares:  7417\n",
      "5 Sample Rows with Invalid Fares:\n",
      "        VendorID     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
      "961032         2 2021-01-24 19:24:40 2021-01-24 19:28:15                1   \n",
      "791413         2 2021-01-20 19:20:59 2021-01-20 19:24:32                2   \n",
      "699436         1 2021-01-18 19:26:01 2021-01-18 19:27:13                1   \n",
      "288947         2 2021-01-08 17:58:16 2021-01-08 18:10:21                1   \n",
      "107851         2 2021-01-04 16:59:01 2021-01-04 17:04:26                1   \n",
      "\n",
      "        trip_distance  RatecodeID store_and_fwd_flag  pickup_zone  \\\n",
      "961032           0.90           1                  N          186   \n",
      "791413           0.51           1                  N          162   \n",
      "699436           0.10           5                  N          236   \n",
      "288947           1.40           1                  N          264   \n",
      "107851           1.44           1                  N          148   \n",
      "\n",
      "        dropoff_zone  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
      "961032           234             4         -5.0    0.0     -0.5         0.0   \n",
      "791413           161             4         -4.5   -1.0     -0.5         0.0   \n",
      "699436           236             4          0.0    0.0      0.0         0.0   \n",
      "288947           137             4         -9.0   -1.0     -0.5         0.0   \n",
      "107851           107             4         -6.5   -1.0     -0.5         0.0   \n",
      "\n",
      "        tolls_amount  improvement_surcharge  total_amount  \\\n",
      "961032           0.0                   -0.3          -8.3   \n",
      "791413           0.0                   -0.3          -8.8   \n",
      "699436           0.0                    0.3           0.3   \n",
      "288947           0.0                   -0.3         -13.3   \n",
      "107851           0.0                   -0.3         -10.8   \n",
      "\n",
      "        congestion_surcharge  airport_fee  \n",
      "961032                  -2.5          NaN  \n",
      "791413                  -2.5          NaN  \n",
      "699436                   0.0          NaN  \n",
      "288947                  -2.5          NaN  \n",
      "107851                  -2.5          NaN  \n"
     ]
    }
   ],
   "source": [
    "def count_invalid_fares(dfs):\n",
    "    \"\"\"\n",
    "    Count rows where any fare-related column has an invalid value.\n",
    "    \n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "\n",
    "    # Columns to check for invalid fare amounts, <= 0; Need a fare for a valid trip\n",
    "            fare_columns = ['fare_amount', 'total_amount']\n",
    "\n",
    "    # Additional columns to check for negative values, < 0 as \"0\" is a valid value\n",
    "            additional_fare_columns = ['extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge', 'airport_fee']\n",
    "\n",
    "    # Count rows where any fare-related column has an invalid value\n",
    "            invalid_fare_counts = df[\n",
    "                (df[fare_columns] <= 0).any(axis=1) | \n",
    "                (df[additional_fare_columns] < 0).any(axis=1)].shape[0]\n",
    "            print(\"Number of rows with invalid fares: \", invalid_fare_counts)\n",
    "\n",
    "            # Find + print rows where with invalid fares\n",
    "            invalid_fare_rows = df[\n",
    "            (df[fare_columns] <= 0).any(axis=1) |\n",
    "            (df[additional_fare_columns] < 0).any(axis=1)]\n",
    "\n",
    "            # Print 5 sample rows with invalid fares\n",
    "            sample_rows = invalid_fare_rows.sample(n=5, random_state=42)\n",
    "            print(\"5 Sample Rows with Invalid Fares:\")\n",
    "            print(sample_rows)\n",
    "\n",
    "count_invalid_fares(yellow_2021_01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did anyone Time Travel?\n",
      "5642\n",
      "One of the rows where time travel occurred:\n",
      "VendorID                                   1\n",
      "pickup_datetime          2021-01-05 17:43:19\n",
      "dropoff_datetime         2021-01-05 17:39:06\n",
      "passenger_count                            1\n",
      "trip_distance                            0.0\n",
      "RatecodeID                                 1\n",
      "store_and_fwd_flag                         N\n",
      "pickup_zone                              145\n",
      "dropoff_zone                             145\n",
      "payment_type                               2\n",
      "fare_amount                              4.0\n",
      "extra                                    1.0\n",
      "mta_tax                                  0.5\n",
      "tip_amount                               0.0\n",
      "tolls_amount                             0.0\n",
      "improvement_surcharge                    0.3\n",
      "total_amount                             5.8\n",
      "congestion_surcharge                     0.0\n",
      "airport_fee                              NaN\n",
      "Name: 151936, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def time_travel(dfs):    \n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            time_travel = df[df['pickup_datetime'] > df['dropoff_datetime']].shape[0]\n",
    "            print(\"Did anyone Time Travel?\")\n",
    "            print(time_travel)\n",
    "\n",
    "            # Find + print rows where pickup time is after dropoff time\n",
    "            time_travel_rows = df[df['pickup_datetime'] > df['dropoff_datetime']]\n",
    "            if not time_travel_rows.empty:\n",
    "                print(\"One of the rows where time travel occurred:\")\n",
    "                print(time_travel_rows.iloc[0])\n",
    "            else:\n",
    "                print(\"No rows where time travel occurred.\")            \n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "\n",
    "time_travel(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travelling no distances?\n",
      "19952\n",
      "One of the rows of the immovable objects:\n",
      "VendorID                                   1\n",
      "pickup_datetime          2021-01-01 00:03:13\n",
      "dropoff_datetime         2021-01-01 00:03:19\n",
      "passenger_count                            1\n",
      "trip_distance                            0.0\n",
      "RatecodeID                                 1\n",
      "store_and_fwd_flag                         N\n",
      "pickup_zone                              169\n",
      "dropoff_zone                             169\n",
      "payment_type                               3\n",
      "fare_amount                              0.0\n",
      "extra                                    0.0\n",
      "mta_tax                                  0.0\n",
      "tip_amount                               0.0\n",
      "tolls_amount                             0.0\n",
      "improvement_surcharge                    0.0\n",
      "total_amount                             0.0\n",
      "congestion_surcharge                     0.0\n",
      "airport_fee                              NaN\n",
      "Name: 38, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def immovable_objects(dfs):    \n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            negative_distances = df[df['trip_distance'] <= 0].shape[0]\n",
    "            print(\"Travelling no distances?\")\n",
    "            print(negative_distances)\n",
    "\n",
    "            # Find + print rows where pickup time is after dropoff time\n",
    "            negative_distances_rows = df[df['trip_distance'] <= 0]\n",
    "            if not negative_distances_rows.empty:\n",
    "                print(\"One of the rows of the immovable objects:\")\n",
    "                print(negative_distances_rows.iloc[0]) #change this number for other examples\n",
    "            else:\n",
    "                print(\"No rows where time travel occurred.\")\n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "\n",
    "immovable_objects(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with payment_type 4 (Dispute): 5667\n",
      "5 Sample Rows with payment_type 4 (Dispute):\n",
      "         VendorID     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
      "1047827         1 2021-01-26 19:22:23 2021-01-26 19:23:29                1   \n",
      "964262          2 2021-01-24 22:25:40 2021-01-24 22:32:23                1   \n",
      "1102473         1 2021-01-28 03:27:12 2021-01-28 03:30:50                1   \n",
      "995123          1 2021-01-25 16:32:28 2021-01-25 16:36:57                1   \n",
      "900844          2 2021-01-23 09:14:12 2021-01-23 09:45:20                2   \n",
      "\n",
      "         trip_distance  RatecodeID store_and_fwd_flag  pickup_zone  \\\n",
      "1047827           2.10           1                  N          262   \n",
      "964262            0.99           1                  N          100   \n",
      "1102473           0.50           1                  N          239   \n",
      "995123            0.80           1                  N          234   \n",
      "900844            2.39           1                  N          263   \n",
      "\n",
      "         dropoff_zone  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
      "1047827           262             4          3.0    3.5      0.5         0.0   \n",
      "964262            170             4         -6.0   -0.5     -0.5         0.0   \n",
      "1102473           142             4          4.5    3.0      0.5         0.0   \n",
      "995123            186             4          5.5    3.5      0.5         0.0   \n",
      "900844            263             4        -20.0    0.0     -0.5         0.1   \n",
      "\n",
      "         tolls_amount  improvement_surcharge  total_amount  \\\n",
      "1047827           0.0                    0.3           7.3   \n",
      "964262            0.0                   -0.3          -9.8   \n",
      "1102473           0.0                    0.3           8.3   \n",
      "995123            0.0                    0.3           9.8   \n",
      "900844            0.0                   -0.3         -23.2   \n",
      "\n",
      "         congestion_surcharge  airport_fee  \n",
      "1047827                   2.5          NaN  \n",
      "964262                   -2.5          NaN  \n",
      "1102473                   2.5          NaN  \n",
      "995123                    2.5          NaN  \n",
      "900844                   -2.5          NaN  \n"
     ]
    }
   ],
   "source": [
    "def check_dispute_payments(dfs):\n",
    "    \"\"\"\n",
    "    Count rows where payment_type is 4 (Dispute) and print sample rows.\n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    \n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            # Count rows where payment_type is 4 (Dispute)\n",
    "            dispute_count = df[df['payment_type'] == 4].shape[0]\n",
    "            print(\"Number of rows with payment_type 4 (Dispute):\", dispute_count)\n",
    "\n",
    "            # Find rows where payment_type is 4 (Dispute)\n",
    "            dispute_rows = df[df['payment_type'] == 4]\n",
    "\n",
    "            # Print 5 sample rows with payment_type 4 (Dispute)\n",
    "            sample_rows = dispute_rows.sample(n=5, random_state=42)\n",
    "            print(\"5 Sample Rows with payment_type 4 (Dispute):\")\n",
    "            print(sample_rows)\n",
    "\n",
    "check_dispute_payments(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the 'airport_fee' column and their counts:\n",
      "airport_fee\n",
      "0.0    5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def check_airport_fee_values(dfs):\n",
    "    \"\"\"\n",
    "    Print all unique values in the 'airport_fee' column and their counts.\n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            # Get the unique values and their counts in the 'airport_fee' column\n",
    "            unique_values_counts = df['airport_fee'].value_counts()\n",
    "            \n",
    "            # Print the unique values and their counts\n",
    "            print(\"Unique values in the 'airport_fee' column and their counts:\")\n",
    "            print(unique_values_counts)\n",
    "\n",
    "check_airport_fee_values(yellow_2021_01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the trip would result in the driver’s having to operate the taxicab for more than 12 consecutive hours, which is prohibited, then that driver may refuse to take a passenger to these destinations.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\n",
      "Taxi Zone CSV Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_other\n",
      "Number of Unique Zones: 69\n",
      "List of Unique Zones: [  4  12  13  24  41  42  43  45  48  50  68  74  75  79  87  88  90 100\n",
      " 103 104 105 107 113 114 116 120 125 127 128 137 140 141 142 143 144 148\n",
      " 151 152 153 158 161 162 163 164 166 170 186 194 202 209 211 224 229 230\n",
      " 231 232 233 234 236 237 238 239 243 244 246 249 261 262 263]\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Working Directory:\", cwd)\n",
    "\n",
    "taxi_zone_dir = os.path.join(os.getcwd(), \"..\", \"Datasets\", \"taxi_other\")\n",
    "\n",
    "\n",
    "# Define the directory where the data is located relative to the current working directory\n",
    "print(\"Taxi Zone CSV Directory:\", taxi_zone_dir)\n",
    "\n",
    "# Define the file path relative to the data directory\n",
    "taxi_zone_path = os.path.join(cwd, taxi_zone_dir, \"taxi_zone_lookup.csv\")\n",
    "\n",
    "taxi_zone = pd.read_csv(taxi_zone_path, keep_default_na=True, delimiter=\",\", skipinitialspace=True, encoding=\"Windows-1252\")\n",
    "\n",
    "def valid_zones_1(df):\n",
    "    manhattan_df = df[df[\"Borough\"] == \"Manhattan\"]\n",
    "    unique_zones = manhattan_df[\"LocationID\"].unique()\n",
    "    \n",
    "    print(f\"Number of Unique Zones: {len(unique_zones)}\")\n",
    "    print(\"List of Unique Zones:\", unique_zones)\n",
    "\n",
    "valid_zones_1(taxi_zone)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Zones: 67\n",
      "List of Unique Zones: [  4  24  12  13  41  45  42  43  48  50  68  79  74  75  87  88  90 125\n",
      " 100 103 107 113 114 116 120 127 128 151 140 137 141 142 152 143 144 148\n",
      " 153 158 161 162 163 164 170 166 186 194 202 209 211 224 229 230 231 239\n",
      " 232 233 234 236 237 238 263 243 244 246 249 261 262]\n"
     ]
    }
   ],
   "source": [
    "# Define the file path relative to the data directory\n",
    "taxi_zone_alternate_path = os.path.join(cwd, taxi_zone_dir, \"taxi_zones_alternate.csv\")\n",
    "\n",
    "taxi_zone_alternate = pd.read_csv(taxi_zone_alternate_path, keep_default_na=True, delimiter=\",\", skipinitialspace=True, encoding=\"Windows-1252\")\n",
    "\n",
    "def valid_zones_alternate(df):\n",
    "    manhattan_df = df[df[\"borough\"] == \"Manhattan\"] # Change in capitalisation of \"Borough\"\n",
    "    unique_zones = manhattan_df[\"LocationID\"].unique()\n",
    "    \n",
    "    print(f\"Number of Unique Zones: {len(unique_zones)}\")\n",
    "    print(\"List of Unique Zones:\", unique_zones)\n",
    "\n",
    "valid_zones_alternate(taxi_zone_alternate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\n",
      "Number of Unique Zones in CSV 1: 69\n",
      "List of Unique Zones in CSV 1: [4, 12, 13, 24, 41, 42, 43, 45, 48, 50, 68, 74, 75, 79, 87, 88, 90, 100, 103, 104, 105, 107, 113, 114, 116, 120, 125, 127, 128, 137, 140, 141, 142, 143, 144, 148, 151, 152, 153, 158, 161, 162, 163, 164, 166, 170, 186, 194, 202, 209, 211, 224, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 243, 244, 246, 249, 261, 262, 263]\n",
      "Number of Unique Zones in CSV 2: 67\n",
      "List of Unique Zones in CSV 2: [4, 12, 13, 24, 41, 42, 43, 45, 48, 50, 68, 74, 75, 79, 87, 88, 90, 100, 103, 107, 113, 114, 116, 120, 125, 127, 128, 137, 140, 141, 142, 143, 144, 148, 151, 152, 153, 158, 161, 162, 163, 164, 166, 170, 186, 194, 202, 209, 211, 224, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 243, 244, 246, 249, 261, 262, 263]\n",
      "Zones only in CSV 1: [104, 105]\n",
      "Zones only in CSV 2: []\n",
      "Zones present only in the first CSV: {104, 105}\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(\"Current Working Directory:\", cwd)\n",
    "\n",
    "# Load the CSV files\n",
    "taxi_zone1 = pd.read_csv(taxi_zone_path, keep_default_na=True, delimiter=\",\", skipinitialspace=True, encoding=\"Windows-1252\")\n",
    "taxi_zone2 = pd.read_csv(taxi_zone_alternate_path, keep_default_na=True, delimiter=\",\", skipinitialspace=True, encoding=\"Windows-1252\")\n",
    "\n",
    "# Define a function to get unique zones for Manhattan\n",
    "def get_unique_zones(df, borough_col):\n",
    "    manhattan_df = df[df[borough_col] == \"Manhattan\"]\n",
    "    unique_zones = manhattan_df[\"LocationID\"].unique()\n",
    "    return set(unique_zones)\n",
    "\n",
    "# Get unique zones for Manhattan from both CSVs\n",
    "unique_zones1 = get_unique_zones(taxi_zone1, \"Borough\")\n",
    "unique_zones2 = get_unique_zones(taxi_zone2, \"borough\")\n",
    "\n",
    "# Print the unique zones and their counts\n",
    "print(f\"Number of Unique Zones in CSV 1: {len(unique_zones1)}\")\n",
    "print(f\"List of Unique Zones in CSV 1: {sorted(unique_zones1)}\")\n",
    "\n",
    "print(f\"Number of Unique Zones in CSV 2: {len(unique_zones2)}\")\n",
    "print(f\"List of Unique Zones in CSV 2: {sorted(unique_zones2)}\")\n",
    "\n",
    "# Identify the differences\n",
    "zones_only_in_csv1 = unique_zones1 - unique_zones2\n",
    "zones_only_in_csv2 = unique_zones2 - unique_zones1\n",
    "\n",
    "print(f\"Zones only in CSV 1: {sorted(zones_only_in_csv1)}\")\n",
    "print(f\"Zones only in CSV 2: {sorted(zones_only_in_csv2)}\")\n",
    "\n",
    "# Analyze the differences to determine correctness\n",
    "if zones_only_in_csv1:\n",
    "    print(f\"Zones present only in the first CSV: {zones_only_in_csv1}\")\n",
    "\n",
    "if zones_only_in_csv2:\n",
    "    print(f\"Zones present only in the second CSV: {zones_only_in_csv2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CSV 1, \"taxi_zone_lookup.csv\". It has 2 zones not in \"taxi_zones_alternate.csv\", and these zones are present at least in the fhv parquets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get unique zones for Manhattan\n",
    "def get_manhattan_zones(df):\n",
    "    manhattan_df = df[df[\"Borough\"] == \"Manhattan\"]\n",
    "    unique_zones = manhattan_df[\"LocationID\"].unique()\n",
    "    return set(unique_zones)\n",
    "\n",
    "# Get the unique Manhattan zones from the taxi_zone DataFrame\n",
    "manhattan_zones = get_manhattan_zones(taxi_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to check pickup and dropoff zones\n",
    "def check_zones(df, manhattan_zones):\n",
    "    # Check if both pickup_zone and dropoff_zone are not in manhattan_zones\n",
    "    invalid_zones = df[~df[\"pickup_zone\"].isin(manhattan_zones) & ~df[\"dropoff_zone\"].isin(manhattan_zones)]\n",
    "    \n",
    "    print(f\"Invalid zones count: {invalid_zones.shape[0]}\")\n",
    "    \n",
    "    if not invalid_zones.empty:\n",
    "        print(\"Examples of rows with invalid zones:\")\n",
    "        print(invalid_zones.head())  # Print first few invalid rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid zones count: 96421\n",
      "Examples of rows with invalid zones:\n",
      "    VendorID     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
      "2          1 2021-01-01 00:43:30 2021-01-01 01:11:06                1   \n",
      "3          1 2021-01-01 00:15:48 2021-01-01 00:31:01                0   \n",
      "6          1 2021-01-01 00:00:28 2021-01-01 00:17:28                1   \n",
      "8          1 2021-01-01 00:39:16 2021-01-01 01:00:13                1   \n",
      "11         2 2021-01-01 00:46:36 2021-01-01 00:53:45                2   \n",
      "\n",
      "    trip_distance  RatecodeID store_and_fwd_flag  pickup_zone  dropoff_zone  \\\n",
      "2           14.70           1                  N          132           165   \n",
      "3           10.60           1                  N          138           132   \n",
      "6            4.10           1                  N           95           157   \n",
      "8            9.10           1                  N           97           129   \n",
      "11           1.21           1                  N          255            80   \n",
      "\n",
      "    payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "2              1         42.0    0.5      0.5        8.65           0.0   \n",
      "3              1         29.0    0.5      0.5        6.05           0.0   \n",
      "6              2         16.0    0.5      0.5        0.00           0.0   \n",
      "8              4         27.5    0.5      0.5        0.00           0.0   \n",
      "11             1          7.0    0.5      0.5        2.49           0.0   \n",
      "\n",
      "    improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
      "2                     0.3         51.95                   0.0          NaN  \n",
      "3                     0.3         36.35                   0.0          NaN  \n",
      "6                     0.3         17.30                   0.0          NaN  \n",
      "8                     0.3         28.80                   0.0          NaN  \n",
      "11                    0.3         10.79                   0.0          NaN  \n"
     ]
    }
   ],
   "source": [
    "check_zones(yellow_2021_01, manhattan_zones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Rows Borough Counts:\n",
      "Borough_combined\n",
      "Queens (pickup), Queens (dropoff)                  27520\n",
      "Brooklyn (pickup), Brooklyn (dropoff)              18404\n",
      "Queens (pickup), Brooklyn (dropoff)                14348\n",
      "Bronx (pickup), Bronx (dropoff)                     8570\n",
      "Unknown (pickup), Unknown (dropoff)                 5555\n",
      "Queens (pickup), Bronx (dropoff)                    3768\n",
      "Brooklyn (pickup), Queens (dropoff)                 2600\n",
      "Bronx (pickup), Queens (dropoff)                    1092\n",
      "Brooklyn (pickup), Bronx (dropoff)                  1082\n",
      "Bronx (pickup), Brooklyn (dropoff)                  1030\n",
      "Unknown (pickup), Queens (dropoff)                   383\n",
      "Queens (pickup), Unknown (dropoff)                   357\n",
      "Unknown (pickup), Brooklyn (dropoff)                 337\n",
      "Queens (pickup), Staten Island (dropoff)             249\n",
      "Brooklyn (pickup), Staten Island (dropoff)           174\n",
      "Staten Island (pickup), Queens (dropoff)             106\n",
      "Staten Island (pickup), Brooklyn (dropoff)           105\n",
      "Unknown (pickup), Bronx (dropoff)                     97\n",
      "Queens (pickup), EWR (dropoff)                        80\n",
      "Brooklyn (pickup), Unknown (dropoff)                  77\n",
      "Bronx (pickup), Unknown (dropoff)                     54\n",
      "Staten Island (pickup), Staten Island (dropoff)       50\n",
      "Staten Island (pickup), Bronx (dropoff)               48\n",
      "EWR (pickup), EWR (dropoff)                           43\n",
      "Bronx (pickup), Staten Island (dropoff)               43\n",
      "Brooklyn (pickup), EWR (dropoff)                      12\n",
      "EWR (pickup), Unknown (dropoff)                        9\n",
      "Unknown (pickup), EWR (dropoff)                        4\n",
      "Staten Island (pickup), Unknown (dropoff)              3\n",
      "Unknown (pickup), Staten Island (dropoff)              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def verifying_invalid_zones(df, manhattan_zones, taxi_zone_csv):\n",
    "    # Identify invalid rows where both pickup_zone and dropoff_zone are not in manhattan_zones\n",
    "    invalid_zones = df[~df[\"pickup_zone\"].isin(manhattan_zones) & ~df[\"dropoff_zone\"].isin(manhattan_zones)]\n",
    "    \n",
    "    # If there are no invalid rows, print and return\n",
    "    if invalid_zones.empty:\n",
    "        print(\"No invalid zones found.\")\n",
    "        return\n",
    "    \n",
    "    # Merge invalid zones with taxi_zone_csv to get borough information for both pickup_zone and dropoff_zone\n",
    "    invalid_zones_merged = invalid_zones.merge(taxi_zone_csv, left_on=\"pickup_zone\", right_on=\"LocationID\", how=\"left\", suffixes=('_pickup', '_dropoff'))\n",
    "    invalid_zones_merged = invalid_zones_merged.merge(taxi_zone_csv, left_on=\"dropoff_zone\", right_on=\"LocationID\", how=\"left\", suffixes=('_pickup', '_dropoff'))\n",
    "\n",
    "    # Concatenate Borough columns for analysis\n",
    "    invalid_zones_merged[\"Borough_combined\"] = invalid_zones_merged[\"Borough_pickup\"] + \" (pickup), \" + invalid_zones_merged[\"Borough_dropoff\"] + \" (dropoff)\"\n",
    "    \n",
    "    # Count the combined Borough information\n",
    "    combined_borough_counts = invalid_zones_merged[\"Borough_combined\"].value_counts()\n",
    "\n",
    "    print(\"Invalid Rows Borough Counts:\")\n",
    "    print(combined_borough_counts)\n",
    "\n",
    "manhattan_zones = get_manhattan_zones(taxi_zone)\n",
    "\n",
    "# Call the verifying_invalid_zones function\n",
    "verifying_invalid_zones(yellow_2021_01, manhattan_zones, taxi_zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Data Quality Report**\n",
    "- **Data Integrity Checks** \n",
    "\n",
    "Having investigated the CSVs, a number of data inconsistincies are present. They are summarised below:\n",
    "\n",
    "- Check 0: No duplicate rows present\n",
    "\n",
    "- Check 1: There are a number of trips with 0 passengers, as well as trip with more than 5 passengers. According to the TLC data dictionary, 5 is the maximum amount of passengers allowed. 0 might represent trips that didn't occur or were cancelled, or serve another purpose. As our goal is to track Busy-ness in NYC, values of 0, 6, 7 and 8 cannot be counted as valid.\n",
    "    - Drop rows from dataset where \"passenger_count\" == 0, 6, 7, 8.\n",
    "\n",
    "- Check 2: There are a number of trips with negative fare amounts. Negative fares could represent refunds or errors in the data entry, and are not likely to represent actual trips where passengers were transported. Since our goal is to track busyness in NYC, negative fare amounts cannot be considered valid data points.\n",
    "    - Drop rows from the dataset where \"fare_amount\" or \"total_amount\" <= 0 (0 is not a valid value)\n",
    "    - Drop rows from the dataset where \"extra\", \"mta_tax\", \"tip_amount'\", \"tolls_amount\", \"improvement_surcharge\", \"congestion_surcharge\", \"airport_fee\" < 0 (\"0\" is a valid value).\n",
    "    \n",
    "- Check 3: There are a number of trips where the pickup time is exactly the same as the dropoff time. This means no time has elapsed for the trip, which is suspicious and likely indicates invalid data points. There are also rows where the pickup time is later in time than the dropoff time (implying time travel). Further checks reveal additional inconsistencies:\n",
    "    - Further Checks:\n",
    "        -> The trip_distance is variable, ranging from 0 miles to over 13 miles, which is implausible for zero or negative elapsed time.\n",
    "        -> The total_amount is also variable, with fares ranging from $6 to over $48, despite zero minutes of travel time.\n",
    "        -> These data points are difficult to trust and it is hard to believe that they represent valid trips.\n",
    "            - Drop rows from the dataset where pickup_datetime == dropoff_datetime.\n",
    "\n",
    "- Check 4: There are some journeys with 0 trip distance, potentially indicating cancelled trips, or invalid ones. These rows do not represent busy-ness, as it is difficult to say that a trip occurred at all. Confusingly, these trips show a variation in total_amount from (-492.8 to +900.35).\n",
    "    - Drop rows from the dataset where \"trip_distance\" <= 0.\n",
    " \n",
    "- Check 5: According to the Yellow Taxi Data Dictionary (appended at bottom), RateCodeID, the final rate code in effect at the end of the trip, should have a value of 1-6. There are a number of rows with a value of \"99\". Some of these rows have varied and valid datetimes, total_amount, passenger_count,  and trip_distance. It is unclear what code \"99\" means, but according to the Data Dictionary, only rows with values of 1-6 are valid.\n",
    "    - Drop rows from the dataset where RateCodeID != 1-6.\n",
    "\n",
    "- Check 6: Disputed payments (payment_type == 4) often indicate issues with the fare. These might be unpaid, mispaid, or late charges. Disputes may suggest problems like incorrect dropoff locations or other inaccuracies in the journey data. The validity of these trips is questionable, as they may not accurately represent completed journeys.\n",
    "    - Drop rows from the dataset where payment_type == 4.\n",
    "\n",
    "- Check 7: The \"airport_fee\" contained only 5 entries with value 0, and the rest of the entries were NaN. This fee might be infrequently applied or waived altogether in the majority of recorded taxi journeys. \n",
    "    - Drop \"airport_fee\" column from dataset due to missing values.\n",
    "\n",
    "- Check 8: According to the accompanying \"taxi_zone_lookup.csv\" file, both the pickup_zone and dropoff_zone should be in Manhattan zones. Rows where neither pickup_zone nor dropoff_zone are in Manhattan zones are considered invalid.\n",
    "    - Drop rows from the dataset where both pickup_zone and dropoff_zone are not Manhattan zones.\n",
    "\n",
    "See also: \n",
    "    https://rules.cityofnewyork.us/rule/taximeter-rate-of-fare-and-various-surcharges/\n",
    "    https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf\n",
    "    https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_green.pdf\n",
    "    https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_fhv.pdf\n",
    "    https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_hvfhs.pdf\n",
    "    https://www.nyc.gov/site/tlc/passengers/passenger-frequently-asked-questions.page \n",
    "    https://www.nyc.gov/site/tlc/passengers/taxi-fare.page \n",
    "    https://www.nyc.gov/assets/tlc/downloads/pdf/archived_public_notices/public_notice_09_17_09.pdf\n",
    "    https://www.nyc.gov/assets/tlc/downloads/pdf/trip_record_user_guide.pdf \n",
    "    https://data.cityofnewyork.us/City-Government/NTA-map/d3qk-pfyz\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_yellow_invalid_rows(df, manhattan_zones):\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        # Drop duplicate rows\n",
    "        df = df.drop_duplicates()\n",
    "        \n",
    "        # Drop rows where passenger_count == 0 or >= 6\n",
    "        df = df[(df[\"passenger_count\"] > 0) & (df[\"passenger_count\"] < 6)]\n",
    "        \n",
    "        # Drop rows where fare_amount or total_amount <= 0\n",
    "        df = df[(df[\"fare_amount\"] > 0) & (df[\"total_amount\"] > 0)]\n",
    "        \n",
    "        # Drop rows where extra, mta_tax, tip_amount, tolls_amount, improvement_surcharge, or congestion_surcharge < 0\n",
    "        df = df[(df[\"extra\"] >= 0) & (df[\"mta_tax\"] >= 0) & (df[\"tip_amount\"] >= 0) & \n",
    "                (df[\"tolls_amount\"] >= 0) & (df[\"improvement_surcharge\"] >= 0) & \n",
    "                (df[\"congestion_surcharge\"] >= 0)]\n",
    "        \n",
    "        # Drop rows where pickup_datetime == dropoff_datetime\n",
    "        df = df[df[\"pickup_datetime\"] != df[\"dropoff_datetime\"]]\n",
    "        \n",
    "        # Drop rows where trip_distance <= 0\n",
    "        df = df[df[\"trip_distance\"] > 0]\n",
    "        \n",
    "        # Drop rows where RateCodeID != 1-6\n",
    "        df = df[df[\"RatecodeID\"].isin([1, 2, 3, 4, 5, 6])]\n",
    "        \n",
    "        # Drop rows where payment_type == 4\n",
    "        df = df[df[\"payment_type\"] != 4]\n",
    "        \n",
    "        # Drop rows where both pickup_zone and dropoff_zone are not Manhattan zones\n",
    "        df = df[df[\"pickup_zone\"].isin(manhattan_zones) | df[\"dropoff_zone\"].isin(manhattan_zones)]\n",
    "        \n",
    "    else:\n",
    "        print(\"Warning: Input is not a DataFrame\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_zones = get_manhattan_zones(taxi_zone)\n",
    "\n",
    "yellow_2021_01 = drop_yellow_invalid_rows(yellow_2021_01, manhattan_zones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1149499 entries, 0 to 1271416\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count    Dtype         \n",
      "---  ------                 --------------    -----         \n",
      " 0   VendorID               1149499 non-null  int64         \n",
      " 1   pickup_datetime        1149499 non-null  datetime64[us]\n",
      " 2   dropoff_datetime       1149499 non-null  datetime64[us]\n",
      " 3   passenger_count        1149499 non-null  int32         \n",
      " 4   trip_distance          1149499 non-null  float64       \n",
      " 5   RatecodeID             1149499 non-null  int32         \n",
      " 6   store_and_fwd_flag     1149499 non-null  object        \n",
      " 7   pickup_zone            1149499 non-null  int64         \n",
      " 8   dropoff_zone           1149499 non-null  int64         \n",
      " 9   payment_type           1149499 non-null  int64         \n",
      " 10  fare_amount            1149499 non-null  float64       \n",
      " 11  extra                  1149499 non-null  float64       \n",
      " 12  mta_tax                1149499 non-null  float64       \n",
      " 13  tip_amount             1149499 non-null  float64       \n",
      " 14  tolls_amount           1149499 non-null  float64       \n",
      " 15  improvement_surcharge  1149499 non-null  float64       \n",
      " 16  total_amount           1149499 non-null  float64       \n",
      " 17  congestion_surcharge   1149499 non-null  float64       \n",
      " 18  airport_fee            4 non-null        float64       \n",
      "dtypes: datetime64[us](2), float64(10), int32(2), int64(4), object(1)\n",
      "memory usage: 166.6+ MB\n"
     ]
    }
   ],
   "source": [
    "yellow_2021_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>pickup_zone</th>\n",
       "      <th>dropoff_zone</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:16:29</td>\n",
       "      <td>2021-01-01 00:24:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>224</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:12:29</td>\n",
       "      <td>2021-01-01 00:30:34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:26:12</td>\n",
       "      <td>2021-01-01 00:39:46</td>\n",
       "      <td>2</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>263</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:15:52</td>\n",
       "      <td>2021-01-01 00:38:07</td>\n",
       "      <td>3</td>\n",
       "      <td>6.11</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>164</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:10:46</td>\n",
       "      <td>2021-01-01 00:32:58</td>\n",
       "      <td>2</td>\n",
       "      <td>7.40</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>24.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>33.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:31:06</td>\n",
       "      <td>2021-01-01 00:38:52</td>\n",
       "      <td>5</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:42:11</td>\n",
       "      <td>2021-01-01 00:44:24</td>\n",
       "      <td>5</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>50</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VendorID     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
       "0          1 2021-01-01 00:30:10 2021-01-01 00:36:12                1   \n",
       "1          1 2021-01-01 00:51:20 2021-01-01 00:52:19                1   \n",
       "4          2 2021-01-01 00:31:49 2021-01-01 00:48:21                1   \n",
       "5          1 2021-01-01 00:16:29 2021-01-01 00:24:30                1   \n",
       "7          1 2021-01-01 00:12:29 2021-01-01 00:30:34                1   \n",
       "9          1 2021-01-01 00:26:12 2021-01-01 00:39:46                2   \n",
       "10         2 2021-01-01 00:15:52 2021-01-01 00:38:07                3   \n",
       "12         1 2021-01-01 00:10:46 2021-01-01 00:32:58                2   \n",
       "13         2 2021-01-01 00:31:06 2021-01-01 00:38:52                5   \n",
       "14         2 2021-01-01 00:42:11 2021-01-01 00:44:24                5   \n",
       "\n",
       "    trip_distance  RatecodeID store_and_fwd_flag  pickup_zone  dropoff_zone  \\\n",
       "0            2.10           1                  N          142            43   \n",
       "1            0.20           1                  N          238           151   \n",
       "4            4.94           1                  N           68            33   \n",
       "5            1.60           1                  N          224            68   \n",
       "7            5.70           1                  N           90            40   \n",
       "9            2.70           1                  N          263           142   \n",
       "10           6.11           1                  N          164           255   \n",
       "12           7.40           1                  N          138           166   \n",
       "13           1.70           1                  N          142            50   \n",
       "14           0.81           1                  N           50           142   \n",
       "\n",
       "    payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0              2          8.0    3.0      0.5        0.00          0.00   \n",
       "1              2          3.0    0.5      0.5        0.00          0.00   \n",
       "4              1         16.5    0.5      0.5        4.06          0.00   \n",
       "5              1          8.0    3.0      0.5        2.35          0.00   \n",
       "7              2         18.0    3.0      0.5        0.00          0.00   \n",
       "9              1         12.0    3.0      0.5        3.15          0.00   \n",
       "10             1         20.5    0.5      0.5        0.00          0.00   \n",
       "12             2         24.5    2.5      0.5        0.00          6.12   \n",
       "13             1          8.0    0.5      0.5        2.36          0.00   \n",
       "14             2          4.5    0.5      0.5        0.00          0.00   \n",
       "\n",
       "    improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                     0.3         11.80                   2.5          NaN  \n",
       "1                     0.3          4.30                   0.0          NaN  \n",
       "4                     0.3         24.36                   2.5          NaN  \n",
       "5                     0.3         14.15                   2.5          NaN  \n",
       "7                     0.3         21.80                   2.5          NaN  \n",
       "9                     0.3         18.95                   2.5          NaN  \n",
       "10                    0.3         24.30                   2.5          NaN  \n",
       "12                    0.3         33.92                   0.0          NaN  \n",
       "13                    0.3         14.16                   2.5          NaN  \n",
       "14                    0.3          8.30                   2.5          NaN  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellow_2021_01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_yellow_columns(df):\n",
    "    columns_to_drop = [\"VendorID\", \"trip_distance\", \"RatecodeID\", \"store_and_fwd_flag\", \"payment_type\", \n",
    "                       \"fare_amount\", \"extra\", \"mta_tax\", \"improvement_surcharge\", \"tip_amount\", \n",
    "                       \"tolls_amount\", \"total_amount\", \"congestion_surcharge\", \"airport_fee\"]\n",
    "    \n",
    "    # Drop only the columns that exist in the DataFrame\n",
    "    existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "    df.drop(columns=existing_columns_to_drop, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_2021_01 = drop_yellow_columns(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1149499 entries, 0 to 1271416\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count    Dtype         \n",
      "---  ------            --------------    -----         \n",
      " 0   pickup_datetime   1149499 non-null  datetime64[us]\n",
      " 1   dropoff_datetime  1149499 non-null  datetime64[us]\n",
      " 2   passenger_count   1149499 non-null  int32         \n",
      " 3   pickup_zone       1149499 non-null  int64         \n",
      " 4   dropoff_zone      1149499 non-null  int64         \n",
      "dtypes: datetime64[us](2), int32(1), int64(2)\n",
      "memory usage: 48.2 MB\n"
     ]
    }
   ],
   "source": [
    "yellow_2021_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_values(df):\n",
    "    \"\"\"\n",
    "    Drops any rows with missing values from the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to clean.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "        int: The number of rows that were dropped.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        initial_row_count = df.shape[0]\n",
    "        df = df.dropna()\n",
    "        final_row_count = df.shape[0]\n",
    "        rows_dropped = initial_row_count - final_row_count\n",
    "        print(f\"Number of rows dropped: {rows_dropped}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_zone</th>\n",
       "      <th>dropoff_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-01 00:16:29</td>\n",
       "      <td>2021-01-01 00:24:30</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-01 00:12:29</td>\n",
       "      <td>2021-01-01 00:30:34</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271412</th>\n",
       "      <td>2021-01-31 23:58:47</td>\n",
       "      <td>2021-02-01 00:04:40</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271413</th>\n",
       "      <td>2021-01-31 23:07:54</td>\n",
       "      <td>2021-01-31 23:19:42</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271414</th>\n",
       "      <td>2021-01-31 23:30:45</td>\n",
       "      <td>2021-01-31 23:35:13</td>\n",
       "      <td>1</td>\n",
       "      <td>233</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271415</th>\n",
       "      <td>2021-01-31 23:09:52</td>\n",
       "      <td>2021-01-31 23:51:56</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271416</th>\n",
       "      <td>2021-01-31 23:26:15</td>\n",
       "      <td>2021-01-31 23:33:48</td>\n",
       "      <td>2</td>\n",
       "      <td>230</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149499 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pickup_datetime    dropoff_datetime  passenger_count  pickup_zone  \\\n",
       "0       2021-01-01 00:30:10 2021-01-01 00:36:12                1          142   \n",
       "1       2021-01-01 00:51:20 2021-01-01 00:52:19                1          238   \n",
       "4       2021-01-01 00:31:49 2021-01-01 00:48:21                1           68   \n",
       "5       2021-01-01 00:16:29 2021-01-01 00:24:30                1          224   \n",
       "7       2021-01-01 00:12:29 2021-01-01 00:30:34                1           90   \n",
       "...                     ...                 ...              ...          ...   \n",
       "1271412 2021-01-31 23:58:47 2021-02-01 00:04:40                3           41   \n",
       "1271413 2021-01-31 23:07:54 2021-01-31 23:19:42                1          113   \n",
       "1271414 2021-01-31 23:30:45 2021-01-31 23:35:13                1          233   \n",
       "1271415 2021-01-31 23:09:52 2021-01-31 23:51:56                2           56   \n",
       "1271416 2021-01-31 23:26:15 2021-01-31 23:33:48                2          230   \n",
       "\n",
       "         dropoff_zone  \n",
       "0                  43  \n",
       "1                 151  \n",
       "4                  33  \n",
       "5                  68  \n",
       "7                  40  \n",
       "...               ...  \n",
       "1271412            74  \n",
       "1271413           141  \n",
       "1271414           237  \n",
       "1271415            68  \n",
       "1271416           229  \n",
       "\n",
       "[1149499 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_missing_values(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data (Columns) Kept:\n",
    "\n",
    "- https://www.nyc.gov/assets/tlc/images/content/pages/about/taxi_zone_map_manhattan.jpg\n",
    "\n",
    "- Yellow = pickup_datetime, dropoff_datetime, passenger_count, pickup_zone and dropoff_zone\n",
    "- https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf \n",
    "\n",
    "- Green = pickup_datetime, dropoff_datetime, passenger_count, pickup_zone, dropoff_zone\n",
    "- https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_green.pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp47350py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
