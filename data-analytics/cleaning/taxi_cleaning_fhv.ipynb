{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: DatetimeIndex(['2021-01-31', '2021-02-28', '2021-03-31', '2021-04-30',\n",
      "               '2021-05-31', '2021-06-30', '2021-07-31', '2021-08-31',\n",
      "               '2021-09-30', '2021-10-31', '2021-11-30', '2021-12-31',\n",
      "               '2022-01-31', '2022-02-28', '2022-03-31', '2022-04-30',\n",
      "               '2022-05-31', '2022-06-30', '2022-07-31', '2022-08-31',\n",
      "               '2022-09-30', '2022-10-31', '2022-11-30', '2022-12-31',\n",
      "               '2023-01-31', '2023-02-28', '2023-03-31', '2023-04-30',\n",
      "               '2023-05-31', '2023-06-30', '2023-07-31', '2023-08-31',\n",
      "               '2023-09-30', '2023-10-31', '2023-11-30', '2023-12-31',\n",
      "               '2024-01-31', '2024-02-29', '2024-03-31'],\n",
      "              dtype='datetime64[ns]', freq='ME')\n"
     ]
    }
   ],
   "source": [
    "date_range = pd.date_range(start='2021-01', end='2024-04', freq='ME')\n",
    "print(\"Date range:\", date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\n",
      "Files in directory c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets: ['combined_df.parquet', 'fhvhv_2021_01.parquet', 'fhvhv_2021_02.parquet', 'fhvhv_2021_03.parquet', 'fhvhv_2021_04.parquet', 'fhvhv_2021_05.parquet', 'fhvhv_2021_06.parquet', 'fhvhv_2021_07.parquet', 'fhvhv_2021_08.parquet', 'fhvhv_2021_09.parquet', 'fhvhv_2021_10.parquet', 'fhvhv_2021_11.parquet', 'fhvhv_2021_12.parquet', 'fhvhv_2022_01.parquet', 'fhvhv_2022_02.parquet', 'fhvhv_2022_03.parquet', 'fhvhv_2022_04.parquet', 'fhvhv_2022_05.parquet', 'fhvhv_2022_06.parquet', 'fhvhv_2022_07.parquet', 'fhvhv_2022_08.parquet', 'fhvhv_2022_09.parquet', 'fhvhv_2022_10.parquet', 'fhvhv_2022_11.parquet', 'fhvhv_2022_12.parquet', 'fhvhv_2023_01.parquet', 'fhvhv_2023_02.parquet', 'fhvhv_2023_03.parquet', 'fhvhv_2023_04.parquet', 'fhvhv_2023_05.parquet', 'fhvhv_2023_06.parquet', 'fhvhv_2023_07.parquet', 'fhvhv_2023_08.parquet', 'fhvhv_2023_09.parquet', 'fhvhv_2023_10.parquet', 'fhvhv_2023_11.parquet', 'fhvhv_2023_12.parquet', 'fhvhv_2024_01.parquet', 'fhvhv_2024_02.parquet', 'fhvhv_2024_03.parquet', 'fhv_2021_01.parquet', 'fhv_2021_02.parquet', 'fhv_2021_03.parquet', 'fhv_2021_04.parquet', 'fhv_2021_05.parquet', 'fhv_2021_06.parquet', 'fhv_2021_07.parquet', 'fhv_2021_08.parquet', 'fhv_2021_09.parquet', 'fhv_2021_10.parquet', 'fhv_2021_11.parquet', 'fhv_2021_12.parquet', 'fhv_2022_01.parquet', 'fhv_2022_02.parquet', 'fhv_2022_03.parquet', 'fhv_2022_04.parquet', 'fhv_2022_05.parquet', 'fhv_2022_06.parquet', 'fhv_2022_07.parquet', 'fhv_2022_08.parquet', 'fhv_2022_09.parquet', 'fhv_2022_10.parquet', 'fhv_2022_11.parquet', 'fhv_2022_12.parquet', 'fhv_2023_01.parquet', 'fhv_2023_02.parquet', 'fhv_2023_03.parquet', 'fhv_2023_04.parquet', 'fhv_2023_05.parquet', 'fhv_2023_06.parquet', 'fhv_2023_07.parquet', 'fhv_2023_08.parquet', 'fhv_2023_09.parquet', 'fhv_2023_10.parquet', 'fhv_2023_11.parquet', 'fhv_2023_12.parquet', 'fhv_2024_01.parquet', 'fhv_2024_02.parquet', 'fhv_2024_03.parquet', 'green_2021_01.parquet', 'green_2021_01_cleaned.parquet', 'green_2021_02.parquet', 'green_2021_02_cleaned.parquet', 'green_2021_03.parquet', 'green_2021_03_cleaned.parquet', 'green_2021_04.parquet', 'green_2021_04_cleaned.parquet', 'green_2021_05.parquet', 'green_2021_05_cleaned.parquet', 'green_2021_06.parquet', 'green_2021_06_cleaned.parquet', 'green_2021_07.parquet', 'green_2021_07_cleaned.parquet', 'green_2021_08.parquet', 'green_2021_08_cleaned.parquet', 'green_2021_09.parquet', 'green_2021_09_cleaned.parquet', 'green_2021_10.parquet', 'green_2021_10_cleaned.parquet', 'green_2021_11.parquet', 'green_2021_11_cleaned.parquet', 'green_2021_12.parquet', 'green_2021_12_cleaned.parquet', 'green_2022_01.parquet', 'green_2022_01_cleaned.parquet', 'green_2022_02.parquet', 'green_2022_02_cleaned.parquet', 'green_2022_03.parquet', 'green_2022_03_cleaned.parquet', 'green_2022_04.parquet', 'green_2022_04_cleaned.parquet', 'green_2022_05.parquet', 'green_2022_05_cleaned.parquet', 'green_2022_06.parquet', 'green_2022_06_cleaned.parquet', 'green_2022_07.parquet', 'green_2022_07_cleaned.parquet', 'green_2022_08.parquet', 'green_2022_08_cleaned.parquet', 'green_2022_09.parquet', 'green_2022_09_cleaned.parquet', 'green_2022_10.parquet', 'green_2022_10_cleaned.parquet', 'green_2022_11.parquet', 'green_2022_11_cleaned.parquet', 'green_2022_12.parquet', 'green_2022_12_cleaned.parquet', 'green_2023_01.parquet', 'green_2023_01_cleaned.parquet', 'green_2023_02.parquet', 'green_2023_02_cleaned.parquet', 'green_2023_03.parquet', 'green_2023_03_cleaned.parquet', 'green_2023_04.parquet', 'green_2023_04_cleaned.parquet', 'green_2023_05.parquet', 'green_2023_05_cleaned.parquet', 'green_2023_06.parquet', 'green_2023_06_cleaned.parquet', 'green_2023_07.parquet', 'green_2023_07_cleaned.parquet', 'green_2023_08.parquet', 'green_2023_08_cleaned.parquet', 'green_2023_09.parquet', 'green_2023_09_cleaned.parquet', 'green_2023_10.parquet', 'green_2023_10_cleaned.parquet', 'green_2023_11.parquet', 'green_2023_11_cleaned.parquet', 'green_2023_12.parquet', 'green_2023_12_cleaned.parquet', 'green_2024_01.parquet', 'green_2024_01_cleaned.parquet', 'green_2024_02.parquet', 'green_2024_02_cleaned.parquet', 'green_2024_03.parquet', 'green_2024_03_cleaned.parquet', 'green_final_cleaned.parquet', 'yellow_2021_01.parquet', 'yellow_2021_01_cleaned.parquet', 'yellow_2021_02.parquet', 'yellow_2021_02_cleaned.parquet', 'yellow_2021_03.parquet', 'yellow_2021_03_cleaned.parquet', 'yellow_2021_04.parquet', 'yellow_2021_04_cleaned.parquet', 'yellow_2021_05.parquet', 'yellow_2021_05_cleaned.parquet', 'yellow_2021_06.parquet', 'yellow_2021_06_cleaned.parquet', 'yellow_2021_07.parquet', 'yellow_2021_07_cleaned.parquet', 'yellow_2021_08.parquet', 'yellow_2021_08_cleaned.parquet', 'yellow_2021_09.parquet', 'yellow_2021_09_cleaned.parquet', 'yellow_2021_10.parquet', 'yellow_2021_10_cleaned.parquet', 'yellow_2021_11.parquet', 'yellow_2021_11_cleaned.parquet', 'yellow_2021_12.parquet', 'yellow_2021_12_cleaned.parquet', 'yellow_2022_01.parquet', 'yellow_2022_01_cleaned.parquet', 'yellow_2022_02.parquet', 'yellow_2022_02_cleaned.parquet', 'yellow_2022_03.parquet', 'yellow_2022_03_cleaned.parquet', 'yellow_2022_04.parquet', 'yellow_2022_04_cleaned.parquet', 'yellow_2022_05.parquet', 'yellow_2022_05_cleaned.parquet', 'yellow_2022_06.parquet', 'yellow_2022_06_cleaned.parquet', 'yellow_2022_07.parquet', 'yellow_2022_07_cleaned.parquet', 'yellow_2022_08.parquet', 'yellow_2022_08_cleaned.parquet', 'yellow_2022_09.parquet', 'yellow_2022_09_cleaned.parquet', 'yellow_2022_10.parquet', 'yellow_2022_10_cleaned.parquet', 'yellow_2022_11.parquet', 'yellow_2022_11_cleaned.parquet', 'yellow_2022_12.parquet', 'yellow_2022_12_cleaned.parquet', 'yellow_2023_01.parquet', 'yellow_2023_01_cleaned.parquet', 'yellow_2023_02.parquet', 'yellow_2023_02_cleaned.parquet', 'yellow_2023_03.parquet', 'yellow_2023_03_cleaned.parquet', 'yellow_2023_04.parquet', 'yellow_2023_04_cleaned.parquet', 'yellow_2023_05.parquet', 'yellow_2023_05_cleaned.parquet', 'yellow_2023_06.parquet', 'yellow_2023_06_cleaned.parquet', 'yellow_2023_07.parquet', 'yellow_2023_07_cleaned.parquet', 'yellow_2023_08.parquet', 'yellow_2023_08_cleaned.parquet', 'yellow_2023_09.parquet', 'yellow_2023_09_cleaned.parquet', 'yellow_2023_10.parquet', 'yellow_2023_10_cleaned.parquet', 'yellow_2023_11.parquet', 'yellow_2023_11_cleaned.parquet', 'yellow_2023_12.parquet', 'yellow_2023_12_cleaned.parquet', 'yellow_2024_01.parquet', 'yellow_2024_01_cleaned.parquet', 'yellow_2024_02.parquet', 'yellow_2024_02_cleaned.parquet', 'yellow_2024_03.parquet', 'yellow_2024_03_cleaned.parquet', 'yellow_final_cleaned.parquet']\n",
      "237\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(os.getcwd(), \"..\", \"Datasets\", \"taxi_parquets\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(data_dir):\n",
    "    print(f\"Directory {data_dir} does not exist\")\n",
    "else:\n",
    "    # List all files in the directory to check for existence and naming\n",
    "    all_files_in_dir = os.listdir(data_dir)\n",
    "    print(f\"Files in directory {data_dir}: {all_files_in_dir}\")\n",
    "    print(len(all_files_in_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_01*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_01*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_01.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_02*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_02*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_02.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_03*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_03*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_03.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_04*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_04*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_04.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_05*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_05*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_05.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_06*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_06*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_06.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_07*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_07*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_07.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_08*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_08*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_08.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_09*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_09*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_09.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_10*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_10*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_10.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_11*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_11*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_11.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_12*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_12*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_12.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_01*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_01*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_01.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_02*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_02*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_02.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_03*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_03*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_03.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_04*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_04*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_04.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_05*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_05*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_05.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_06*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_06*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_06.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_07*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_07*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_07.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_08*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_08*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_08.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_09*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_09*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_09.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_10*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_10*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_10.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_11*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_11*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_11.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_12*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2022_12*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_12.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_01*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_01*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_01.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_02*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_02*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_02.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_03*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_03*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_03.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_04*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_04*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_04.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_05*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_05*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_05.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_06*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_06*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_06.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_07*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_07*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_07.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_08*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_08*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_08.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_09*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_09*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_09.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_10*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_10*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_10.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_11*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_11*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_11.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_12*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2023_12*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_12.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2024_01*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2024_01*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2024_01.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2024_02*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2024_02*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2024_02.parquet']\n",
      "Searching for files with pattern: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2024_03*.parquet\n",
      "Files found for pattern c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2024_03*.parquet: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2024_03.parquet']\n",
      "All files found: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2021_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2022_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2023_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2024_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2024_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\..\\\\Datasets\\\\taxi_parquets\\\\fhv_2024_03.parquet']\n",
      "Number of files found: 39\n"
     ]
    }
   ],
   "source": [
    "all_files = []\n",
    "\n",
    "for date in date_range:\n",
    "    search_pattern = os.path.join(data_dir, f\"fhv_{date.strftime('%Y_%m')}*.parquet\")\n",
    "    print(f\"Searching for files with pattern: {search_pattern}\")\n",
    "    files = glob.glob(search_pattern)\n",
    "    if files:\n",
    "        print(f\"Files found for pattern {search_pattern}: {files}\")\n",
    "    all_files.extend(files)  # Add the found files to the list\n",
    "\n",
    "print(\"All files found:\", all_files)\n",
    "print(\"Number of files found:\", len(all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\n",
      "Data Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\n",
      "fhv_2021_01_path: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\fhv_2021_01.parquet\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(\"Current Working Directory:\", cwd)\n",
    "\n",
    "# Define the directory where the data is located relative to the current working directory\n",
    "print(\"Data Directory:\", data_dir)\n",
    "\n",
    "# Define the file paths relative to the data directory\n",
    "fhv_2021_01_path = os.path.join(data_dir, \"fhv_2021_01.parquet\")\n",
    "\n",
    "# Print the constructed file paths to verify\n",
    "print(\"fhv_2021_01_path:\", fhv_2021_01_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhv_2021_01 = pd.read_parquet(fhv_2021_01_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory path to save CSV files: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_other\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Save dataframes to CSVs, for alternative and efficient analysis\n",
    "Similar error catching as above\n",
    "\"\"\"\n",
    "\n",
    "directory_path = os.path.join(os.getcwd(), \"..\", \"Datasets\", \"taxi_other\")\n",
    "\n",
    "# Print target directory path (error catching)\n",
    "print(\"Directory path to save CSV files:\", directory_path)\n",
    "\n",
    "# Verify the directory exists\n",
    "if not os.path.isdir(directory_path):\n",
    "    raise OSError(f\"Directory does not exist: '{directory_path}'\")\n",
    "\n",
    "# Define file paths for each CSV\n",
    "fhv_file_path = os.path.join(directory_path, \"fhv_2021_01.csv\")\n",
    "\n",
    "# Save each dataframe to its respective CSV file\n",
    "fhv_2021_01.to_csv(fhv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:27:00</td>\n",
       "      <td>2021-01-01 00:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:50:00</td>\n",
       "      <td>2021-01-01 01:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-01-01 00:01:00</td>\n",
       "      <td>2021-01-01 01:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:13:09</td>\n",
       "      <td>2021-01-01 00:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:38:31</td>\n",
       "      <td>2021-01-01 00:53:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:59:02</td>\n",
       "      <td>2021-01-01 01:08:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:18:12</td>\n",
       "      <td>2021-01-01 00:30:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:36:15</td>\n",
       "      <td>2021-01-01 00:45:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:55:04</td>\n",
       "      <td>2021-01-01 01:13:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:48:40</td>\n",
       "      <td>2021-01-01 01:12:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID  \\\n",
       "0               B00009 2021-01-01 00:27:00 2021-01-01 00:44:00           NaN   \n",
       "1               B00009 2021-01-01 00:50:00 2021-01-01 01:07:00           NaN   \n",
       "2               B00013 2021-01-01 00:01:00 2021-01-01 01:51:00           NaN   \n",
       "3               B00037 2021-01-01 00:13:09 2021-01-01 00:21:26           NaN   \n",
       "4               B00037 2021-01-01 00:38:31 2021-01-01 00:53:44           NaN   \n",
       "5               B00037 2021-01-01 00:59:02 2021-01-01 01:08:05           NaN   \n",
       "6               B00037 2021-01-01 00:18:12 2021-01-01 00:30:04           NaN   \n",
       "7               B00037 2021-01-01 00:36:15 2021-01-01 00:45:08           NaN   \n",
       "8               B00037 2021-01-01 00:55:04 2021-01-01 01:13:02           NaN   \n",
       "9               B00037 2021-01-01 00:48:40 2021-01-01 01:12:02           NaN   \n",
       "\n",
       "   DOlocationID SR_Flag Affiliated_base_number  \n",
       "0           NaN    None                 B00009  \n",
       "1           NaN    None                 B00009  \n",
       "2           NaN    None                 B00013  \n",
       "3          72.0    None                 B00037  \n",
       "4          61.0    None                 B00037  \n",
       "5          71.0    None                 B00037  \n",
       "6          91.0    None                 B00037  \n",
       "7          39.0    None                 B00037  \n",
       "8          37.0    None                 B00037  \n",
       "9          39.0    None                 B00037  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhv_2021_01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1154112 entries, 0 to 1154111\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count    Dtype         \n",
      "---  ------                  --------------    -----         \n",
      " 0   dispatching_base_num    1154112 non-null  object        \n",
      " 1   pickup_datetime         1154112 non-null  datetime64[us]\n",
      " 2   dropOff_datetime        1154112 non-null  datetime64[us]\n",
      " 3   PUlocationID            195845 non-null   float64       \n",
      " 4   DOlocationID            991892 non-null   float64       \n",
      " 5   SR_Flag                 0 non-null        object        \n",
      " 6   Affiliated_base_number  1153227 non-null  object        \n",
      "dtypes: datetime64[us](2), float64(2), object(3)\n",
      "memory usage: 61.6+ MB\n"
     ]
    }
   ],
   "source": [
    "fhv_2021_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renaming_fhv_to_standard(dfs):\n",
    "    \"\"\" \n",
    "    Functions for renaming the columns of a dataset or list of datasets to standard names, which will ease the cleaning process\n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            df.rename(columns={\n",
    "                'dropOff_datetime': 'dropoff_datetime', \n",
    "                'PUlocationID': 'pickup_zone', \n",
    "                'DOlocationID': 'dropoff_zone'\n",
    "            }, inplace=True)\n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "\n",
    "renaming_fhv_to_standard(fhv_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows found:\n",
      "         dispatching_base_num     pickup_datetime    dropoff_datetime  \\\n",
      "8885                  B02037 2021-01-01 09:30:00 2021-01-01 09:45:00   \n",
      "9108                  B02832 2021-01-01 09:30:00 2021-01-01 10:00:00   \n",
      "9739                  B01336 2021-01-01 10:14:00 2021-01-01 10:38:00   \n",
      "9740                  B01336 2021-01-01 10:41:00 2021-01-01 11:05:00   \n",
      "9742                  B01336 2021-01-01 10:14:00 2021-01-01 10:38:00   \n",
      "...                      ...                 ...                 ...   \n",
      "1146526               B02819 2021-01-31 16:05:29 2021-01-31 16:16:31   \n",
      "1147295               B01280 2021-01-31 17:53:00 2021-01-31 18:17:00   \n",
      "1147362               B01336 2021-01-31 17:31:00 2021-01-31 17:55:00   \n",
      "1148728               B01336 2021-01-31 18:30:00 2021-01-31 18:54:00   \n",
      "1148804               B01466 2021-01-31 18:45:04 2021-01-31 19:21:27   \n",
      "\n",
      "         pickup_zone  dropoff_zone SR_Flag Affiliated_base_number  \n",
      "8885             NaN           NaN    None                         \n",
      "9108           264.0         264.0    None                 B02832  \n",
      "9739             NaN           NaN    None                 B01336  \n",
      "9740             NaN           NaN    None                 B01336  \n",
      "9742             NaN           NaN    None                 B01336  \n",
      "...              ...           ...     ...                    ...  \n",
      "1146526          NaN          89.0    None                 B02819  \n",
      "1147295          NaN           NaN    None                 B01280  \n",
      "1147362          NaN           NaN    None                 B01336  \n",
      "1148728          NaN           NaN    None                 B01336  \n",
      "1148804          NaN          76.0    None                 B01466  \n",
      "\n",
      "[2059 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "def duplicated_rows(dfs):\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            duplicate_rows = df[df.duplicated()]\n",
    "            if not duplicate_rows.empty:\n",
    "                print(\"Duplicate rows found:\\n\", duplicate_rows)\n",
    "            else:\n",
    "                print(\"No duplicate rows found\")\n",
    "duplicated_rows(fhv_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did anyone Time Travel?\n",
      "0\n",
      "No rows where time travel occurred.\n"
     ]
    }
   ],
   "source": [
    "def time_travel(dfs):    \n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            time_travel = df[df['pickup_datetime'] > df['dropoff_datetime']].shape[0]\n",
    "            print(\"Did anyone Time Travel?\")\n",
    "            print(time_travel)\n",
    "\n",
    "            # Find + print rows where pickup time is after dropoff time\n",
    "            time_travel_rows = df[df['pickup_datetime'] > df['dropoff_datetime']]\n",
    "            if not time_travel_rows.empty:\n",
    "                print(\"One of the rows where time travel occurred:\")\n",
    "                print(time_travel_rows.iloc[0])\n",
    "            else:\n",
    "                print(\"No rows where time travel occurred.\")            \n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "\n",
    "time_travel(fhv_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\n",
      "Taxi Zone CSV Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_other\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Working Directory:\", cwd)\n",
    "\n",
    "taxi_zone_dir = os.path.join(os.getcwd(), \"..\", \"Datasets\", \"taxi_other\")\n",
    "\n",
    "# Define the directory where the data is located relative to the current working directory\n",
    "print(\"Taxi Zone CSV Directory:\", taxi_zone_dir)\n",
    "\n",
    "# Define the file path relative to the data directory\n",
    "taxi_zone_path = os.path.join(cwd, taxi_zone_dir, \"taxi_zone_lookup.csv\")\n",
    "\n",
    "taxi_zone = pd.read_csv(taxi_zone_path, keep_default_na=True, delimiter=\",\", skipinitialspace=True, encoding=\"Windows-1252\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Zones: 69\n",
      "List of Unique Zones: [  4  12  13  24  41  42  43  45  48  50  68  74  75  79  87  88  90 100\n",
      " 103 104 105 107 113 114 116 120 125 127 128 137 140 141 142 143 144 148\n",
      " 151 152 153 158 161 162 163 164 166 170 186 194 202 209 211 224 229 230\n",
      " 231 232 233 234 236 237 238 239 243 244 246 249 261 262 263]\n"
     ]
    }
   ],
   "source": [
    "def get_manhattan_zones(df):\n",
    "    manhattan_df = df[df[\"Borough\"] == \"Manhattan\"]\n",
    "    unique_zones = manhattan_df[\"LocationID\"].unique()\n",
    "    print(f\"Number of Unique Zones: {len(unique_zones)}\")\n",
    "    print(\"List of Unique Zones:\", unique_zones)\n",
    "    return unique_zones\n",
    "manhattan_zones = get_manhattan_zones(taxi_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid zones count: 1010868\n",
      "Examples of rows with invalid zones:\n",
      "  dispatching_base_num     pickup_datetime    dropoff_datetime  pickup_zone  \\\n",
      "0               B00009 2021-01-01 00:27:00 2021-01-01 00:44:00          NaN   \n",
      "1               B00009 2021-01-01 00:50:00 2021-01-01 01:07:00          NaN   \n",
      "2               B00013 2021-01-01 00:01:00 2021-01-01 01:51:00          NaN   \n",
      "3               B00037 2021-01-01 00:13:09 2021-01-01 00:21:26          NaN   \n",
      "4               B00037 2021-01-01 00:38:31 2021-01-01 00:53:44          NaN   \n",
      "\n",
      "   dropoff_zone SR_Flag Affiliated_base_number  \n",
      "0           NaN    None                 B00009  \n",
      "1           NaN    None                 B00009  \n",
      "2           NaN    None                 B00013  \n",
      "3          72.0    None                 B00037  \n",
      "4          61.0    None                 B00037  \n"
     ]
    }
   ],
   "source": [
    "# Define the function to check pickup and dropoff zones\n",
    "def check_zones(df, manhattan_zones):\n",
    "    # Check if both pickup_zone and dropoff_zone are not in manhattan_zones\n",
    "    invalid_zones = df[~df[\"pickup_zone\"].isin(manhattan_zones) & ~df[\"dropoff_zone\"].isin(manhattan_zones)]\n",
    "    \n",
    "    print(f\"Invalid zones count: {invalid_zones.shape[0]}\")\n",
    "    \n",
    "    if not invalid_zones.empty:\n",
    "        print(\"Examples of rows with invalid zones:\")\n",
    "        print(invalid_zones.head())  # Print first few invalid rows\n",
    "\n",
    "check_zones(fhv_2021_01, manhattan_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Zones: 69\n",
      "List of Unique Zones: [  4  12  13  24  41  42  43  45  48  50  68  74  75  79  87  88  90 100\n",
      " 103 104 105 107 113 114 116 120 125 127 128 137 140 141 142 143 144 148\n",
      " 151 152 153 158 161 162 163 164 166 170 186 194 202 209 211 224 229 230\n",
      " 231 232 233 234 236 237 238 239 243 244 246 249 261 262 263]\n",
      "Invalid Rows Borough Counts:\n",
      "Borough_combined\n",
      "Queens (pickup), Queens (dropoff)                  51029\n",
      "Staten Island (pickup), Staten Island (dropoff)    27109\n",
      "Bronx (pickup), Bronx (dropoff)                    25402\n",
      "Brooklyn (pickup), Brooklyn (dropoff)              24421\n",
      "Queens (pickup), Brooklyn (dropoff)                 2409\n",
      "Bronx (pickup), Brooklyn (dropoff)                  2245\n",
      "Brooklyn (pickup), Bronx (dropoff)                  2235\n",
      "Brooklyn (pickup), Queens (dropoff)                 2110\n",
      "Queens (pickup), Bronx (dropoff)                     919\n",
      "Bronx (pickup), Queens (dropoff)                     818\n",
      "Unknown (pickup), Unknown (dropoff)                  498\n",
      "Staten Island (pickup), Brooklyn (dropoff)           445\n",
      "Brooklyn (pickup), Staten Island (dropoff)           348\n",
      "Staten Island (pickup), Bronx (dropoff)              140\n",
      "Bronx (pickup), Staten Island (dropoff)              127\n",
      "Staten Island (pickup), Queens (dropoff)              71\n",
      "Staten Island (pickup), EWR (dropoff)                 69\n",
      "Queens (pickup), EWR (dropoff)                        65\n",
      "Queens (pickup), Staten Island (dropoff)              41\n",
      "Brooklyn (pickup), EWR (dropoff)                      32\n",
      "EWR (pickup), Staten Island (dropoff)                 15\n",
      "EWR (pickup), Brooklyn (dropoff)                      11\n",
      "Unknown (pickup), Queens (dropoff)                    10\n",
      "Bronx (pickup), Unknown (dropoff)                      6\n",
      "Unknown (pickup), Bronx (dropoff)                      6\n",
      "Unknown (pickup), Brooklyn (dropoff)                   3\n",
      "EWR (pickup), Queens (dropoff)                         2\n",
      "Queens (pickup), Unknown (dropoff)                     2\n",
      "EWR (pickup), Bronx (dropoff)                          1\n",
      "EWR (pickup), EWR (dropoff)                            1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def verifying_invalid_zones(df, manhattan_zones, taxi_zone_csv):\n",
    "    # Identify invalid rows where both pickup_zone and dropoff_zone are not in manhattan_zones\n",
    "    invalid_zones = df[~df[\"pickup_zone\"].isin(manhattan_zones) & ~df[\"dropoff_zone\"].isin(manhattan_zones)]\n",
    "    \n",
    "    # If there are no invalid rows, print and return\n",
    "    if invalid_zones.empty:\n",
    "        print(\"No invalid zones found.\")\n",
    "        return\n",
    "    \n",
    "    # Merge invalid zones with taxi_zone_csv to get borough information for both pickup_zone and dropoff_zone\n",
    "    invalid_zones_merged = invalid_zones.merge(taxi_zone_csv, left_on=\"pickup_zone\", right_on=\"LocationID\", how=\"left\", suffixes=('_pickup', '_dropoff'))\n",
    "    invalid_zones_merged = invalid_zones_merged.merge(taxi_zone_csv, left_on=\"dropoff_zone\", right_on=\"LocationID\", how=\"left\", suffixes=('_pickup', '_dropoff'))\n",
    "\n",
    "    # Concatenate Borough columns for analysis\n",
    "    invalid_zones_merged[\"Borough_combined\"] = invalid_zones_merged[\"Borough_pickup\"] + \" (pickup), \" + invalid_zones_merged[\"Borough_dropoff\"] + \" (dropoff)\"\n",
    "    \n",
    "    # Count the combined Borough information\n",
    "    combined_borough_counts = invalid_zones_merged[\"Borough_combined\"].value_counts()\n",
    "\n",
    "    print(\"Invalid Rows Borough Counts:\")\n",
    "    print(combined_borough_counts)\n",
    "\n",
    "manhattan_zones = get_manhattan_zones(taxi_zone)\n",
    "\n",
    "# Call the verifying_invalid_zones function\n",
    "verifying_invalid_zones(fhv_2021_01, manhattan_zones, taxi_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_fhv_invalid_rows(dfs, manhattan_zones, taxi_zone_csv):\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "\n",
    "    cleaned_dfs = []\n",
    "    \n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            # Drop duplicate rows\n",
    "            df = df.drop_duplicates()\n",
    "            \n",
    "            # Drop rows where pickup_datetime == dropoff_datetime\n",
    "            df = df[df[\"pickup_datetime\"] != df[\"dropoff_datetime\"]]\n",
    "            \n",
    "            # Drop rows where both pickup_zone and dropoff_zone are not Manhattan zones\n",
    "            df = df[df[\"pickup_zone\"].isin(manhattan_zones) | df[\"dropoff_zone\"].isin(manhattan_zones)]\n",
    "            \n",
    "            # Append the cleaned DataFrame to the list\n",
    "            cleaned_dfs.append(df)\n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "    \n",
    "    # Return the cleaned DataFrame(s)\n",
    "    if len(cleaned_dfs) == 1:\n",
    "        return cleaned_dfs[0]\n",
    "    else:\n",
    "        return cleaned_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the verifying_invalid_zones function\n",
    "fhv_2021_01 = drop_fhv_invalid_rows(fhv_2021_01, manhattan_zones, taxi_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 142953 entries, 39 to 1154089\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   dispatching_base_num    142953 non-null  object        \n",
      " 1   pickup_datetime         142953 non-null  datetime64[us]\n",
      " 2   dropoff_datetime        142953 non-null  datetime64[us]\n",
      " 3   pickup_zone             38571 non-null   float64       \n",
      " 4   dropoff_zone            142916 non-null  float64       \n",
      " 5   SR_Flag                 0 non-null       object        \n",
      " 6   Affiliated_base_number  142953 non-null  object        \n",
      "dtypes: datetime64[us](2), float64(2), object(3)\n",
      "memory usage: 8.7+ MB\n"
     ]
    }
   ],
   "source": [
    "fhv_2021_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_zone</th>\n",
       "      <th>dropoff_zone</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>B00254</td>\n",
       "      <td>2021-01-01 00:21:20</td>\n",
       "      <td>2021-01-01 00:27:33</td>\n",
       "      <td>236.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>B00310</td>\n",
       "      <td>2021-01-01 00:41:04</td>\n",
       "      <td>2021-01-01 00:59:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B02864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>B00310</td>\n",
       "      <td>2021-01-01 00:08:50</td>\n",
       "      <td>2021-01-01 00:21:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B02880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>B00457</td>\n",
       "      <td>2021-01-01 00:54:39</td>\n",
       "      <td>2021-01-01 01:11:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>B00628</td>\n",
       "      <td>2021-01-01 00:38:23</td>\n",
       "      <td>2021-01-01 00:43:45</td>\n",
       "      <td>143.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>B00647</td>\n",
       "      <td>2021-01-01 00:54:43</td>\n",
       "      <td>2021-01-01 01:10:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>244.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>B00647</td>\n",
       "      <td>2021-01-01 00:22:25</td>\n",
       "      <td>2021-01-01 00:42:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>B00823</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>2021-01-01 00:37:22</td>\n",
       "      <td>166.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B02207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>B00856</td>\n",
       "      <td>2021-01-01 00:07:29</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B02879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>B00856</td>\n",
       "      <td>2021-01-01 00:26:25</td>\n",
       "      <td>2021-01-01 01:08:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B02872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dispatching_base_num     pickup_datetime    dropoff_datetime  pickup_zone  \\\n",
       "39                B00254 2021-01-01 00:21:20 2021-01-01 00:27:33        236.0   \n",
       "62                B00310 2021-01-01 00:41:04 2021-01-01 00:59:09          NaN   \n",
       "69                B00310 2021-01-01 00:08:50 2021-01-01 00:21:46          NaN   \n",
       "94                B00457 2021-01-01 00:54:39 2021-01-01 01:11:46          NaN   \n",
       "104               B00628 2021-01-01 00:38:23 2021-01-01 00:43:45        143.0   \n",
       "112               B00647 2021-01-01 00:54:43 2021-01-01 01:10:12          NaN   \n",
       "114               B00647 2021-01-01 00:22:25 2021-01-01 00:42:44          NaN   \n",
       "157               B00823 2021-01-01 00:00:00 2021-01-01 00:37:22        166.0   \n",
       "194               B00856 2021-01-01 00:07:29 2021-01-01 00:30:10          NaN   \n",
       "199               B00856 2021-01-01 00:26:25 2021-01-01 01:08:15          NaN   \n",
       "\n",
       "     dropoff_zone SR_Flag Affiliated_base_number  \n",
       "39          237.0    None                 B00254  \n",
       "62           42.0    None                 B02864  \n",
       "69          127.0    None                 B02880  \n",
       "94           42.0    None                 B00457  \n",
       "104         142.0    None                 B00628  \n",
       "112         244.0    None                 B00647  \n",
       "114         116.0    None                 B00647  \n",
       "157         228.0    None                 B02207  \n",
       "194         232.0    None                 B02879  \n",
       "199         152.0    None                 B02872  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhv_2021_01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_zone</th>\n",
       "      <th>dropoff_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2021-01-01 00:21:20</td>\n",
       "      <td>2021-01-01 00:27:33</td>\n",
       "      <td>236.0</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2021-01-01 00:41:04</td>\n",
       "      <td>2021-01-01 00:59:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2021-01-01 00:08:50</td>\n",
       "      <td>2021-01-01 00:21:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2021-01-01 00:54:39</td>\n",
       "      <td>2021-01-01 01:11:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2021-01-01 00:38:23</td>\n",
       "      <td>2021-01-01 00:43:45</td>\n",
       "      <td>143.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154058</th>\n",
       "      <td>2021-01-31 23:40:54</td>\n",
       "      <td>2021-02-01 00:05:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154060</th>\n",
       "      <td>2021-01-31 23:04:57</td>\n",
       "      <td>2021-01-31 23:17:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154065</th>\n",
       "      <td>2021-01-31 23:09:23</td>\n",
       "      <td>2021-01-31 23:37:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154088</th>\n",
       "      <td>2021-01-31 23:43:47</td>\n",
       "      <td>2021-01-31 23:52:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154089</th>\n",
       "      <td>2021-01-31 23:58:30</td>\n",
       "      <td>2021-02-01 00:04:22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142953 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pickup_datetime    dropoff_datetime  pickup_zone  dropoff_zone\n",
       "39      2021-01-01 00:21:20 2021-01-01 00:27:33        236.0         237.0\n",
       "62      2021-01-01 00:41:04 2021-01-01 00:59:09          NaN          42.0\n",
       "69      2021-01-01 00:08:50 2021-01-01 00:21:46          NaN         127.0\n",
       "94      2021-01-01 00:54:39 2021-01-01 01:11:46          NaN          42.0\n",
       "104     2021-01-01 00:38:23 2021-01-01 00:43:45        143.0         142.0\n",
       "...                     ...                 ...          ...           ...\n",
       "1154058 2021-01-31 23:40:54 2021-02-01 00:05:53          NaN          74.0\n",
       "1154060 2021-01-31 23:04:57 2021-01-31 23:17:54          NaN          74.0\n",
       "1154065 2021-01-31 23:09:23 2021-01-31 23:37:16          NaN         246.0\n",
       "1154088 2021-01-31 23:43:47 2021-01-31 23:52:18          NaN          74.0\n",
       "1154089 2021-01-31 23:58:30 2021-02-01 00:04:22          NaN          74.0\n",
       "\n",
       "[142953 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_fhv_columns(df):\n",
    "    columns_to_drop = [\"SR_Flag\", \"dispatching_base_num\", \"Affiliated_base_number\"]\n",
    "    \n",
    "    # Drop only the columns that exist in the DataFrame\n",
    "    existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "    df.drop(columns=existing_columns_to_drop, inplace=True)\n",
    "\n",
    "    # Return the modified DataFrame\n",
    "    return df\n",
    "\n",
    "drop_fhv_columns(fhv_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 142953 entries, 39 to 1154089\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   pickup_datetime   142953 non-null  datetime64[us]\n",
      " 1   dropoff_datetime  142953 non-null  datetime64[us]\n",
      " 2   pickup_zone       38571 non-null   float64       \n",
      " 3   dropoff_zone      142916 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(2)\n",
      "memory usage: 5.5 MB\n"
     ]
    }
   ],
   "source": [
    "fhv_2021_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zone_busy(yellow_df):\n",
    "    # Combine pickup and dropoff data into a single DataFrame; Renamed and combined into a single datetime column\n",
    "    pickup_data = yellow_df[['pickup_datetime', 'passenger_count', 'pickup_zone']].rename(columns={'pickup_datetime': 'datetime', 'pickup_zone': 'zone'})\n",
    "    dropoff_data = yellow_df[['dropoff_datetime', 'passenger_count', 'dropoff_zone']].rename(columns={'dropoff_datetime': 'datetime', 'dropoff_zone': 'zone'})\n",
    "    combined_data = pd.concat([pickup_data, dropoff_data])\n",
    "    \n",
    "    # Round datetime to the nearest hour\n",
    "    combined_data['datetime'] = combined_data['datetime'].dt.round('h')\n",
    "    \n",
    "    # Group by hour and zone, summing passenger counts\n",
    "    zone_busy_df = combined_data.groupby(['datetime', 'zone'])['passenger_count'].sum().reset_index()\n",
    "    \n",
    "    return zone_busy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['passenger_count'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcalculate_zone_busy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfhv_2021_01\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[69], line 3\u001b[0m, in \u001b[0;36mcalculate_zone_busy\u001b[1;34m(yellow_df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_zone_busy\u001b[39m(yellow_df):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Combine pickup and dropoff data into a single DataFrame; Renamed and combined into a single datetime column\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     pickup_data \u001b[38;5;241m=\u001b[39m \u001b[43myellow_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpickup_datetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpassenger_count\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpickup_zone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_zone\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzone\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      4\u001b[0m     dropoff_data \u001b[38;5;241m=\u001b[39m yellow_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropoff_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassenger_count\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropoff_zone\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropoff_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropoff_zone\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzone\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      5\u001b[0m     combined_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pickup_data, dropoff_data])\n",
      "File \u001b[1;32mc:\\Users\\35385\\anaconda3\\envs\\comp47350py311\\Lib\\site-packages\\pandas\\core\\frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\35385\\anaconda3\\envs\\comp47350py311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\35385\\anaconda3\\envs\\comp47350py311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['passenger_count'] not in index\""
     ]
    }
   ],
   "source": [
    "calculate_zone_busy(fhv_2021_01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp47350py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
