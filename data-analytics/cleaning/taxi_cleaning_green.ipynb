{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "File for Cleaning Taxi Data of the Green Taxis.\n",
    "Begin by loading 1 parquet file as pandas dataframe.\n",
    "Look at each the dataframe, as a csv and through python\n",
    "Implement Crisp-DM data cleaning methodology -> Data Quality Report, Data Quality Plan\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found: []\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(os.getcwd(), \"Datasets/taxi_parquets\")\n",
    "all_files = glob.glob(os.path.join(data_dir, \"*.parquet\"))\n",
    "print(\"All files found:\", all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path for green_2021_01: /data-analytics/Datasets/taxi_parquets/green_2021_01.parquet\n"
     ]
    }
   ],
   "source": [
    "print(\"File path for green_2021_01:\", r\"/data-analytics/Datasets/taxi_parquets/green_2021_01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\n",
      "Data Directory: Datasets/taxi_parquets\n",
      "green_2021_01_path: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\Datasets/taxi_parquets\\green_2021_01.parquet\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Begin by loading 1 parquet file as pandas dataframe from each of the 4 TLC genres.\n",
    "Error catching across OSes implemented: cwd, data directory, paths etc.\n",
    "\"\"\"\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(\"Current Working Directory:\", cwd)\n",
    "\n",
    "# Define the directory where the data is located relative to the current working directory\n",
    "data_dir = \"Datasets/taxi_parquets\"\n",
    "print(\"Data Directory:\", data_dir)\n",
    "\n",
    "# Define the file paths relative to the data directory\n",
    "green_2021_01_path = os.path.join(cwd, data_dir, \"green_2021_01.parquet\")\n",
    "\n",
    "print(\"green_2021_01_path:\", green_2021_01_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\Datasets/taxi_parquets\\\\green_2021_01.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m green_2021_01 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgreen_2021_01_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpyarrow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\35385\\anaconda3\\envs\\comp47350py311\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\35385\\anaconda3\\envs\\comp47350py311\\Lib\\site-packages\\pandas\\io\\parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    275\u001b[0m         path_or_handle,\n\u001b[0;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    280\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\35385\\anaconda3\\envs\\comp47350py311\\Lib\\site-packages\\pandas\\io\\parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\35385\\anaconda3\\envs\\comp47350py311\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\cleaning\\\\Datasets/taxi_parquets\\\\green_2021_01.parquet'"
     ]
    }
   ],
   "source": [
    "green_2021_01 = pd.read_parquet(green_2021_01_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory path to save CSV files: Datasets\\taxi_other\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Save dataframe to CSV, for alternative and efficient analysis\n",
    "\"\"\"\n",
    "\n",
    "directory_path = os.path.join(\"Datasets\", \"taxi_other\")\n",
    "\n",
    "# Print target directory path (error catching)\n",
    "print(\"Directory path to save CSV files:\", directory_path)\n",
    "\n",
    "# Verify the directory exists\n",
    "if not os.path.isdir(directory_path):\n",
    "    raise OSError(f\"Directory does not exist: '{directory_path}'\")\n",
    "\n",
    "green_file_path = os.path.join(directory_path, \"green_2021_01.csv\")\n",
    "\n",
    "green_2021_01.to_csv(green_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_2021_01 = pd.read_parquet(green_2021_01_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:15:56</td>\n",
       "      <td>2021-01-01 00:19:52</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:25:59</td>\n",
       "      <td>2021-01-01 00:34:44</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:45:57</td>\n",
       "      <td>2021-01-01 00:51:55</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-12-31 23:57:51</td>\n",
       "      <td>2021-01-01 00:04:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:16:36</td>\n",
       "      <td>2021-01-01 00:16:40</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-52.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:16:36</td>\n",
       "      <td>2021-01-01 00:16:40</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>52.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:19:14</td>\n",
       "      <td>2021-01-01 00:19:21</td>\n",
       "      <td>N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>216.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:26:31</td>\n",
       "      <td>2021-01-01 00:28:50</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:57:46</td>\n",
       "      <td>2021-01-01 00:57:57</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:58:32</td>\n",
       "      <td>2021-01-01 01:32:34</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225</td>\n",
       "      <td>265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.19</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>42.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2021-01-01 00:15:56   2021-01-01 00:19:52                  N   \n",
       "1         2  2021-01-01 00:25:59   2021-01-01 00:34:44                  N   \n",
       "2         2  2021-01-01 00:45:57   2021-01-01 00:51:55                  N   \n",
       "3         2  2020-12-31 23:57:51   2021-01-01 00:04:56                  N   \n",
       "4         2  2021-01-01 00:16:36   2021-01-01 00:16:40                  N   \n",
       "5         2  2021-01-01 00:16:36   2021-01-01 00:16:40                  N   \n",
       "6         2  2021-01-01 00:19:14   2021-01-01 00:19:21                  N   \n",
       "7         2  2021-01-01 00:26:31   2021-01-01 00:28:50                  N   \n",
       "8         2  2021-01-01 00:57:46   2021-01-01 00:57:57                  N   \n",
       "9         2  2021-01-01 00:58:32   2021-01-01 01:32:34                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0         1.0            43           151              1.0           1.01   \n",
       "1         1.0           166           239              1.0           2.53   \n",
       "2         1.0            41            42              1.0           1.12   \n",
       "3         1.0           168            75              1.0           1.99   \n",
       "4         2.0           265           265              3.0           0.00   \n",
       "5         2.0           265           265              3.0           0.00   \n",
       "6         5.0           265           265              1.0           0.00   \n",
       "7         1.0            75            75              6.0           0.45   \n",
       "8         1.0           225           225              1.0           0.00   \n",
       "9         1.0           225           265              1.0          12.19   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount ehail_fee  \\\n",
       "0          5.5    0.5      0.5        0.00           0.0      None   \n",
       "1         10.0    0.5      0.5        2.81           0.0      None   \n",
       "2          6.0    0.5      0.5        1.00           0.0      None   \n",
       "3          8.0    0.5      0.5        0.00           0.0      None   \n",
       "4        -52.0    0.0     -0.5        0.00           0.0      None   \n",
       "5         52.0    0.0      0.5        0.00           0.0      None   \n",
       "6        180.0    0.0      0.0       36.06           0.0      None   \n",
       "7          3.5    0.5      0.5        0.96           0.0      None   \n",
       "8          2.5    0.5      0.5        0.00           0.0      None   \n",
       "9         38.0    0.5      0.5        2.75           0.0      None   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.3          6.80           2.0        1.0   \n",
       "1                    0.3         16.86           1.0        1.0   \n",
       "2                    0.3          8.30           1.0        1.0   \n",
       "3                    0.3          9.30           2.0        1.0   \n",
       "4                   -0.3        -52.80           3.0        1.0   \n",
       "5                    0.3         52.80           2.0        1.0   \n",
       "6                    0.3        216.36           1.0        2.0   \n",
       "7                    0.3          5.76           1.0        1.0   \n",
       "8                    0.3          3.80           2.0        1.0   \n",
       "9                    0.3         42.05           1.0        1.0   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                  0.00  \n",
       "1                  2.75  \n",
       "2                  0.00  \n",
       "3                  0.00  \n",
       "4                  0.00  \n",
       "5                  0.00  \n",
       "6                  0.00  \n",
       "7                  0.00  \n",
       "8                  0.00  \n",
       "9                  0.00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_2021_01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76518 entries, 0 to 76517\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               76518 non-null  int64         \n",
      " 1   lpep_pickup_datetime   76518 non-null  datetime64[us]\n",
      " 2   lpep_dropoff_datetime  76518 non-null  datetime64[us]\n",
      " 3   store_and_fwd_flag     40471 non-null  object        \n",
      " 4   RatecodeID             40471 non-null  float64       \n",
      " 5   PULocationID           76518 non-null  int64         \n",
      " 6   DOLocationID           76518 non-null  int64         \n",
      " 7   passenger_count        40471 non-null  float64       \n",
      " 8   trip_distance          76518 non-null  float64       \n",
      " 9   fare_amount            76518 non-null  float64       \n",
      " 10  extra                  76518 non-null  float64       \n",
      " 11  mta_tax                76518 non-null  float64       \n",
      " 12  tip_amount             76518 non-null  float64       \n",
      " 13  tolls_amount           76518 non-null  float64       \n",
      " 14  ehail_fee              0 non-null      object        \n",
      " 15  improvement_surcharge  76518 non-null  float64       \n",
      " 16  total_amount           76518 non-null  float64       \n",
      " 17  payment_type           40471 non-null  float64       \n",
      " 18  trip_type              40471 non-null  float64       \n",
      " 19  congestion_surcharge   40471 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(13), int64(3), object(2)\n",
      "memory usage: 11.7+ MB\n"
     ]
    }
   ],
   "source": [
    "green_2021_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renaming_green_to_standard(dfs):\n",
    "    \"\"\" \n",
    "    Functions for renaming the columns of a dataset or list of datasets to standard names, which will ease the cleaning process\n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            df.rename(columns={\n",
    "                'lpep_pickup_datetime': 'pickup_datetime', \n",
    "                'lpep_dropoff_datetime': 'dropoff_datetime', \n",
    "                'PULocationID': 'pickup_zone', \n",
    "                'DOLocationID': 'dropoff_zone'\n",
    "            }, inplace=True)\n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming_green_to_standard(green_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_float_to_int(dfs):\n",
    "    \"\"\" \n",
    "    Function for converting datatypes of specific columns of a DataFrame or list of DataFrames to appropriate types.\n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            if \"RatecodeID\" in df.columns:\n",
    "                df[\"RatecodeID\"] = df[\"RatecodeID\"].fillna(0).astype(\"int\")\n",
    "            if \"passenger_count\" in df.columns:\n",
    "                df[\"passenger_count\"] = df[\"passenger_count\"].fillna(0).astype(\"int\")\n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_float_to_int(green_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate rows found\n"
     ]
    }
   ],
   "source": [
    "def duplicated_rows(dfs):\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            duplicate_rows = df[df.duplicated()]\n",
    "            if not duplicate_rows.empty:\n",
    "                print(\"Duplicate rows found:\\n\", duplicate_rows)\n",
    "            else:\n",
    "                print(\"No duplicate rows found\")\n",
    "\n",
    "duplicated_rows(green_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def passenger_counts(df):\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        passenger_count_counts = df['passenger_count'].value_counts()\n",
    "        if not passenger_count_counts.empty:\n",
    "            print(\"Count for each unique value in 'passenger_count' column: in\")\n",
    "            print(passenger_count_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_counts(green_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_invalid_fares(dfs):\n",
    "    \"\"\"\n",
    "    Count rows where any fare-related column has an invalid value.\n",
    "    \n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "\n",
    "    # Columns to check for invalid fare amounts, <= 0; Need a fare for a valid trip\n",
    "            fare_columns = ['fare_amount', 'total_amount']\n",
    "\n",
    "    # Additional columns to check for negative values, < 0 as \"0\" is a valid value\n",
    "            additional_fare_columns = ['extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge']\n",
    "\n",
    "    # Count rows where any fare-related column has an invalid value\n",
    "            invalid_fare_counts = df[\n",
    "                (df[fare_columns] <= 0).any(axis=1) | \n",
    "                (df[additional_fare_columns] < 0).any(axis=1)].shape[0]\n",
    "            print(\"Number of rows with invalid fares: \", invalid_fare_counts)\n",
    "\n",
    "            # Find + print rows where with invalid fares\n",
    "            invalid_fare_rows = df[\n",
    "            (df[fare_columns] <= 0).any(axis=1) |\n",
    "            (df[additional_fare_columns] < 0).any(axis=1)]\n",
    "\n",
    "            # Print 5 sample rows with invalid fares\n",
    "            sample_rows = invalid_fare_rows.sample(n=5, random_state=42)\n",
    "            print(\"5 Sample Rows with Invalid Fares:\")\n",
    "            print(sample_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_invalid_fares(green_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did anyone Time Travel?\n",
      "0\n",
      "No rows where time travel occurred.\n"
     ]
    }
   ],
   "source": [
    "def time_travel(dfs):    \n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            time_travel = df[df['pickup_datetime'] > df['dropoff_datetime']].shape[0]\n",
    "            print(\"Did anyone Time Travel?\")\n",
    "            print(time_travel)\n",
    "\n",
    "            # Find + print rows where pickup time is after dropoff time\n",
    "            time_travel_rows = df[df['pickup_datetime'] > df['dropoff_datetime']]\n",
    "            if not time_travel_rows.empty:\n",
    "                print(\"One of the rows where time travel occurred:\")\n",
    "                print(time_travel_rows.iloc[0])\n",
    "            else:\n",
    "                print(\"No rows where time travel occurred.\")            \n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "\n",
    "time_travel(green_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travelling no distances?\n",
      "2553\n",
      "One of the rows of the immovable objects:\n",
      "VendorID                                   1\n",
      "pickup_datetime          2021-01-01 04:24:35\n",
      "dropoff_datetime         2021-01-01 04:33:20\n",
      "store_and_fwd_flag                         N\n",
      "RatecodeID                                 1\n",
      "pickup_zone                              248\n",
      "dropoff_zone                             169\n",
      "passenger_count                            1\n",
      "trip_distance                            0.0\n",
      "fare_amount                             17.2\n",
      "extra                                    0.0\n",
      "mta_tax                                  0.5\n",
      "tip_amount                               0.0\n",
      "tolls_amount                             0.0\n",
      "ehail_fee                               None\n",
      "improvement_surcharge                    0.3\n",
      "total_amount                            18.0\n",
      "payment_type                             1.0\n",
      "trip_type                                1.0\n",
      "congestion_surcharge                     0.0\n",
      "Name: 94, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def immovable_objects(dfs):    \n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            negative_distances = df[df['trip_distance'] <= 0].shape[0]\n",
    "            print(\"Travelling no distances?\")\n",
    "            print(negative_distances)\n",
    "\n",
    "            # Find + print rows where pickup time is after dropoff time\n",
    "            negative_distances_rows = df[df['trip_distance'] <= 0]\n",
    "            if not negative_distances_rows.empty:\n",
    "                print(\"One of the rows of the immovable objects:\")\n",
    "                print(negative_distances_rows.iloc[19]) #change this number for other examples\n",
    "            else:\n",
    "                print(\"No rows where time travel occurred.\")\n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "\n",
    "immovable_objects(green_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with payment_type 4 (Dispute): 79\n",
      "5 Sample Rows with payment_type 4 (Dispute):\n",
      "       VendorID     pickup_datetime    dropoff_datetime store_and_fwd_flag  \\\n",
      "17697         2 2021-01-14 15:42:42 2021-01-14 15:43:23                  N   \n",
      "433           1 2021-01-01 16:03:43 2021-01-01 16:13:37                  N   \n",
      "15814         1 2021-01-13 11:16:16 2021-01-13 11:34:36                  N   \n",
      "17708         1 2021-01-14 15:04:16 2021-01-14 15:10:23                  N   \n",
      "13498         2 2021-01-11 18:16:50 2021-01-11 18:17:24                  N   \n",
      "\n",
      "       RatecodeID  pickup_zone  dropoff_zone  passenger_count  trip_distance  \\\n",
      "17697           1          244           244                1           0.04   \n",
      "433             1          152            41                1           1.60   \n",
      "15814           1          244           241                1           4.40   \n",
      "17708           5          166           166                1           0.80   \n",
      "13498           1           75           236                1           0.00   \n",
      "\n",
      "       fare_amount  extra  mta_tax  tip_amount  tolls_amount ehail_fee  \\\n",
      "17697         -2.5    0.0     -0.5         0.0           0.0      None   \n",
      "433            9.0    0.0      0.5         0.0           0.0      None   \n",
      "15814         16.5    0.0      0.5         0.0           0.0      None   \n",
      "17708          9.0    0.0      0.0         0.0           0.0      None   \n",
      "13498         -2.5   -1.0     -0.5         0.0           0.0      None   \n",
      "\n",
      "       improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
      "17697                   -0.3          -3.3           4.0        1.0   \n",
      "433                      0.3           9.8           4.0        1.0   \n",
      "15814                    0.3          17.3           4.0        1.0   \n",
      "17708                    0.0           9.0           4.0        2.0   \n",
      "13498                   -0.3          -4.3           4.0        1.0   \n",
      "\n",
      "       congestion_surcharge  \n",
      "17697                   0.0  \n",
      "433                     0.0  \n",
      "15814                   0.0  \n",
      "17708                   0.0  \n",
      "13498                   0.0  \n"
     ]
    }
   ],
   "source": [
    "def check_dispute_payments(dfs):\n",
    "    \"\"\"\n",
    "    Count rows where payment_type is 4 (Dispute) and print sample rows.\n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    \n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            # Count rows where payment_type is 4 (Dispute)\n",
    "            dispute_count = df[df['payment_type'] == 4].shape[0]\n",
    "            print(\"Number of rows with payment_type 4 (Dispute):\", dispute_count)\n",
    "\n",
    "            # Find rows where payment_type is 4 (Dispute)\n",
    "            dispute_rows = df[df['payment_type'] == 4]\n",
    "\n",
    "            # Print 5 sample rows with payment_type 4 (Dispute)\n",
    "            sample_rows = dispute_rows.sample(n=5, random_state=42)\n",
    "            print(\"5 Sample Rows with payment_type 4 (Dispute):\")\n",
    "            print(sample_rows)\n",
    "\n",
    "check_dispute_payments(green_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the 'ehail_fee' column and their counts:\n",
      "ehail_fee\n",
      "None    76518\n",
      "Name: count, dtype: int64\n",
      "Number of null values in the 'ehail_fee' column: 76518\n"
     ]
    }
   ],
   "source": [
    "def check_ehail_fee_values(dfs):\n",
    "    \"\"\"\n",
    "    Print all unique values in the 'ehail_fee' column and their counts.\n",
    "    Also, print the number of null values in the 'ehail_fee' column.\n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            # Get the unique values and their counts in the 'ehail_fee' column\n",
    "            unique_values_counts = df['ehail_fee'].value_counts(dropna=False)\n",
    "            \n",
    "            # Print the unique values and their counts\n",
    "            print(\"Unique values in the 'ehail_fee' column and their counts:\")\n",
    "            print(unique_values_counts)\n",
    "            \n",
    "            # Count and print the number of null values in the 'ehail_fee' column\n",
    "            null_count = df['ehail_fee'].isnull().sum()\n",
    "            print(f\"Number of null values in the 'ehail_fee' column: {null_count}\")\n",
    "\n",
    "check_ehail_fee_values(green_2021_01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\n",
      "Taxi Zone CSV Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_other\n",
      "Number of Unique Zones: 69\n",
      "List of Unique Zones: [  4  12  13  24  41  42  43  45  48  50  68  74  75  79  87  88  90 100\n",
      " 103 104 105 107 113 114 116 120 125 127 128 137 140 141 142 143 144 148\n",
      " 151 152 153 158 161 162 163 164 166 170 186 194 202 209 211 224 229 230\n",
      " 231 232 233 234 236 237 238 239 243 244 246 249 261 262 263]\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Working Directory:\", cwd)\n",
    "\n",
    "taxi_zone_dir = os.path.join(os.getcwd(), \"..\", \"Datasets\", \"taxi_other\")\n",
    "\n",
    "# Define the directory where the data is located relative to the current working directory\n",
    "print(\"Taxi Zone CSV Directory:\", taxi_zone_dir)\n",
    "\n",
    "# Define the file path relative to the data directory\n",
    "taxi_zone_path = os.path.join(cwd, taxi_zone_dir, \"taxi_zone_lookup.csv\")\n",
    "\n",
    "taxi_zone = pd.read_csv(taxi_zone_path, keep_default_na=True, delimiter=\",\", skipinitialspace=True, encoding=\"Windows-1252\")\n",
    "\n",
    "def valid_zones_1(df):\n",
    "    manhattan_df = df[df[\"Borough\"] == \"Manhattan\"]\n",
    "    unique_zones = manhattan_df[\"LocationID\"].unique()\n",
    "    \n",
    "    print(f\"Number of Unique Zones: {len(unique_zones)}\")\n",
    "    print(\"List of Unique Zones:\", unique_zones)\n",
    "\n",
    "valid_zones_1(taxi_zone)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get unique zones for Manhattan\n",
    "def get_manhattan_zones(df):\n",
    "    manhattan_df = df[df[\"Borough\"] == \"Manhattan\"]\n",
    "    unique_zones = manhattan_df[\"LocationID\"].unique()\n",
    "    return set(unique_zones)\n",
    "\n",
    "# Get the unique Manhattan zones from the taxi_zone DataFrame\n",
    "manhattan_zones = get_manhattan_zones(taxi_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to check pickup and dropoff zones\n",
    "def check_zones(df, manhattan_zones):\n",
    "    # Check if both pickup_zone and dropoff_zone are not in manhattan_zones\n",
    "    invalid_zones = df[~df[\"pickup_zone\"].isin(manhattan_zones) & ~df[\"dropoff_zone\"].isin(manhattan_zones)]\n",
    "    \n",
    "    print(f\"Invalid zones count: {invalid_zones.shape[0]}\")\n",
    "    \n",
    "    if not invalid_zones.empty:\n",
    "        print(\"Examples of rows with invalid zones:\")\n",
    "        print(invalid_zones.head())  # Print first few invalid rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid zones count: 40376\n",
      "Examples of rows with invalid zones:\n",
      "   VendorID     pickup_datetime    dropoff_datetime store_and_fwd_flag  \\\n",
      "4         2 2021-01-01 00:16:36 2021-01-01 00:16:40                  N   \n",
      "5         2 2021-01-01 00:16:36 2021-01-01 00:16:40                  N   \n",
      "6         2 2021-01-01 00:19:14 2021-01-01 00:19:21                  N   \n",
      "8         2 2021-01-01 00:57:46 2021-01-01 00:57:57                  N   \n",
      "9         2 2021-01-01 00:58:32 2021-01-01 01:32:34                  N   \n",
      "\n",
      "   RatecodeID  pickup_zone  dropoff_zone  passenger_count  trip_distance  \\\n",
      "4           2          265           265                3           0.00   \n",
      "5           2          265           265                3           0.00   \n",
      "6           5          265           265                1           0.00   \n",
      "8           1          225           225                1           0.00   \n",
      "9           1          225           265                1          12.19   \n",
      "\n",
      "   fare_amount  extra  mta_tax  tip_amount  tolls_amount ehail_fee  \\\n",
      "4        -52.0    0.0     -0.5        0.00           0.0      None   \n",
      "5         52.0    0.0      0.5        0.00           0.0      None   \n",
      "6        180.0    0.0      0.0       36.06           0.0      None   \n",
      "8          2.5    0.5      0.5        0.00           0.0      None   \n",
      "9         38.0    0.5      0.5        2.75           0.0      None   \n",
      "\n",
      "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
      "4                   -0.3        -52.80           3.0        1.0   \n",
      "5                    0.3         52.80           2.0        1.0   \n",
      "6                    0.3        216.36           1.0        2.0   \n",
      "8                    0.3          3.80           2.0        1.0   \n",
      "9                    0.3         42.05           1.0        1.0   \n",
      "\n",
      "   congestion_surcharge  \n",
      "4                   0.0  \n",
      "5                   0.0  \n",
      "6                   0.0  \n",
      "8                   0.0  \n",
      "9                   0.0  \n"
     ]
    }
   ],
   "source": [
    "check_zones(green_2021_01, manhattan_zones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifying_invalid_zones(df, manhattan_zones, taxi_zone_csv):\n",
    "    # Identify invalid rows where both pickup_zone and dropoff_zone are not in manhattan_zones\n",
    "    invalid_zones = df[~df[\"pickup_zone\"].isin(manhattan_zones) & ~df[\"dropoff_zone\"].isin(manhattan_zones)]\n",
    "    \n",
    "    # If there are no invalid rows, print and return\n",
    "    if invalid_zones.empty:\n",
    "        print(\"No invalid zones found.\")\n",
    "        return\n",
    "    \n",
    "    # Merge invalid zones with taxi_zone_csv to get borough information for both pickup_zone and dropoff_zone\n",
    "    invalid_zones_merged = invalid_zones.merge(taxi_zone_csv, left_on=\"pickup_zone\", right_on=\"LocationID\", how=\"left\", suffixes=('_pickup', '_dropoff'))\n",
    "    invalid_zones_merged = invalid_zones_merged.merge(taxi_zone_csv, left_on=\"dropoff_zone\", right_on=\"LocationID\", how=\"left\", suffixes=('_pickup', '_dropoff'))\n",
    "\n",
    "    # Concatenate Borough columns for analysis\n",
    "    invalid_zones_merged[\"Borough_combined\"] = invalid_zones_merged[\"Borough_pickup\"] + \" (pickup), \" + invalid_zones_merged[\"Borough_dropoff\"] + \" (dropoff)\"\n",
    "    \n",
    "    # Count the combined Borough information\n",
    "    combined_borough_counts = invalid_zones_merged[\"Borough_combined\"].value_counts()\n",
    "\n",
    "    print(\"Invalid Rows Borough Counts:\")\n",
    "    print(combined_borough_counts)\n",
    "\n",
    "manhattan_zones = get_manhattan_zones(taxi_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifying_invalid_zones(green_2021_01, manhattan_zones, taxi_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_green_invalid_rows(dfs, manhattan_zones, taxi_zone_csv):\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "\n",
    "    cleaned_dfs = []\n",
    "    \n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            # Drop duplicate rows\n",
    "            df = df.drop_duplicates()\n",
    "            \n",
    "            # Drop \"airport_fee\" column due to missing values\n",
    "            if \"ehail_fee\" in df.columns:\n",
    "                df = df.drop(columns=[\"ehail_fee\"])\n",
    "            \n",
    "            # Drop rows where passenger_count == 0 or >= 6\n",
    "            df = df[(df[\"passenger_count\"] > 0) & (df[\"passenger_count\"] < 6)]\n",
    "            \n",
    "            # Drop rows where fare_amount or total_amount <= 0\n",
    "            df = df[(df[\"fare_amount\"] > 0) & (df[\"total_amount\"] > 0)]\n",
    "            \n",
    "            # Drop rows where extra, mta_tax, tip_amount, tolls_amount, improvement_surcharge, or congestion_surcharge < 0\n",
    "            df = df[(df[\"extra\"] >= 0) & (df[\"mta_tax\"] >= 0) & (df[\"tip_amount\"] >= 0) & \n",
    "                    (df[\"tolls_amount\"] >= 0) & (df[\"improvement_surcharge\"] >= 0) & \n",
    "                    (df[\"congestion_surcharge\"] >= 0)]\n",
    "            \n",
    "            # Drop rows where pickup_datetime == dropoff_datetime\n",
    "            df = df[df[\"pickup_datetime\"] != df[\"dropoff_datetime\"]]\n",
    "            \n",
    "            # Drop rows where trip_distance <= 0\n",
    "            df = df[df[\"trip_distance\"] > 0]\n",
    "            \n",
    "            # Drop rows where RateCodeID != 1-6\n",
    "            df = df[df[\"RatecodeID\"].isin([1, 2, 3, 4, 5, 6])]\n",
    "            \n",
    "            # Drop rows where payment_type == 4\n",
    "            df = df[df[\"payment_type\"] != 4]\n",
    "            \n",
    "            # Drop rows where both pickup_zone and dropoff_zone are not Manhattan zones\n",
    "            df = df[df[\"pickup_zone\"].isin(manhattan_zones) | df[\"dropoff_zone\"].isin(manhattan_zones)]\n",
    "            \n",
    "            # Append the cleaned DataFrame to the list\n",
    "            cleaned_dfs.append(df)\n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "    \n",
    "    # Return the cleaned DataFrame(s)\n",
    "    if len(cleaned_dfs) == 1:\n",
    "        return cleaned_dfs[0]\n",
    "    else:\n",
    "        return cleaned_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_zones = get_manhattan_zones(taxi_zone)\n",
    "\n",
    "# Call the verifying_invalid_zones function\n",
    "green_2021_01 = drop_green_invalid_rows(green_2021_01, manhattan_zones, taxi_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25598 entries, 0 to 40470\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               25598 non-null  int64         \n",
      " 1   pickup_datetime        25598 non-null  datetime64[us]\n",
      " 2   dropoff_datetime       25598 non-null  datetime64[us]\n",
      " 3   store_and_fwd_flag     25598 non-null  object        \n",
      " 4   RatecodeID             25598 non-null  int32         \n",
      " 5   pickup_zone            25598 non-null  int64         \n",
      " 6   dropoff_zone           25598 non-null  int64         \n",
      " 7   passenger_count        25598 non-null  int32         \n",
      " 8   trip_distance          25598 non-null  float64       \n",
      " 9   fare_amount            25598 non-null  float64       \n",
      " 10  extra                  25598 non-null  float64       \n",
      " 11  mta_tax                25598 non-null  float64       \n",
      " 12  tip_amount             25598 non-null  float64       \n",
      " 13  tolls_amount           25598 non-null  float64       \n",
      " 14  improvement_surcharge  25598 non-null  float64       \n",
      " 15  total_amount           25598 non-null  float64       \n",
      " 16  payment_type           25598 non-null  float64       \n",
      " 17  trip_type              25598 non-null  float64       \n",
      " 18  congestion_surcharge   25598 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(11), int32(2), int64(3), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "green_2021_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_green_columns(df):\n",
    "    columns_to_drop = [\"VendorID\", \"trip_distance\", \"RatecodeID\", \"store_and_fwd_flag\", \"payment_type\", \n",
    "                       \"fare_amount\", \"extra\", \"mta_tax\", \"improvement_surcharge\", \"tip_amount\", \n",
    "                       \"tolls_amount\", \"total_amount\", \"congestion_surcharge\", \"trip_type\"]\n",
    "    \n",
    "    # Drop only the columns that exist in the DataFrame\n",
    "    existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "    df.drop(columns=existing_columns_to_drop, inplace=True)\n",
    "\n",
    "    # Return the modified DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_zone</th>\n",
       "      <th>dropoff_zone</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:15:56</td>\n",
       "      <td>2021-01-01 00:19:52</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 00:25:59</td>\n",
       "      <td>2021-01-01 00:34:44</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 00:45:57</td>\n",
       "      <td>2021-01-01 00:51:55</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-31 23:57:51</td>\n",
       "      <td>2021-01-01 00:04:56</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-01-01 00:31:14</td>\n",
       "      <td>2021-01-01 00:55:07</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40463</th>\n",
       "      <td>2021-01-31 23:45:27</td>\n",
       "      <td>2021-01-31 23:56:04</td>\n",
       "      <td>74</td>\n",
       "      <td>244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40467</th>\n",
       "      <td>2021-01-31 23:13:36</td>\n",
       "      <td>2021-01-31 23:17:51</td>\n",
       "      <td>75</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40468</th>\n",
       "      <td>2021-01-31 23:46:45</td>\n",
       "      <td>2021-01-31 23:57:08</td>\n",
       "      <td>41</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40469</th>\n",
       "      <td>2021-01-31 23:42:17</td>\n",
       "      <td>2021-01-31 23:48:19</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40470</th>\n",
       "      <td>2021-01-31 23:09:07</td>\n",
       "      <td>2021-01-31 23:29:01</td>\n",
       "      <td>74</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25598 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_datetime    dropoff_datetime  pickup_zone  dropoff_zone  \\\n",
       "0     2021-01-01 00:15:56 2021-01-01 00:19:52           43           151   \n",
       "1     2021-01-01 00:25:59 2021-01-01 00:34:44          166           239   \n",
       "2     2021-01-01 00:45:57 2021-01-01 00:51:55           41            42   \n",
       "3     2020-12-31 23:57:51 2021-01-01 00:04:56          168            75   \n",
       "10    2021-01-01 00:31:14 2021-01-01 00:55:07          244           244   \n",
       "...                   ...                 ...          ...           ...   \n",
       "40463 2021-01-31 23:45:27 2021-01-31 23:56:04           74           244   \n",
       "40467 2021-01-31 23:13:36 2021-01-31 23:17:51           75           238   \n",
       "40468 2021-01-31 23:46:45 2021-01-31 23:57:08           41           263   \n",
       "40469 2021-01-31 23:42:17 2021-01-31 23:48:19           75            75   \n",
       "40470 2021-01-31 23:09:07 2021-01-31 23:29:01           74           100   \n",
       "\n",
       "       passenger_count  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "10                   2  \n",
       "...                ...  \n",
       "40463                1  \n",
       "40467                1  \n",
       "40468                1  \n",
       "40469                1  \n",
       "40470                1  \n",
       "\n",
       "[25598 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_green_columns(green_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25598 entries, 0 to 40470\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   pickup_datetime   25598 non-null  datetime64[us]\n",
      " 1   dropoff_datetime  25598 non-null  datetime64[us]\n",
      " 2   pickup_zone       25598 non-null  int64         \n",
      " 3   dropoff_zone      25598 non-null  int64         \n",
      " 4   passenger_count   25598 non-null  int32         \n",
      "dtypes: datetime64[us](2), int32(1), int64(2)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "green_2021_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_values(dfs):\n",
    "    \"\"\"\n",
    "    Drops any rows with missing values from the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to clean.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "        int: The number of rows that were dropped.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "\n",
    "    cleaned_dfs = []\n",
    "    \n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):    # Count the number of rows before dropping missing values\n",
    "            initial_row_count = df.shape[0]\n",
    "    \n",
    "            # Drop rows with missing values\n",
    "            df = df.dropna()\n",
    "    \n",
    "            # Count the number of rows after dropping missing values\n",
    "            final_row_count = df.shape[0]\n",
    "    \n",
    "            # Calculate the number of rows that were dropped\n",
    "            rows_dropped = initial_row_count - final_row_count\n",
    "        print(f\"Number of rows dropped: {rows_dropped}\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_zone</th>\n",
       "      <th>dropoff_zone</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:15:56</td>\n",
       "      <td>2021-01-01 00:19:52</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 00:25:59</td>\n",
       "      <td>2021-01-01 00:34:44</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 00:45:57</td>\n",
       "      <td>2021-01-01 00:51:55</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-31 23:57:51</td>\n",
       "      <td>2021-01-01 00:04:56</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-01-01 00:31:14</td>\n",
       "      <td>2021-01-01 00:55:07</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40463</th>\n",
       "      <td>2021-01-31 23:45:27</td>\n",
       "      <td>2021-01-31 23:56:04</td>\n",
       "      <td>74</td>\n",
       "      <td>244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40467</th>\n",
       "      <td>2021-01-31 23:13:36</td>\n",
       "      <td>2021-01-31 23:17:51</td>\n",
       "      <td>75</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40468</th>\n",
       "      <td>2021-01-31 23:46:45</td>\n",
       "      <td>2021-01-31 23:57:08</td>\n",
       "      <td>41</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40469</th>\n",
       "      <td>2021-01-31 23:42:17</td>\n",
       "      <td>2021-01-31 23:48:19</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40470</th>\n",
       "      <td>2021-01-31 23:09:07</td>\n",
       "      <td>2021-01-31 23:29:01</td>\n",
       "      <td>74</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25598 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_datetime    dropoff_datetime  pickup_zone  dropoff_zone  \\\n",
       "0     2021-01-01 00:15:56 2021-01-01 00:19:52           43           151   \n",
       "1     2021-01-01 00:25:59 2021-01-01 00:34:44          166           239   \n",
       "2     2021-01-01 00:45:57 2021-01-01 00:51:55           41            42   \n",
       "3     2020-12-31 23:57:51 2021-01-01 00:04:56          168            75   \n",
       "10    2021-01-01 00:31:14 2021-01-01 00:55:07          244           244   \n",
       "...                   ...                 ...          ...           ...   \n",
       "40463 2021-01-31 23:45:27 2021-01-31 23:56:04           74           244   \n",
       "40467 2021-01-31 23:13:36 2021-01-31 23:17:51           75           238   \n",
       "40468 2021-01-31 23:46:45 2021-01-31 23:57:08           41           263   \n",
       "40469 2021-01-31 23:42:17 2021-01-31 23:48:19           75            75   \n",
       "40470 2021-01-31 23:09:07 2021-01-31 23:29:01           74           100   \n",
       "\n",
       "       passenger_count  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "10                   2  \n",
       "...                ...  \n",
       "40463                1  \n",
       "40467                1  \n",
       "40468                1  \n",
       "40469                1  \n",
       "40470                1  \n",
       "\n",
       "[25598 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_missing_values(green_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zone_busy(green_df):\n",
    "    # Combine pickup and dropoff data into a single DataFrame; Renamed and combined into a single datetime column\n",
    "    pickup_data = green_df[['pickup_datetime', 'passenger_count', 'pickup_zone']].rename(columns={'pickup_datetime': 'datetime', 'pickup_zone': 'zone'})\n",
    "    dropoff_data = green_df[['dropoff_datetime', 'passenger_count', 'dropoff_zone']].rename(columns={'dropoff_datetime': 'datetime', 'dropoff_zone': 'zone'})\n",
    "    combined_data = pd.concat([pickup_data, dropoff_data])\n",
    "    \n",
    "    # Round datetime to the nearest hour\n",
    "    combined_data['datetime'] = combined_data['datetime'].dt.round('h')\n",
    "    \n",
    "    # Group by hour and zone, summing passenger counts\n",
    "    zone_busy_df = combined_data.groupby(['datetime', 'zone'])['passenger_count'].sum().reset_index()\n",
    "    \n",
    "    return zone_busy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_2021_01 = calculate_zone_busy(green_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15898 entries, 0 to 15897\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   datetime         15898 non-null  datetime64[us]\n",
      " 1   zone             15898 non-null  int64         \n",
      " 2   passenger_count  15898 non-null  int32         \n",
      "dtypes: datetime64[us](1), int32(1), int64(1)\n",
      "memory usage: 310.6 KB\n"
     ]
    }
   ],
   "source": [
    "green_2021_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>zone</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime  zone  passenger_count\n",
       "0 2021-01-01    41                1\n",
       "1 2021-01-01    42                1\n",
       "2 2021-01-01    43                1\n",
       "3 2021-01-01    74                2\n",
       "4 2021-01-01    75                4\n",
       "5 2021-01-01   116                3\n",
       "6 2021-01-01   151                1\n",
       "7 2021-01-01   152                1\n",
       "8 2021-01-01   166                2\n",
       "9 2021-01-01   168                1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_2021_01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to: Datasets\\taxi_other\\green_2021_01_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "directory_path = os.path.join(\"Datasets\", \"taxi_other\")\n",
    "\n",
    "\n",
    "# Define the file path\n",
    "file_path = os.path.join(directory_path, \"green_2021_01_cleaned.csv\")\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "green_2021_01.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"DataFrame saved to:\", file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: DatetimeIndex(['2021-01-31', '2021-02-28', '2021-03-31', '2021-04-30',\n",
      "               '2021-05-31', '2021-06-30', '2021-07-31', '2021-08-31',\n",
      "               '2021-09-30', '2021-10-31', '2021-11-30', '2021-12-31',\n",
      "               '2022-01-31', '2022-02-28', '2022-03-31', '2022-04-30',\n",
      "               '2022-05-31', '2022-06-30', '2022-07-31', '2022-08-31',\n",
      "               '2022-09-30', '2022-10-31', '2022-11-30', '2022-12-31',\n",
      "               '2023-01-31', '2023-02-28', '2023-03-31', '2023-04-30',\n",
      "               '2023-05-31', '2023-06-30', '2023-07-31', '2023-08-31',\n",
      "               '2023-09-30', '2023-10-31', '2023-11-30', '2023-12-31',\n",
      "               '2024-01-31', '2024-02-29', '2024-03-31'],\n",
      "              dtype='datetime64[ns]', freq='ME')\n"
     ]
    }
   ],
   "source": [
    "date_range = pd.date_range(start='2021-01', end='2024-04', freq='ME')\n",
    "print(\"Date range:\", date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\n",
      "Files in directory c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets: ['fhvhv_2021_01.parquet', 'fhvhv_2021_02.parquet', 'fhvhv_2021_03.parquet', 'fhvhv_2021_04.parquet', 'fhvhv_2021_05.parquet', 'fhvhv_2021_06.parquet', 'fhvhv_2021_07.parquet', 'fhvhv_2021_08.parquet', 'fhvhv_2021_09.parquet', 'fhvhv_2021_10.parquet', 'fhvhv_2021_11.parquet', 'fhvhv_2021_12.parquet', 'fhvhv_2022_01.parquet', 'fhvhv_2022_02.parquet', 'fhvhv_2022_03.parquet', 'fhvhv_2022_04.parquet', 'fhvhv_2022_05.parquet', 'fhvhv_2022_06.parquet', 'fhvhv_2022_07.parquet', 'fhvhv_2022_08.parquet', 'fhvhv_2022_09.parquet', 'fhvhv_2022_10.parquet', 'fhvhv_2022_11.parquet', 'fhvhv_2022_12.parquet', 'fhvhv_2023_01.parquet', 'fhvhv_2023_02.parquet', 'fhvhv_2023_03.parquet', 'fhvhv_2023_04.parquet', 'fhvhv_2023_05.parquet', 'fhvhv_2023_06.parquet', 'fhvhv_2023_07.parquet', 'fhvhv_2023_08.parquet', 'fhvhv_2023_09.parquet', 'fhvhv_2023_10.parquet', 'fhvhv_2023_11.parquet', 'fhvhv_2023_12.parquet', 'fhvhv_2024_01.parquet', 'fhvhv_2024_02.parquet', 'fhvhv_2024_03.parquet', 'fhv_2021_01.parquet', 'fhv_2021_02.parquet', 'fhv_2021_03.parquet', 'fhv_2021_04.parquet', 'fhv_2021_05.parquet', 'fhv_2021_06.parquet', 'fhv_2021_07.parquet', 'fhv_2021_08.parquet', 'fhv_2021_09.parquet', 'fhv_2021_10.parquet', 'fhv_2021_11.parquet', 'fhv_2021_12.parquet', 'fhv_2022_01.parquet', 'fhv_2022_02.parquet', 'fhv_2022_03.parquet', 'fhv_2022_04.parquet', 'fhv_2022_05.parquet', 'fhv_2022_06.parquet', 'fhv_2022_07.parquet', 'fhv_2022_08.parquet', 'fhv_2022_09.parquet', 'fhv_2022_10.parquet', 'fhv_2022_11.parquet', 'fhv_2022_12.parquet', 'fhv_2023_01.parquet', 'fhv_2023_02.parquet', 'fhv_2023_03.parquet', 'fhv_2023_04.parquet', 'fhv_2023_05.parquet', 'fhv_2023_06.parquet', 'fhv_2023_07.parquet', 'fhv_2023_08.parquet', 'fhv_2023_09.parquet', 'fhv_2023_10.parquet', 'fhv_2023_11.parquet', 'fhv_2023_12.parquet', 'fhv_2024_01.parquet', 'fhv_2024_02.parquet', 'fhv_2024_03.parquet', 'green_2021_01.parquet', 'green_2021_01_cleaned.parquet', 'green_2021_02.parquet', 'green_2021_02_cleaned.parquet', 'green_2021_03.parquet', 'green_2021_03_cleaned.parquet', 'green_2021_04.parquet', 'green_2021_04_cleaned.parquet', 'green_2021_05.parquet', 'green_2021_05_cleaned.parquet', 'green_2021_06.parquet', 'green_2021_06_cleaned.parquet', 'green_2021_07.parquet', 'green_2021_07_cleaned.parquet', 'green_2021_08.parquet', 'green_2021_08_cleaned.parquet', 'green_2021_09.parquet', 'green_2021_09_cleaned.parquet', 'green_2021_10.parquet', 'green_2021_10_cleaned.parquet', 'green_2021_11.parquet', 'green_2021_11_cleaned.parquet', 'green_2021_12.parquet', 'green_2021_12_cleaned.parquet', 'green_2022_01.parquet', 'green_2022_01_cleaned.parquet', 'green_2022_02.parquet', 'green_2022_02_cleaned.parquet', 'green_2022_03.parquet', 'green_2022_03_cleaned.parquet', 'green_2022_04.parquet', 'green_2022_04_cleaned.parquet', 'green_2022_05.parquet', 'green_2022_05_cleaned.parquet', 'green_2022_06.parquet', 'green_2022_06_cleaned.parquet', 'green_2022_07.parquet', 'green_2022_07_cleaned.parquet', 'green_2022_08.parquet', 'green_2022_08_cleaned.parquet', 'green_2022_09.parquet', 'green_2022_09_cleaned.parquet', 'green_2022_10.parquet', 'green_2022_10_cleaned.parquet', 'green_2022_11.parquet', 'green_2022_11_cleaned.parquet', 'green_2022_12.parquet', 'green_2022_12_cleaned.parquet', 'green_2023_01.parquet', 'green_2023_01_cleaned.parquet', 'green_2023_02.parquet', 'green_2023_02_cleaned.parquet', 'green_2023_03.parquet', 'green_2023_03_cleaned.parquet', 'green_2023_04.parquet', 'green_2023_04_cleaned.parquet', 'green_2023_05.parquet', 'green_2023_05_cleaned.parquet', 'green_2023_06.parquet', 'green_2023_06_cleaned.parquet', 'green_2023_07.parquet', 'green_2023_07_cleaned.parquet', 'green_2023_08.parquet', 'green_2023_08_cleaned.parquet', 'green_2023_09.parquet', 'green_2023_09_cleaned.parquet', 'green_2023_10.parquet', 'green_2023_10_cleaned.parquet', 'green_2023_11.parquet', 'green_2023_11_cleaned.parquet', 'green_2023_12.parquet', 'green_2023_12_cleaned.parquet', 'green_2024_01.parquet', 'green_2024_01_cleaned.parquet', 'green_2024_02.parquet', 'green_2024_02_cleaned.parquet', 'green_2024_03.parquet', 'green_2024_03_cleaned.parquet', 'green_final_cleaned.parquet', 'yellow_2021_01.parquet', 'yellow_2021_01_cleaned.parquet', 'yellow_2021_02.parquet', 'yellow_2021_02_cleaned.parquet', 'yellow_2021_03.parquet', 'yellow_2021_03_cleaned.parquet', 'yellow_2021_04.parquet', 'yellow_2021_04_cleaned.parquet', 'yellow_2021_05.parquet', 'yellow_2021_05_cleaned.parquet', 'yellow_2021_06.parquet', 'yellow_2021_06_cleaned.parquet', 'yellow_2021_07.parquet', 'yellow_2021_07_cleaned.parquet', 'yellow_2021_08.parquet', 'yellow_2021_08_cleaned.parquet', 'yellow_2021_09.parquet', 'yellow_2021_09_cleaned.parquet', 'yellow_2021_10.parquet', 'yellow_2021_10_cleaned.parquet', 'yellow_2021_11.parquet', 'yellow_2021_11_cleaned.parquet', 'yellow_2021_12.parquet', 'yellow_2021_12_cleaned.parquet', 'yellow_2022_01.parquet', 'yellow_2022_01_cleaned.parquet', 'yellow_2022_02.parquet', 'yellow_2022_02_cleaned.parquet', 'yellow_2022_03.parquet', 'yellow_2022_03_cleaned.parquet', 'yellow_2022_04.parquet', 'yellow_2022_04_cleaned.parquet', 'yellow_2022_05.parquet', 'yellow_2022_05_cleaned.parquet', 'yellow_2022_06.parquet', 'yellow_2022_06_cleaned.parquet', 'yellow_2022_07.parquet', 'yellow_2022_07_cleaned.parquet', 'yellow_2022_08.parquet', 'yellow_2022_08_cleaned.parquet', 'yellow_2022_09.parquet', 'yellow_2022_09_cleaned.parquet', 'yellow_2022_10.parquet', 'yellow_2022_10_cleaned.parquet', 'yellow_2022_11.parquet', 'yellow_2022_11_cleaned.parquet', 'yellow_2022_12.parquet', 'yellow_2022_12_cleaned.parquet', 'yellow_2023_01.parquet', 'yellow_2023_01_cleaned.parquet', 'yellow_2023_02.parquet', 'yellow_2023_02_cleaned.parquet', 'yellow_2023_03.parquet', 'yellow_2023_03_cleaned.parquet', 'yellow_2023_04.parquet', 'yellow_2023_04_cleaned.parquet', 'yellow_2023_05.parquet', 'yellow_2023_05_cleaned.parquet', 'yellow_2023_06.parquet', 'yellow_2023_06_cleaned.parquet', 'yellow_2023_07.parquet', 'yellow_2023_07_cleaned.parquet', 'yellow_2023_08.parquet', 'yellow_2023_08_cleaned.parquet', 'yellow_2023_09.parquet', 'yellow_2023_09_cleaned.parquet', 'yellow_2023_10.parquet', 'yellow_2023_10_cleaned.parquet', 'yellow_2023_11.parquet', 'yellow_2023_11_cleaned.parquet', 'yellow_2023_12.parquet', 'yellow_2023_12_cleaned.parquet', 'yellow_2024_01.parquet', 'yellow_2024_01_cleaned.parquet', 'yellow_2024_02.parquet', 'yellow_2024_02_cleaned.parquet', 'yellow_2024_03.parquet', 'yellow_2024_03_cleaned.parquet', 'yellow_final_cleaned.parquet']\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(os.getcwd(), \"..\", \"Datasets\", \"taxi_parquets\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(data_dir):\n",
    "    print(f\"Directory {data_dir} does not exist\")\n",
    "else:\n",
    "    # List all files in the directory to check for existence and naming\n",
    "    all_files_in_dir = os.listdir(data_dir)\n",
    "    print(f\"Files in directory {data_dir}: {all_files_in_dir}\")\n",
    "\n",
    "all_files = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\n",
      "green_2024_03_path: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\cleaning\\..\\Datasets\\taxi_parquets\\green_2024_03.parquet\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(\"Current Working Directory:\", cwd)\n",
    "\n",
    "# Define the file paths relative to the data directory\n",
    "green_2024_03_path = os.path.join(cwd, data_dir, \"green_2024_03.parquet\")\n",
    "\n",
    "print(\"green_2024_03_path:\", green_2024_03_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_2024_03 = pd.read_parquet(green_2024_03_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming_green_to_standard(green_2024_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_float_to_int(green_2024_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>pickup_zone</th>\n",
       "      <th>dropoff_zone</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-01 00:10:52</td>\n",
       "      <td>2024-03-01 00:26:12</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>1.72</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-01 00:22:21</td>\n",
       "      <td>2024-03-01 00:35:15</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>3.25</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-01 00:45:27</td>\n",
       "      <td>2024-03-01 01:04:32</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>4.58</td>\n",
       "      <td>23.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-03-01 00:02:00</td>\n",
       "      <td>2024-03-01 00:23:45</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-01 00:16:45</td>\n",
       "      <td>2024-03-01 00:23:25</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>1.15</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-01 00:41:20</td>\n",
       "      <td>2024-03-01 00:57:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6.78</td>\n",
       "      <td>28.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-01 00:47:47</td>\n",
       "      <td>2024-03-01 01:00:53</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>6.19</td>\n",
       "      <td>26.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-01 00:44:48</td>\n",
       "      <td>2024-03-01 01:07:13</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>6.26</td>\n",
       "      <td>28.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-01 00:32:39</td>\n",
       "      <td>2024-03-01 00:38:57</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-01 00:07:41</td>\n",
       "      <td>2024-03-01 00:14:12</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>2</td>\n",
       "      <td>1.15</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID     pickup_datetime    dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2 2024-03-01 00:10:52 2024-03-01 00:26:12                  N   \n",
       "1         2 2024-03-01 00:22:21 2024-03-01 00:35:15                  N   \n",
       "2         2 2024-03-01 00:45:27 2024-03-01 01:04:32                  N   \n",
       "3         1 2024-03-01 00:02:00 2024-03-01 00:23:45                  N   \n",
       "4         2 2024-03-01 00:16:45 2024-03-01 00:23:25                  N   \n",
       "5         2 2024-03-01 00:41:20 2024-03-01 00:57:00                  N   \n",
       "6         2 2024-03-01 00:47:47 2024-03-01 01:00:53                  N   \n",
       "7         2 2024-03-01 00:44:48 2024-03-01 01:07:13                  N   \n",
       "8         2 2024-03-01 00:32:39 2024-03-01 00:38:57                  N   \n",
       "9         2 2024-03-01 00:07:41 2024-03-01 00:14:12                  N   \n",
       "\n",
       "   RatecodeID  pickup_zone  dropoff_zone  passenger_count  trip_distance  \\\n",
       "0           1          129           226                1           1.72   \n",
       "1           1          130           218                1           3.25   \n",
       "2           1          255           107                2           4.58   \n",
       "3           1          181            71                1           0.00   \n",
       "4           1           95           135                1           1.15   \n",
       "5           1           80             7                2           6.78   \n",
       "6           1           42           233                1           6.19   \n",
       "7           1           36           195                1           6.26   \n",
       "8           1           75           263                1           0.81   \n",
       "9           1          179           179                2           1.15   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0         12.8    1.0      0.5        3.06           0.0        NaN   \n",
       "1         17.7    1.0      0.5        0.00           0.0        NaN   \n",
       "2         23.3    1.0      0.5        3.50           0.0        NaN   \n",
       "3         22.5    0.0      1.5        0.00           0.0        NaN   \n",
       "4          8.6    1.0      0.5        1.00           0.0        NaN   \n",
       "5         28.9    1.0      0.5        9.42           0.0        NaN   \n",
       "6         26.1    1.0      0.5        0.00           0.0        NaN   \n",
       "7         28.9    1.0      0.5        9.42           0.0        NaN   \n",
       "8          7.9    1.0      0.5        0.73           0.0        NaN   \n",
       "9          8.6    1.0      0.5        2.22           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    1.0         18.36           1.0        1.0   \n",
       "1                    1.0         20.20           2.0        1.0   \n",
       "2                    1.0         32.05           1.0        1.0   \n",
       "3                    1.0         24.00           1.0        1.0   \n",
       "4                    1.0         12.10           1.0        1.0   \n",
       "5                    1.0         40.82           1.0        1.0   \n",
       "6                    1.0         31.10           2.0        1.0   \n",
       "7                    1.0         40.82           1.0        1.0   \n",
       "8                    1.0         11.13           1.0        1.0   \n",
       "9                    1.0         13.32           1.0        1.0   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                  0.00  \n",
       "1                  0.00  \n",
       "2                  2.75  \n",
       "3                  0.00  \n",
       "4                  0.00  \n",
       "5                  0.00  \n",
       "6                  2.50  \n",
       "7                  0.00  \n",
       "8                  0.00  \n",
       "9                  0.00  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_2024_03.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count for each unique value in 'passenger_count' column: in\n",
      "passenger_count\n",
      "1    46154\n",
      "2     5547\n",
      "0     2656\n",
      "5     1347\n",
      "6     1006\n",
      "3      544\n",
      "4      195\n",
      "9        3\n",
      "8        3\n",
      "7        2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "passenger_counts(green_2024_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with invalid fares:  223\n",
      "5 Sample Rows with Invalid Fares:\n",
      "       VendorID     pickup_datetime    dropoff_datetime store_and_fwd_flag  \\\n",
      "1685          2 2024-03-01 19:54:04 2024-03-01 19:58:00                  N   \n",
      "20271         2 2024-03-12 09:25:46 2024-03-12 09:29:40                  N   \n",
      "27722         2 2024-03-15 23:15:20 2024-03-15 23:19:08                  N   \n",
      "34812         2 2024-03-20 09:29:35 2024-03-20 09:32:32                  N   \n",
      "54117         2 2024-03-31 03:11:40 2024-03-31 03:11:55                  N   \n",
      "\n",
      "       RatecodeID  pickup_zone  dropoff_zone  passenger_count  trip_distance  \\\n",
      "1685            1           74            75                2           0.51   \n",
      "20271           1           74            42                1           0.45   \n",
      "27722           1           33            52                1           0.79   \n",
      "34812           1           74            74                1           0.06   \n",
      "54117           1          129            82                1           0.07   \n",
      "\n",
      "       fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
      "1685          -5.8   -2.5     -0.5         0.0           0.0        NaN   \n",
      "20271         -5.8    0.0     -0.5         0.0           0.0        NaN   \n",
      "27722         -5.8   -1.0     -0.5         0.0           0.0        NaN   \n",
      "34812         -4.4    0.0     -0.5         0.0           0.0        NaN   \n",
      "54117         -3.0   -1.0     -0.5         0.0           0.0        NaN   \n",
      "\n",
      "       improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
      "1685                    -1.0          -9.8           3.0        1.0   \n",
      "20271                   -1.0          -7.3           3.0        1.0   \n",
      "27722                   -1.0          -8.3           4.0        1.0   \n",
      "34812                   -1.0          -5.9           3.0        1.0   \n",
      "54117                   -1.0          -5.5           4.0        1.0   \n",
      "\n",
      "       congestion_surcharge  \n",
      "1685                    0.0  \n",
      "20271                   0.0  \n",
      "27722                   0.0  \n",
      "34812                   0.0  \n",
      "54117                   0.0  \n"
     ]
    }
   ],
   "source": [
    "count_invalid_fares(green_2024_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid zones count: 22441\n",
      "Examples of rows with invalid zones:\n",
      "   VendorID     pickup_datetime    dropoff_datetime store_and_fwd_flag  \\\n",
      "0         2 2024-03-01 00:10:52 2024-03-01 00:26:12                  N   \n",
      "1         2 2024-03-01 00:22:21 2024-03-01 00:35:15                  N   \n",
      "3         1 2024-03-01 00:02:00 2024-03-01 00:23:45                  N   \n",
      "4         2 2024-03-01 00:16:45 2024-03-01 00:23:25                  N   \n",
      "5         2 2024-03-01 00:41:20 2024-03-01 00:57:00                  N   \n",
      "\n",
      "   RatecodeID  pickup_zone  dropoff_zone  passenger_count  trip_distance  \\\n",
      "0           1          129           226                1           1.72   \n",
      "1           1          130           218                1           3.25   \n",
      "3           1          181            71                1           0.00   \n",
      "4           1           95           135                1           1.15   \n",
      "5           1           80             7                2           6.78   \n",
      "\n",
      "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
      "0         12.8    1.0      0.5        3.06           0.0        NaN   \n",
      "1         17.7    1.0      0.5        0.00           0.0        NaN   \n",
      "3         22.5    0.0      1.5        0.00           0.0        NaN   \n",
      "4          8.6    1.0      0.5        1.00           0.0        NaN   \n",
      "5         28.9    1.0      0.5        9.42           0.0        NaN   \n",
      "\n",
      "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
      "0                    1.0         18.36           1.0        1.0   \n",
      "1                    1.0         20.20           2.0        1.0   \n",
      "3                    1.0         24.00           1.0        1.0   \n",
      "4                    1.0         12.10           1.0        1.0   \n",
      "5                    1.0         40.82           1.0        1.0   \n",
      "\n",
      "   congestion_surcharge  \n",
      "0                   0.0  \n",
      "1                   0.0  \n",
      "3                   0.0  \n",
      "4                   0.0  \n",
      "5                   0.0  \n"
     ]
    }
   ],
   "source": [
    "check_zones(green_2024_03, manhattan_zones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Rows Borough Counts:\n",
      "Borough_combined\n",
      "Queens (pickup), Queens (dropoff)             13854\n",
      "Brooklyn (pickup), Brooklyn (dropoff)          6435\n",
      "Queens (pickup), Brooklyn (dropoff)             499\n",
      "Bronx (pickup), Bronx (dropoff)                 460\n",
      "Brooklyn (pickup), Queens (dropoff)             451\n",
      "Queens (pickup), Unknown (dropoff)              212\n",
      "Unknown (pickup), Unknown (dropoff)             118\n",
      "Queens (pickup), Bronx (dropoff)                 58\n",
      "Brooklyn (pickup), Unknown (dropoff)             55\n",
      "Bronx (pickup), Queens (dropoff)                 45\n",
      "Bronx (pickup), Brooklyn (dropoff)               31\n",
      "Brooklyn (pickup), Bronx (dropoff)               26\n",
      "Bronx (pickup), Unknown (dropoff)                22\n",
      "Unknown (pickup), Queens (dropoff)               10\n",
      "Brooklyn (pickup), EWR (dropoff)                 10\n",
      "Brooklyn (pickup), Staten Island (dropoff)        3\n",
      "Staten Island (pickup), Brooklyn (dropoff)        2\n",
      "Unknown (pickup), Brooklyn (dropoff)              2\n",
      "Unknown (pickup), Bronx (dropoff)                 1\n",
      "Staten Island (pickup), Unknown (dropoff)         1\n",
      "EWR (pickup), Unknown (dropoff)                   1\n",
      "Queens (pickup), EWR (dropoff)                    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "verifying_invalid_zones(green_2024_03, manhattan_zones, taxi_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp47350py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
