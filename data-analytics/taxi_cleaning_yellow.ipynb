{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "File for Cleaning Taxi Data of the Yellow Taxis.\n",
    "Begin by loading 1 parquet file as pandas dataframe from each of the 4 TLC genres.\n",
    "Look at each of the dataframes, as a csv and through python\n",
    "Implement Crisp-DM data cleaning methodology -> Data Quality Report, Data Quality Plan\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TLC = Taxi and Limousine Commission\n",
    "\n",
    "- Yellow = hail or prearrange\n",
    "\n",
    "- Green = Not certain Manhattan Areas (below 110th St. on the West Side, and below 96th St. on the East Side, or at either LaGuardia or JFK airports)\n",
    "\n",
    "- FHV (For Hire Vehicles) = Prearranged, Limousines, Black Cars, Livery (Regular), FHVHV\n",
    "\n",
    "- **FHVHV**/ HVFHV/ HVFHS (For Hire Vehicle High Volume/ High Volume FHV/ High Volume For Hire Service) = \"FHV Bases/ Businesses that dispatch more than 10,000 trips per day\" = Lyft/ Uber/ Juno/ Via\n",
    "\n",
    "- See also:\n",
    "    https://www.nyc.gov/site/tlc/passengers/your-ride.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found: ['c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2021_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2021_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2021_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2021_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2021_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2021_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2021_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2021_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2021_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2021_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2021_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2021_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2022_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2022_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2022_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2022_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2022_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2022_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2022_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2022_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2022_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2022_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2022_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2022_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2023_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2023_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2023_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2023_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2023_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2023_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2023_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2023_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2023_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2023_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2023_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2023_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2024_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2024_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhvhv_2024_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2021_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2021_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2021_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2021_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2021_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2021_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2021_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2021_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2021_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2021_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2021_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2021_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2022_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2022_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2022_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2022_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2022_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2022_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2022_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2022_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2022_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2022_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2022_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2022_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2023_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2023_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2023_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2023_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2023_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2023_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2023_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2023_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2023_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2023_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2023_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2023_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2024_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2024_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\fhv_2024_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2021_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2021_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2021_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2021_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2021_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2021_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2021_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2021_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2021_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2021_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2021_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2021_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2022_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2022_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2022_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2022_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2022_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2022_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2022_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2022_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2022_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2022_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2022_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2022_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2023_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2023_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2023_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2023_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2023_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2023_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2023_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2023_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2023_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2023_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2023_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2023_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2024_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2024_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\green_2024_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2021_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2021_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2021_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2021_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2021_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2021_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2021_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2021_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2021_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2021_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2021_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2021_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2022_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2022_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2022_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2022_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2022_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2022_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2022_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2022_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2022_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2022_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2022_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2022_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2023_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2023_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2023_03.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2023_04.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2023_05.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2023_06.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2023_07.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2023_08.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2023_09.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2023_10.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2023_11.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2023_12.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2024_01.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2024_02.parquet', 'c:\\\\Users\\\\35385\\\\Desktop\\\\CS_Summer_2024\\\\Shared_GH\\\\New-York-App\\\\data-analytics\\\\Datasets/taxi_parquets\\\\yellow_2024_03.parquet']\n",
      "156\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(os.getcwd(), \"Datasets/taxi_parquets\")\n",
    "all_files = glob.glob(os.path.join(data_dir, \"*.parquet\"))\n",
    "print(\"All files found:\", all_files)\n",
    "print(len(all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path for fhvhv_2021_02: /data-analytics/Datasets/taxi_parquets/fhvhv_2021_02.parquet\n",
      "File path for fhv_2021_02: /data-analytics/Datasets/taxi_parquets/fhv_2021-02_parquet\n",
      "File path for yellow_2021_01: /data-analytics/Datasets/taxi_parquets/yellow_2021_01.parquet\n"
     ]
    }
   ],
   "source": [
    "print(\"File path for yellow_2021_01:\", r\"/data-analytics/Datasets/taxi_parquets/yellow_2021_01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\n",
      "Data Directory: Datasets/taxi_parquets\n",
      "fhvhv_2021_02_path: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\Datasets/taxi_parquets\\fhvhv_2021_02.parquet\n",
      "fhv_2021_02_path: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\Datasets/taxi_parquets\\fhv_2021_02.parquet\n",
      "yellow_2021_01_path: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\\Datasets/taxi_parquets\\yellow_2021_01.parquet\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Begin by loading 1 parquet file as pandas dataframe from each of the 4 TLC genres.\n",
    "Error catching across OSes implemented: cwd, data directory, paths etc.\n",
    "\"\"\"\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(\"Current Working Directory:\", cwd)\n",
    "\n",
    "# Define the directory where the data is located relative to the current working directory\n",
    "data_dir = \"Datasets/taxi_parquets\"\n",
    "print(\"Data Directory:\", data_dir)\n",
    "\n",
    "# Define the file paths relative to the data directory\n",
    "fhvhv_2021_02_path = os.path.join(cwd, data_dir, \"fhvhv_2021_02.parquet\")\n",
    "yellow_2021_01_path = os.path.join(cwd, data_dir, \"yellow_2021_01.parquet\")\n",
    "\n",
    "# Print the constructed file paths to verify\n",
    "print(\"fhvhv_2021_02_path:\", fhvhv_2021_02_path)\n",
    "print(\"yellow_2021_01_path:\", yellow_2021_01_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the parquet files using the relative file paths\n",
    "yellow_2021_01 = pd.read_parquet(yellow_2021_01_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory path to save CSV files: Datasets\\taxi_other\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Save dataframes to CSVs, for alternative and efficient analysis\n",
    "Similar error catching as above\n",
    "(Runtime = ~2 mins)\n",
    "\"\"\"\n",
    "\n",
    "directory_path = os.path.join(\"Datasets\", \"taxi_other\")\n",
    "\n",
    "# Print target directory path (error catching)\n",
    "print(\"Directory path to save CSV files:\", directory_path)\n",
    "\n",
    "# Verify the directory exists\n",
    "if not os.path.isdir(directory_path):\n",
    "    raise OSError(f\"Directory does not exist: '{directory_path}'\")\n",
    "\n",
    "# Define file paths for each CSV\n",
    "yellow_file_path = os.path.join(directory_path, \"yellow_2021_01.csv\")\n",
    "fhv_file_path = os.path.join(directory_path, \"fhv_2021_02.csv\")\n",
    "fhvhv_file_path = os.path.join(directory_path, \"fhvhv_2021_02.csv\")\n",
    "\n",
    "# Save each dataframe to its respective CSV file\n",
    "yellow_2021_01.to_csv(yellow_file_path, index=False)\n",
    "fhvhv_2021_02.to_csv(fhvhv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_2021_01 = pd.read_parquet(yellow_2021_01_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigating Yellow Taxi Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:16:29</td>\n",
       "      <td>2021-01-01 00:24:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>224</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:00:28</td>\n",
       "      <td>2021-01-01 00:17:28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>95</td>\n",
       "      <td>157</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:12:29</td>\n",
       "      <td>2021-01-01 00:30:34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:39:16</td>\n",
       "      <td>2021-01-01 01:00:13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>97</td>\n",
       "      <td>129</td>\n",
       "      <td>4</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>28.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:26:12</td>\n",
       "      <td>2021-01-01 00:39:46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>263</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2021-01-01 00:30:10   2021-01-01 00:36:12              1.0   \n",
       "1         1  2021-01-01 00:51:20   2021-01-01 00:52:19              1.0   \n",
       "2         1  2021-01-01 00:43:30   2021-01-01 01:11:06              1.0   \n",
       "3         1  2021-01-01 00:15:48   2021-01-01 00:31:01              0.0   \n",
       "4         2  2021-01-01 00:31:49   2021-01-01 00:48:21              1.0   \n",
       "5         1  2021-01-01 00:16:29   2021-01-01 00:24:30              1.0   \n",
       "6         1  2021-01-01 00:00:28   2021-01-01 00:17:28              1.0   \n",
       "7         1  2021-01-01 00:12:29   2021-01-01 00:30:34              1.0   \n",
       "8         1  2021-01-01 00:39:16   2021-01-01 01:00:13              1.0   \n",
       "9         1  2021-01-01 00:26:12   2021-01-01 00:39:46              2.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           2.10         1.0                  N           142            43   \n",
       "1           0.20         1.0                  N           238           151   \n",
       "2          14.70         1.0                  N           132           165   \n",
       "3          10.60         1.0                  N           138           132   \n",
       "4           4.94         1.0                  N            68            33   \n",
       "5           1.60         1.0                  N           224            68   \n",
       "6           4.10         1.0                  N            95           157   \n",
       "7           5.70         1.0                  N            90            40   \n",
       "8           9.10         1.0                  N            97           129   \n",
       "9           2.70         1.0                  N           263           142   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          8.0    3.0      0.5        0.00           0.0   \n",
       "1             2          3.0    0.5      0.5        0.00           0.0   \n",
       "2             1         42.0    0.5      0.5        8.65           0.0   \n",
       "3             1         29.0    0.5      0.5        6.05           0.0   \n",
       "4             1         16.5    0.5      0.5        4.06           0.0   \n",
       "5             1          8.0    3.0      0.5        2.35           0.0   \n",
       "6             2         16.0    0.5      0.5        0.00           0.0   \n",
       "7             2         18.0    3.0      0.5        0.00           0.0   \n",
       "8             4         27.5    0.5      0.5        0.00           0.0   \n",
       "9             1         12.0    3.0      0.5        3.15           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    0.3         11.80                   2.5          NaN  \n",
       "1                    0.3          4.30                   0.0          NaN  \n",
       "2                    0.3         51.95                   0.0          NaN  \n",
       "3                    0.3         36.35                   0.0          NaN  \n",
       "4                    0.3         24.36                   2.5          NaN  \n",
       "5                    0.3         14.15                   2.5          NaN  \n",
       "6                    0.3         17.30                   0.0          NaN  \n",
       "7                    0.3         21.80                   2.5          NaN  \n",
       "8                    0.3         28.80                   0.0          NaN  \n",
       "9                    0.3         18.95                   2.5          NaN  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellow_2021_01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1369769 entries, 0 to 1369768\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count    Dtype         \n",
      "---  ------                 --------------    -----         \n",
      " 0   VendorID               1369769 non-null  int64         \n",
      " 1   tpep_pickup_datetime   1369769 non-null  datetime64[us]\n",
      " 2   tpep_dropoff_datetime  1369769 non-null  datetime64[us]\n",
      " 3   passenger_count        1271417 non-null  float64       \n",
      " 4   trip_distance          1369769 non-null  float64       \n",
      " 5   RatecodeID             1271417 non-null  float64       \n",
      " 6   store_and_fwd_flag     1271417 non-null  object        \n",
      " 7   PULocationID           1369769 non-null  int64         \n",
      " 8   DOLocationID           1369769 non-null  int64         \n",
      " 9   payment_type           1369769 non-null  int64         \n",
      " 10  fare_amount            1369769 non-null  float64       \n",
      " 11  extra                  1369769 non-null  float64       \n",
      " 12  mta_tax                1369769 non-null  float64       \n",
      " 13  tip_amount             1369769 non-null  float64       \n",
      " 14  tolls_amount           1369769 non-null  float64       \n",
      " 15  improvement_surcharge  1369769 non-null  float64       \n",
      " 16  total_amount           1369769 non-null  float64       \n",
      " 17  congestion_surcharge   1271417 non-null  float64       \n",
      " 18  airport_fee            5 non-null        float64       \n",
      "dtypes: datetime64[us](2), float64(12), int64(4), object(1)\n",
      "memory usage: 198.6+ MB\n"
     ]
    }
   ],
   "source": [
    "yellow_2021_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renaming_yellow_to_standard(dfs):\n",
    "    \"\"\" \n",
    "    Functions for renaming the columns of a dataset or list of datasets to standard names, which will ease the cleaning process\n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            df.rename(columns={\n",
    "                'tpep_pickup_datetime': 'pickup_datetime', \n",
    "                'tpep_dropoff_datetime': 'dropoff_datetime', \n",
    "                'PULocationID': 'pickup_zone', \n",
    "                'DOLocationID': 'dropoff_zone'\n",
    "            }, inplace=True)\n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "\n",
    "renaming_yellow_to_standard(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_float_to_int(dfs):\n",
    "    \"\"\" \n",
    "    Function for converting datatypes of specific columns of a DataFrame or list of DataFrames to appropriate types.\n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            if \"RatecodeID\" in df.columns:\n",
    "                df[\"RatecodeID\"] = df[\"RatecodeID\"].fillna(0).astype(\"int\")\n",
    "            if \"passenger_count\" in df.columns:\n",
    "                df[\"passenger_count\"] = df[\"passenger_count\"].fillna(0).astype(\"int\")\n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "\n",
    "convert_float_to_int(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate rows found\n"
     ]
    }
   ],
   "source": [
    "def duplicated_rows(dfs):\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            duplicate_rows = df[df.duplicated()]\n",
    "            if not duplicate_rows.empty:\n",
    "                print(\"Duplicate rows found:\\n\", duplicate_rows)\n",
    "            else:\n",
    "                print(\"No duplicate rows found\")\n",
    "duplicated_rows(yellow_2021_01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count for each unique value in 'passenger_count' column: in\n",
      "passenger_count\n",
      "1    966236\n",
      "2    161671\n",
      "0    125078\n",
      "3     43935\n",
      "5     31089\n",
      "6     25362\n",
      "4     16391\n",
      "7         5\n",
      "8         2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def passenger_counts(dfs):\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            passenger_count_counts = df['passenger_count'].value_counts()\n",
    "            if not passenger_count_counts.empty:\n",
    "                print(\"Count for each unique value in 'passenger_count' column: in\")\n",
    "                print(passenger_count_counts)\n",
    "\n",
    "passenger_counts(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with invalid fares:  7417\n",
      "5 Sample Rows with Invalid Fares:\n",
      "        VendorID     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
      "961032         2 2021-01-24 19:24:40 2021-01-24 19:28:15                1   \n",
      "791413         2 2021-01-20 19:20:59 2021-01-20 19:24:32                2   \n",
      "699436         1 2021-01-18 19:26:01 2021-01-18 19:27:13                1   \n",
      "288947         2 2021-01-08 17:58:16 2021-01-08 18:10:21                1   \n",
      "107851         2 2021-01-04 16:59:01 2021-01-04 17:04:26                1   \n",
      "\n",
      "        trip_distance  RatecodeID store_and_fwd_flag  pickup_zone  \\\n",
      "961032           0.90           1                  N          186   \n",
      "791413           0.51           1                  N          162   \n",
      "699436           0.10           5                  N          236   \n",
      "288947           1.40           1                  N          264   \n",
      "107851           1.44           1                  N          148   \n",
      "\n",
      "        dropoff_zone  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
      "961032           234             4         -5.0    0.0     -0.5         0.0   \n",
      "791413           161             4         -4.5   -1.0     -0.5         0.0   \n",
      "699436           236             4          0.0    0.0      0.0         0.0   \n",
      "288947           137             4         -9.0   -1.0     -0.5         0.0   \n",
      "107851           107             4         -6.5   -1.0     -0.5         0.0   \n",
      "\n",
      "        tolls_amount  improvement_surcharge  total_amount  \\\n",
      "961032           0.0                   -0.3          -8.3   \n",
      "791413           0.0                   -0.3          -8.8   \n",
      "699436           0.0                    0.3           0.3   \n",
      "288947           0.0                   -0.3         -13.3   \n",
      "107851           0.0                   -0.3         -10.8   \n",
      "\n",
      "        congestion_surcharge  airport_fee  \n",
      "961032                  -2.5          NaN  \n",
      "791413                  -2.5          NaN  \n",
      "699436                   0.0          NaN  \n",
      "288947                  -2.5          NaN  \n",
      "107851                  -2.5          NaN  \n"
     ]
    }
   ],
   "source": [
    "def count_invalid_fares(dfs):\n",
    "    \"\"\"\n",
    "    Count rows where any fare-related column has an invalid value.\n",
    "    \n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "\n",
    "    # Columns to check for invalid fare amounts, <= 0; Need a fare for a valid trip\n",
    "            fare_columns = ['fare_amount', 'total_amount']\n",
    "\n",
    "    # Additional columns to check for negative values, < 0 as \"0\" is a valid value\n",
    "            additional_fare_columns = ['extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge', 'airport_fee']\n",
    "\n",
    "    # Count rows where any fare-related column has an invalid value\n",
    "            invalid_fare_counts = df[\n",
    "                (df[fare_columns] <= 0).any(axis=1) | \n",
    "                (df[additional_fare_columns] < 0).any(axis=1)].shape[0]\n",
    "            print(\"Number of rows with invalid fares: \", invalid_fare_counts)\n",
    "\n",
    "            # Find + print rows where with invalid fares\n",
    "            invalid_fare_rows = df[\n",
    "            (df[fare_columns] <= 0).any(axis=1) |\n",
    "            (df[additional_fare_columns] < 0).any(axis=1)]\n",
    "\n",
    "            # Print 5 sample rows with invalid fares\n",
    "            sample_rows = invalid_fare_rows.sample(n=5, random_state=42)\n",
    "            print(\"5 Sample Rows with Invalid Fares:\")\n",
    "            print(sample_rows)\n",
    "\n",
    "count_invalid_fares(yellow_2021_01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did anyone Time Travel?\n",
      "5642\n",
      "One of the rows where time travel occurred:\n",
      "VendorID                                   1\n",
      "pickup_datetime          2021-01-05 17:43:19\n",
      "dropoff_datetime         2021-01-05 17:39:06\n",
      "passenger_count                            1\n",
      "trip_distance                            0.0\n",
      "RatecodeID                                 1\n",
      "store_and_fwd_flag                         N\n",
      "pickup_zone                              145\n",
      "dropoff_zone                             145\n",
      "payment_type                               2\n",
      "fare_amount                              4.0\n",
      "extra                                    1.0\n",
      "mta_tax                                  0.5\n",
      "tip_amount                               0.0\n",
      "tolls_amount                             0.0\n",
      "improvement_surcharge                    0.3\n",
      "total_amount                             5.8\n",
      "congestion_surcharge                     0.0\n",
      "airport_fee                              NaN\n",
      "Name: 151936, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def time_travel(dfs):    \n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            time_travel = df[df['pickup_datetime'] > df['dropoff_datetime']].shape[0]\n",
    "            print(\"Did anyone Time Travel?\")\n",
    "            print(time_travel)\n",
    "\n",
    "            # Find + print rows where pickup time is after dropoff time\n",
    "            time_travel_rows = df[df['pickup_datetime'] > df['dropoff_datetime']]\n",
    "            if not time_travel_rows.empty:\n",
    "                print(\"One of the rows where time travel occurred:\")\n",
    "                print(time_travel_rows.iloc[0])\n",
    "            else:\n",
    "                print(\"No rows where time travel occurred.\")            \n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "\n",
    "time_travel(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travelling no distances?\n",
      "19952\n",
      "One of the rows of the immovable objects:\n",
      "VendorID                                   1\n",
      "pickup_datetime          2021-01-01 00:03:13\n",
      "dropoff_datetime         2021-01-01 00:03:19\n",
      "passenger_count                            1\n",
      "trip_distance                            0.0\n",
      "RatecodeID                                 1\n",
      "store_and_fwd_flag                         N\n",
      "pickup_zone                              169\n",
      "dropoff_zone                             169\n",
      "payment_type                               3\n",
      "fare_amount                              0.0\n",
      "extra                                    0.0\n",
      "mta_tax                                  0.0\n",
      "tip_amount                               0.0\n",
      "tolls_amount                             0.0\n",
      "improvement_surcharge                    0.0\n",
      "total_amount                             0.0\n",
      "congestion_surcharge                     0.0\n",
      "airport_fee                              NaN\n",
      "Name: 38, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def immovable_objects(dfs):    \n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            negative_distances = df[df['trip_distance'] <= 0].shape[0]\n",
    "            print(\"Travelling no distances?\")\n",
    "            print(negative_distances)\n",
    "\n",
    "            # Find + print rows where pickup time is after dropoff time\n",
    "            negative_distances_rows = df[df['trip_distance'] <= 0]\n",
    "            if not negative_distances_rows.empty:\n",
    "                print(\"One of the rows of the immovable objects:\")\n",
    "                print(negative_distances_rows.iloc[0]) #change this number for other examples\n",
    "            else:\n",
    "                print(\"No rows where time travel occurred.\")\n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "\n",
    "immovable_objects(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with payment_type 4 (Dispute): 5667\n",
      "5 Sample Rows with payment_type 4 (Dispute):\n",
      "         VendorID     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
      "1047827         1 2021-01-26 19:22:23 2021-01-26 19:23:29                1   \n",
      "964262          2 2021-01-24 22:25:40 2021-01-24 22:32:23                1   \n",
      "1102473         1 2021-01-28 03:27:12 2021-01-28 03:30:50                1   \n",
      "995123          1 2021-01-25 16:32:28 2021-01-25 16:36:57                1   \n",
      "900844          2 2021-01-23 09:14:12 2021-01-23 09:45:20                2   \n",
      "\n",
      "         trip_distance  RatecodeID store_and_fwd_flag  pickup_zone  \\\n",
      "1047827           2.10           1                  N          262   \n",
      "964262            0.99           1                  N          100   \n",
      "1102473           0.50           1                  N          239   \n",
      "995123            0.80           1                  N          234   \n",
      "900844            2.39           1                  N          263   \n",
      "\n",
      "         dropoff_zone  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
      "1047827           262             4          3.0    3.5      0.5         0.0   \n",
      "964262            170             4         -6.0   -0.5     -0.5         0.0   \n",
      "1102473           142             4          4.5    3.0      0.5         0.0   \n",
      "995123            186             4          5.5    3.5      0.5         0.0   \n",
      "900844            263             4        -20.0    0.0     -0.5         0.1   \n",
      "\n",
      "         tolls_amount  improvement_surcharge  total_amount  \\\n",
      "1047827           0.0                    0.3           7.3   \n",
      "964262            0.0                   -0.3          -9.8   \n",
      "1102473           0.0                    0.3           8.3   \n",
      "995123            0.0                    0.3           9.8   \n",
      "900844            0.0                   -0.3         -23.2   \n",
      "\n",
      "         congestion_surcharge  airport_fee  \n",
      "1047827                   2.5          NaN  \n",
      "964262                   -2.5          NaN  \n",
      "1102473                   2.5          NaN  \n",
      "995123                    2.5          NaN  \n",
      "900844                   -2.5          NaN  \n"
     ]
    }
   ],
   "source": [
    "def check_dispute_payments(dfs):\n",
    "    \"\"\"\n",
    "    Count rows where payment_type is 4 (Dispute) and print sample rows.\n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    \n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            # Count rows where payment_type is 4 (Dispute)\n",
    "            dispute_count = df[df['payment_type'] == 4].shape[0]\n",
    "            print(\"Number of rows with payment_type 4 (Dispute):\", dispute_count)\n",
    "\n",
    "            # Find rows where payment_type is 4 (Dispute)\n",
    "            dispute_rows = df[df['payment_type'] == 4]\n",
    "\n",
    "            # Print 5 sample rows with payment_type 4 (Dispute)\n",
    "            sample_rows = dispute_rows.sample(n=5, random_state=42)\n",
    "            print(\"5 Sample Rows with payment_type 4 (Dispute):\")\n",
    "            print(sample_rows)\n",
    "\n",
    "check_dispute_payments(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the 'airport_fee' column and their counts:\n",
      "airport_fee\n",
      "0.0    5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def check_airport_fee_values(dfs):\n",
    "    \"\"\"\n",
    "    Print all unique values in the 'airport_fee' column and their counts.\n",
    "    \"\"\"\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            # Get the unique values and their counts in the 'airport_fee' column\n",
    "            unique_values_counts = df['airport_fee'].value_counts()\n",
    "            \n",
    "            # Print the unique values and their counts\n",
    "            print(\"Unique values in the 'airport_fee' column and their counts:\")\n",
    "            print(unique_values_counts)\n",
    "\n",
    "check_airport_fee_values(yellow_2021_01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the trip would result in the drivers having to operate the taxicab for more than 12 consecutive hours, which is prohibited, then that driver may refuse to take a passenger to these destinations.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\n",
      "Taxi Zone CSV Directory: Datasets/taxi_other\n",
      "Number of Unique Zones: 69\n",
      "List of Unique Zones: [  4  12  13  24  41  42  43  45  48  50  68  74  75  79  87  88  90 100\n",
      " 103 104 105 107 113 114 116 120 125 127 128 137 140 141 142 143 144 148\n",
      " 151 152 153 158 161 162 163 164 166 170 186 194 202 209 211 224 229 230\n",
      " 231 232 233 234 236 237 238 239 243 244 246 249 261 262 263]\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Working Directory:\", cwd)\n",
    "\n",
    "# Define the directory where the data is located relative to the current working directory\n",
    "taxi_zone_dir = \"Datasets/taxi_other\"\n",
    "print(\"Taxi Zone CSV Directory:\", taxi_zone_dir)\n",
    "\n",
    "# Define the file path relative to the data directory\n",
    "taxi_zone_path = os.path.join(cwd, taxi_zone_dir, \"taxi_zone_lookup.csv\")\n",
    "\n",
    "taxi_zone = pd.read_csv(taxi_zone_path, keep_default_na=True, delimiter=\",\", skipinitialspace=True, encoding=\"Windows-1252\")\n",
    "\n",
    "def valid_zones_1(df):\n",
    "    manhattan_df = df[df[\"Borough\"] == \"Manhattan\"]\n",
    "    unique_zones = manhattan_df[\"LocationID\"].unique()\n",
    "    \n",
    "    print(f\"Number of Unique Zones: {len(unique_zones)}\")\n",
    "    print(\"List of Unique Zones:\", unique_zones)\n",
    "\n",
    "valid_zones_1(taxi_zone)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\n",
      "Taxi Zone CSV Directory: Datasets/taxi_other\n",
      "Number of Unique Zones: 67\n",
      "List of Unique Zones: [  4  24  12  13  41  45  42  43  48  50  68  79  74  75  87  88  90 125\n",
      " 100 103 107 113 114 116 120 127 128 151 140 137 141 142 152 143 144 148\n",
      " 153 158 161 162 163 164 170 166 186 194 202 209 211 224 229 230 231 239\n",
      " 232 233 234 236 237 238 263 243 244 246 249 261 262]\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Working Directory:\", cwd)\n",
    "\n",
    "# Define the directory where the data is located relative to the current working directory\n",
    "taxi_zone_dir = \"Datasets/taxi_other\"\n",
    "print(\"Taxi Zone CSV Directory:\", taxi_zone_dir)\n",
    "\n",
    "# Define the file path relative to the data directory\n",
    "taxi_zone_alternate_path = os.path.join(cwd, taxi_zone_dir, \"taxi_zones_alternate.csv\")\n",
    "\n",
    "taxi_zone_alternate = pd.read_csv(taxi_zone_alternate_path, keep_default_na=True, delimiter=\",\", skipinitialspace=True, encoding=\"Windows-1252\")\n",
    "\n",
    "def valid_zones_alternate(df):\n",
    "    manhattan_df = df[df[\"borough\"] == \"Manhattan\"] # Change in capitalisation of \"Borough\"\n",
    "    unique_zones = manhattan_df[\"LocationID\"].unique()\n",
    "    \n",
    "    print(f\"Number of Unique Zones: {len(unique_zones)}\")\n",
    "    print(\"List of Unique Zones:\", unique_zones)\n",
    "\n",
    "valid_zones_alternate(taxi_zone_alternate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\35385\\Desktop\\CS_Summer_2024\\Shared_GH\\New-York-App\\data-analytics\n",
      "Number of Unique Zones in CSV 1: 69\n",
      "List of Unique Zones in CSV 1: [4, 12, 13, 24, 41, 42, 43, 45, 48, 50, 68, 74, 75, 79, 87, 88, 90, 100, 103, 104, 105, 107, 113, 114, 116, 120, 125, 127, 128, 137, 140, 141, 142, 143, 144, 148, 151, 152, 153, 158, 161, 162, 163, 164, 166, 170, 186, 194, 202, 209, 211, 224, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 243, 244, 246, 249, 261, 262, 263]\n",
      "Number of Unique Zones in CSV 2: 67\n",
      "List of Unique Zones in CSV 2: [4, 12, 13, 24, 41, 42, 43, 45, 48, 50, 68, 74, 75, 79, 87, 88, 90, 100, 103, 107, 113, 114, 116, 120, 125, 127, 128, 137, 140, 141, 142, 143, 144, 148, 151, 152, 153, 158, 161, 162, 163, 164, 166, 170, 186, 194, 202, 209, 211, 224, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 243, 244, 246, 249, 261, 262, 263]\n",
      "Zones only in CSV 1: [104, 105]\n",
      "Zones only in CSV 2: []\n",
      "Zones present only in the first CSV: {104, 105}\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(\"Current Working Directory:\", cwd)\n",
    "\n",
    "# Load the CSV files\n",
    "taxi_zone1 = pd.read_csv(taxi_zone_path, keep_default_na=True, delimiter=\",\", skipinitialspace=True, encoding=\"Windows-1252\")\n",
    "taxi_zone2 = pd.read_csv(taxi_zone_alternate_path, keep_default_na=True, delimiter=\",\", skipinitialspace=True, encoding=\"Windows-1252\")\n",
    "\n",
    "# Define a function to get unique zones for Manhattan\n",
    "def get_unique_zones(df, borough_col):\n",
    "    manhattan_df = df[df[borough_col] == \"Manhattan\"]\n",
    "    unique_zones = manhattan_df[\"LocationID\"].unique()\n",
    "    return set(unique_zones)\n",
    "\n",
    "# Get unique zones for Manhattan from both CSVs\n",
    "unique_zones1 = get_unique_zones(taxi_zone1, \"Borough\")\n",
    "unique_zones2 = get_unique_zones(taxi_zone2, \"borough\")\n",
    "\n",
    "# Print the unique zones and their counts\n",
    "print(f\"Number of Unique Zones in CSV 1: {len(unique_zones1)}\")\n",
    "print(f\"List of Unique Zones in CSV 1: {sorted(unique_zones1)}\")\n",
    "\n",
    "print(f\"Number of Unique Zones in CSV 2: {len(unique_zones2)}\")\n",
    "print(f\"List of Unique Zones in CSV 2: {sorted(unique_zones2)}\")\n",
    "\n",
    "# Identify the differences\n",
    "zones_only_in_csv1 = unique_zones1 - unique_zones2\n",
    "zones_only_in_csv2 = unique_zones2 - unique_zones1\n",
    "\n",
    "print(f\"Zones only in CSV 1: {sorted(zones_only_in_csv1)}\")\n",
    "print(f\"Zones only in CSV 2: {sorted(zones_only_in_csv2)}\")\n",
    "\n",
    "# Analyze the differences to determine correctness\n",
    "if zones_only_in_csv1:\n",
    "    print(f\"Zones present only in the first CSV: {zones_only_in_csv1}\")\n",
    "\n",
    "if zones_only_in_csv2:\n",
    "    print(f\"Zones present only in the second CSV: {zones_only_in_csv2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use CSV 1, \"taxi_zone_lookup.csv\". It has 2 zones not in \"taxi_zones_alternate.csv\", and these zones are present at least in the fhv parquets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get unique zones for Manhattan\n",
    "def get_manhattan_zones(df):\n",
    "    manhattan_df = df[df[\"Borough\"] == \"Manhattan\"]\n",
    "    unique_zones = manhattan_df[\"LocationID\"].unique()\n",
    "    return set(unique_zones)\n",
    "\n",
    "# Get the unique Manhattan zones from the taxi_zone DataFrame\n",
    "manhattan_zones = get_manhattan_zones(taxi_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to check pickup and dropoff zones\n",
    "def check_zones(df, manhattan_zones):\n",
    "    # Check if both pickup_zone and dropoff_zone are not in manhattan_zones\n",
    "    invalid_zones = df[~df[\"pickup_zone\"].isin(manhattan_zones) & ~df[\"dropoff_zone\"].isin(manhattan_zones)]\n",
    "    \n",
    "    print(f\"Invalid zones count: {invalid_zones.shape[0]}\")\n",
    "    \n",
    "    if not invalid_zones.empty:\n",
    "        print(\"Examples of rows with invalid zones:\")\n",
    "        print(invalid_zones.head())  # Print first few invalid rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid zones count: 96421\n",
      "Examples of rows with invalid zones:\n",
      "    VendorID     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
      "2          1 2021-01-01 00:43:30 2021-01-01 01:11:06                1   \n",
      "3          1 2021-01-01 00:15:48 2021-01-01 00:31:01                0   \n",
      "6          1 2021-01-01 00:00:28 2021-01-01 00:17:28                1   \n",
      "8          1 2021-01-01 00:39:16 2021-01-01 01:00:13                1   \n",
      "11         2 2021-01-01 00:46:36 2021-01-01 00:53:45                2   \n",
      "\n",
      "    trip_distance  RatecodeID store_and_fwd_flag  pickup_zone  dropoff_zone  \\\n",
      "2           14.70           1                  N          132           165   \n",
      "3           10.60           1                  N          138           132   \n",
      "6            4.10           1                  N           95           157   \n",
      "8            9.10           1                  N           97           129   \n",
      "11           1.21           1                  N          255            80   \n",
      "\n",
      "    payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "2              1         42.0    0.5      0.5        8.65           0.0   \n",
      "3              1         29.0    0.5      0.5        6.05           0.0   \n",
      "6              2         16.0    0.5      0.5        0.00           0.0   \n",
      "8              4         27.5    0.5      0.5        0.00           0.0   \n",
      "11             1          7.0    0.5      0.5        2.49           0.0   \n",
      "\n",
      "    improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
      "2                     0.3         51.95                   0.0          NaN  \n",
      "3                     0.3         36.35                   0.0          NaN  \n",
      "6                     0.3         17.30                   0.0          NaN  \n",
      "8                     0.3         28.80                   0.0          NaN  \n",
      "11                    0.3         10.79                   0.0          NaN  \n"
     ]
    }
   ],
   "source": [
    "check_zones(yellow_2021_01, manhattan_zones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Rows Borough Counts:\n",
      "Borough_combined\n",
      "Queens (pickup), Queens (dropoff)                  27520\n",
      "Brooklyn (pickup), Brooklyn (dropoff)              18404\n",
      "Queens (pickup), Brooklyn (dropoff)                14348\n",
      "Bronx (pickup), Bronx (dropoff)                     8570\n",
      "Unknown (pickup), Unknown (dropoff)                 5555\n",
      "Queens (pickup), Bronx (dropoff)                    3768\n",
      "Brooklyn (pickup), Queens (dropoff)                 2600\n",
      "Bronx (pickup), Queens (dropoff)                    1092\n",
      "Brooklyn (pickup), Bronx (dropoff)                  1082\n",
      "Bronx (pickup), Brooklyn (dropoff)                  1030\n",
      "Unknown (pickup), Queens (dropoff)                   383\n",
      "Queens (pickup), Unknown (dropoff)                   357\n",
      "Unknown (pickup), Brooklyn (dropoff)                 337\n",
      "Queens (pickup), Staten Island (dropoff)             249\n",
      "Brooklyn (pickup), Staten Island (dropoff)           174\n",
      "Staten Island (pickup), Queens (dropoff)             106\n",
      "Staten Island (pickup), Brooklyn (dropoff)           105\n",
      "Unknown (pickup), Bronx (dropoff)                     97\n",
      "Queens (pickup), EWR (dropoff)                        80\n",
      "Brooklyn (pickup), Unknown (dropoff)                  77\n",
      "Bronx (pickup), Unknown (dropoff)                     54\n",
      "Staten Island (pickup), Staten Island (dropoff)       50\n",
      "Staten Island (pickup), Bronx (dropoff)               48\n",
      "EWR (pickup), EWR (dropoff)                           43\n",
      "Bronx (pickup), Staten Island (dropoff)               43\n",
      "Brooklyn (pickup), EWR (dropoff)                      12\n",
      "EWR (pickup), Unknown (dropoff)                        9\n",
      "Unknown (pickup), EWR (dropoff)                        4\n",
      "Staten Island (pickup), Unknown (dropoff)              3\n",
      "Unknown (pickup), Staten Island (dropoff)              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def verifying_invalid_zones(df, manhattan_zones, taxi_zone_csv):\n",
    "    # Identify invalid rows where both pickup_zone and dropoff_zone are not in manhattan_zones\n",
    "    invalid_zones = df[~df[\"pickup_zone\"].isin(manhattan_zones) & ~df[\"dropoff_zone\"].isin(manhattan_zones)]\n",
    "    \n",
    "    # If there are no invalid rows, print and return\n",
    "    if invalid_zones.empty:\n",
    "        print(\"No invalid zones found.\")\n",
    "        return\n",
    "    \n",
    "    # Merge invalid zones with taxi_zone_csv to get borough information for both pickup_zone and dropoff_zone\n",
    "    invalid_zones_merged = invalid_zones.merge(taxi_zone_csv, left_on=\"pickup_zone\", right_on=\"LocationID\", how=\"left\", suffixes=('_pickup', '_dropoff'))\n",
    "    invalid_zones_merged = invalid_zones_merged.merge(taxi_zone_csv, left_on=\"dropoff_zone\", right_on=\"LocationID\", how=\"left\", suffixes=('_pickup', '_dropoff'))\n",
    "\n",
    "    # Concatenate Borough columns for analysis\n",
    "    invalid_zones_merged[\"Borough_combined\"] = invalid_zones_merged[\"Borough_pickup\"] + \" (pickup), \" + invalid_zones_merged[\"Borough_dropoff\"] + \" (dropoff)\"\n",
    "    \n",
    "    # Count the combined Borough information\n",
    "    combined_borough_counts = invalid_zones_merged[\"Borough_combined\"].value_counts()\n",
    "\n",
    "    print(\"Invalid Rows Borough Counts:\")\n",
    "    print(combined_borough_counts)\n",
    "\n",
    "manhattan_zones = get_manhattan_zones(taxi_zone)\n",
    "\n",
    "# Call the verifying_invalid_zones function\n",
    "verifying_invalid_zones(yellow_2021_01, manhattan_zones, taxi_zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Data Quality Report**\n",
    "- **Data Integrity Checks** \n",
    "\n",
    "Having investigated the CSVs, a number of data inconsistincies are present. They are summarised below:\n",
    "\n",
    "- Check 0: No duplicate rows present\n",
    "\n",
    "- Check 1: There are a number of trips with 0 passengers, as well as trip with more than 5 passengers. According to the TLC data dictionary, 5 is the maximum amount of passengers allowed. 0 might represent trips that didn't occur or were cancelled, or serve another purpose. As our goal is to track Busy-ness in NYC, values of 0, 6, 7 and 8 cannot be counted as valid.\n",
    "    - Drop rows from dataset where \"passenger_count\" == 0, 6, 7, 8.\n",
    "\n",
    "- Check 2: There are a number of trips with negative fare amounts. Negative fares could represent refunds or errors in the data entry, and are not likely to represent actual trips where passengers were transported. Since our goal is to track busyness in NYC, negative fare amounts cannot be considered valid data points.\n",
    "    - Drop rows from the dataset where \"fare_amount\" or \"total_amount\" <= 0 (0 is not a valid value)\n",
    "    - Drop rows from the dataset where \"extra\", \"mta_tax\", \"tip_amount'\", \"tolls_amount\", \"improvement_surcharge\", \"congestion_surcharge\", \"airport_fee\" < 0 (\"0\" is a valid value).\n",
    "    \n",
    "- Check 3: There are a number of trips where the pickup time is exactly the same as the dropoff time. This means no time has elapsed for the trip, which is suspicious and likely indicates invalid data points. There are also rows where the pickup time is later in time than the dropoff time (implying time travel). Further checks reveal additional inconsistencies:\n",
    "    - Further Checks:\n",
    "        -> The trip_distance is variable, ranging from 0 miles to over 13 miles, which is implausible for zero or negative elapsed time.\n",
    "        -> The total_amount is also variable, with fares ranging from $6 to over $48, despite zero minutes of travel time.\n",
    "        -> These data points are difficult to trust and it is hard to believe that they represent valid trips.\n",
    "            - Drop rows from the dataset where pickup_datetime == dropoff_datetime.\n",
    "\n",
    "- Check 4: There are some journeys with 0 trip distance, potentially indicating cancelled trips, or invalid ones. These rows do not represent busy-ness, as it is difficult to say that a trip occurred at all. Confusingly, these trips show a variation in total_amount from (-492.8 to +900.35).\n",
    "    - Drop rows from the dataset where \"trip_distance\" <= 0.\n",
    " \n",
    "- Check 5: According to the Yellow Taxi Data Dictionary (appended at bottom), RateCodeID, the final rate code in effect at the end of the trip, should have a value of 1-6. There are a number of rows with a value of \"99\". Some of these rows have varied and valid datetimes, total_amount, passenger_count,  and trip_distance. It is unclear what code \"99\" means, but according to the Data Dictionary, only rows with values of 1-6 are valid.\n",
    "    - Drop rows from the dataset where RateCodeID != 1-6.\n",
    "\n",
    "- Check 6: Disputed payments (payment_type == 4) often indicate issues with the fare. These might be unpaid, mispaid, or late charges. Disputes may suggest problems like incorrect dropoff locations or other inaccuracies in the journey data. The validity of these trips is questionable, as they may not accurately represent completed journeys.\n",
    "    - Drop rows from the dataset where payment_type == 4.\n",
    "\n",
    "- Check 7: The \"airport_fee\" contained only 5 entries with value 0, and the rest of the entries were NaN. This fee might be infrequently applied or waived altogether in the majority of recorded taxi journeys. \n",
    "    - Drop \"airport_fee\" column from dataset due to missing values.\n",
    "\n",
    "- Check 8: According to the accompanying \"taxi_zone_lookup.csv\" file, both the pickup_zone and dropoff_zone should be in Manhattan zones. Rows where neither pickup_zone nor dropoff_zone are in Manhattan zones are considered invalid.\n",
    "    - Drop rows from the dataset where both pickup_zone and dropoff_zone are not Manhattan zones.\n",
    "\n",
    "See also: \n",
    "    https://rules.cityofnewyork.us/rule/taximeter-rate-of-fare-and-various-surcharges/\n",
    "    https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf\n",
    "    https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_green.pdf\n",
    "    https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_fhv.pdf\n",
    "    https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_hvfhs.pdf\n",
    "    https://www.nyc.gov/site/tlc/passengers/passenger-frequently-asked-questions.page \n",
    "    https://www.nyc.gov/site/tlc/passengers/taxi-fare.page \n",
    "    https://www.nyc.gov/assets/tlc/downloads/pdf/archived_public_notices/public_notice_09_17_09.pdf\n",
    "    https://www.nyc.gov/assets/tlc/downloads/pdf/trip_record_user_guide.pdf \n",
    "    https://data.cityofnewyork.us/City-Government/NTA-map/d3qk-pfyz\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_yellow_invalid_rows(dfs, manhattan_zones, taxi_zone_csv):\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "\n",
    "    cleaned_dfs = []\n",
    "    \n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            # Drop duplicate rows\n",
    "            df = df.drop_duplicates()\n",
    "            \n",
    "            # Drop \"airport_fee\" column due to missing values\n",
    "            if \"airport_fee\" in df.columns:\n",
    "                df = df.drop(columns=[\"airport_fee\"])\n",
    "            \n",
    "            # Drop rows where passenger_count == 0 or >= 6\n",
    "            df = df[(df[\"passenger_count\"] > 0) & (df[\"passenger_count\"] < 6)]\n",
    "            \n",
    "            # Drop rows where fare_amount or total_amount <= 0\n",
    "            df = df[(df[\"fare_amount\"] > 0) & (df[\"total_amount\"] > 0)]\n",
    "            \n",
    "            # Drop rows where extra, mta_tax, tip_amount, tolls_amount, improvement_surcharge, or congestion_surcharge < 0\n",
    "            df = df[(df[\"extra\"] >= 0) & (df[\"mta_tax\"] >= 0) & (df[\"tip_amount\"] >= 0) & \n",
    "                    (df[\"tolls_amount\"] >= 0) & (df[\"improvement_surcharge\"] >= 0) & \n",
    "                    (df[\"congestion_surcharge\"] >= 0)]\n",
    "            \n",
    "            # Drop rows where pickup_datetime == dropoff_datetime\n",
    "            df = df[df[\"pickup_datetime\"] != df[\"dropoff_datetime\"]]\n",
    "            \n",
    "            # Drop rows where trip_distance <= 0\n",
    "            df = df[df[\"trip_distance\"] > 0]\n",
    "            \n",
    "            # Drop rows where RateCodeID != 1-6\n",
    "            df = df[df[\"RatecodeID\"].isin([1, 2, 3, 4, 5, 6])]\n",
    "            \n",
    "            # Drop rows where payment_type == 4\n",
    "            df = df[df[\"payment_type\"] != 4]\n",
    "            \n",
    "            # Drop rows where both pickup_zone and dropoff_zone are not Manhattan zones\n",
    "            df = df[df[\"pickup_zone\"].isin(manhattan_zones) | df[\"dropoff_zone\"].isin(manhattan_zones)]\n",
    "            \n",
    "            # Append the cleaned DataFrame to the list\n",
    "            cleaned_dfs.append(df)\n",
    "        else:\n",
    "            print(\"Warning: The list contains non-DataFrame elements\")\n",
    "    \n",
    "    # Return the cleaned DataFrame(s)\n",
    "    if len(cleaned_dfs) == 1:\n",
    "        return cleaned_dfs[0]\n",
    "    else:\n",
    "        return cleaned_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_zones = get_manhattan_zones(taxi_zone)\n",
    "\n",
    "# Call the verifying_invalid_zones function\n",
    "yellow_2021_01 = drop_yellow_invalid_rows(yellow_2021_01, manhattan_zones, taxi_zone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1149499 entries, 0 to 1271416\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count    Dtype         \n",
      "---  ------                 --------------    -----         \n",
      " 0   VendorID               1149499 non-null  int64         \n",
      " 1   pickup_datetime        1149499 non-null  datetime64[us]\n",
      " 2   dropoff_datetime       1149499 non-null  datetime64[us]\n",
      " 3   passenger_count        1149499 non-null  int32         \n",
      " 4   trip_distance          1149499 non-null  float64       \n",
      " 5   RatecodeID             1149499 non-null  int32         \n",
      " 6   store_and_fwd_flag     1149499 non-null  object        \n",
      " 7   pickup_zone            1149499 non-null  int64         \n",
      " 8   dropoff_zone           1149499 non-null  int64         \n",
      " 9   payment_type           1149499 non-null  int64         \n",
      " 10  fare_amount            1149499 non-null  float64       \n",
      " 11  extra                  1149499 non-null  float64       \n",
      " 12  mta_tax                1149499 non-null  float64       \n",
      " 13  tip_amount             1149499 non-null  float64       \n",
      " 14  tolls_amount           1149499 non-null  float64       \n",
      " 15  improvement_surcharge  1149499 non-null  float64       \n",
      " 16  total_amount           1149499 non-null  float64       \n",
      " 17  congestion_surcharge   1149499 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(9), int32(2), int64(4), object(1)\n",
      "memory usage: 157.9+ MB\n"
     ]
    }
   ],
   "source": [
    "yellow_2021_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_yellow_columns(df):\n",
    "    columns_to_drop = [\"VendorID\", \"trip_distance\", \"RatecodeID\", \"store_and_fwd_flag\", \"payment_type\", \n",
    "                       \"fare_amount\", \"extra\", \"mta_tax\", \"improvement_surcharge\", \"tip_amount\", \n",
    "                       \"tolls_amount\", \"total_amount\", \"congestion_surcharge\", \"airport_fee\"]\n",
    "    \n",
    "    # Drop only the columns that exist in the DataFrame\n",
    "    existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "    df.drop(columns=existing_columns_to_drop, inplace=True)\n",
    "\n",
    "    # Return the modified DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_2021_01 = drop_yellow_columns(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1149499 entries, 0 to 1271416\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count    Dtype         \n",
      "---  ------            --------------    -----         \n",
      " 0   pickup_datetime   1149499 non-null  datetime64[us]\n",
      " 1   dropoff_datetime  1149499 non-null  datetime64[us]\n",
      " 2   passenger_count   1149499 non-null  int32         \n",
      " 3   pickup_zone       1149499 non-null  int64         \n",
      " 4   dropoff_zone      1149499 non-null  int64         \n",
      "dtypes: datetime64[us](2), int32(1), int64(2)\n",
      "memory usage: 48.2 MB\n"
     ]
    }
   ],
   "source": [
    "yellow_2021_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_values(dfs):\n",
    "    \"\"\"\n",
    "    Drops any rows with missing values from the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to clean.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "        int: The number of rows that were dropped.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "\n",
    "    cleaned_dfs = []\n",
    "    \n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):    # Count the number of rows before dropping missing values\n",
    "            initial_row_count = df.shape[0]\n",
    "    \n",
    "            # Drop rows with missing values\n",
    "            df = df.dropna()\n",
    "    \n",
    "            # Count the number of rows after dropping missing values\n",
    "            final_row_count = df.shape[0]\n",
    "    \n",
    "            # Calculate the number of rows that were dropped\n",
    "            rows_dropped = initial_row_count - final_row_count\n",
    "        print(f\"Number of rows dropped: {rows_dropped}\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_zone</th>\n",
       "      <th>dropoff_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-01 00:16:29</td>\n",
       "      <td>2021-01-01 00:24:30</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-01 00:12:29</td>\n",
       "      <td>2021-01-01 00:30:34</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271412</th>\n",
       "      <td>2021-01-31 23:58:47</td>\n",
       "      <td>2021-02-01 00:04:40</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271413</th>\n",
       "      <td>2021-01-31 23:07:54</td>\n",
       "      <td>2021-01-31 23:19:42</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271414</th>\n",
       "      <td>2021-01-31 23:30:45</td>\n",
       "      <td>2021-01-31 23:35:13</td>\n",
       "      <td>1</td>\n",
       "      <td>233</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271415</th>\n",
       "      <td>2021-01-31 23:09:52</td>\n",
       "      <td>2021-01-31 23:51:56</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271416</th>\n",
       "      <td>2021-01-31 23:26:15</td>\n",
       "      <td>2021-01-31 23:33:48</td>\n",
       "      <td>2</td>\n",
       "      <td>230</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149499 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pickup_datetime    dropoff_datetime  passenger_count  pickup_zone  \\\n",
       "0       2021-01-01 00:30:10 2021-01-01 00:36:12                1          142   \n",
       "1       2021-01-01 00:51:20 2021-01-01 00:52:19                1          238   \n",
       "4       2021-01-01 00:31:49 2021-01-01 00:48:21                1           68   \n",
       "5       2021-01-01 00:16:29 2021-01-01 00:24:30                1          224   \n",
       "7       2021-01-01 00:12:29 2021-01-01 00:30:34                1           90   \n",
       "...                     ...                 ...              ...          ...   \n",
       "1271412 2021-01-31 23:58:47 2021-02-01 00:04:40                3           41   \n",
       "1271413 2021-01-31 23:07:54 2021-01-31 23:19:42                1          113   \n",
       "1271414 2021-01-31 23:30:45 2021-01-31 23:35:13                1          233   \n",
       "1271415 2021-01-31 23:09:52 2021-01-31 23:51:56                2           56   \n",
       "1271416 2021-01-31 23:26:15 2021-01-31 23:33:48                2          230   \n",
       "\n",
       "         dropoff_zone  \n",
       "0                  43  \n",
       "1                 151  \n",
       "4                  33  \n",
       "5                  68  \n",
       "7                  40  \n",
       "...               ...  \n",
       "1271412            74  \n",
       "1271413           141  \n",
       "1271414           237  \n",
       "1271415            68  \n",
       "1271416           229  \n",
       "\n",
       "[1149499 rows x 5 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_missing_values(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zone_busy(yellow_df):\n",
    "    # Combine pickup and dropoff data into a single DataFrame; Renamed and combined into a single datetime column\n",
    "    pickup_data = yellow_df[['pickup_datetime', 'passenger_count', 'pickup_zone']].rename(columns={'pickup_datetime': 'datetime', 'pickup_zone': 'zone'})\n",
    "    dropoff_data = yellow_df[['dropoff_datetime', 'passenger_count', 'dropoff_zone']].rename(columns={'dropoff_datetime': 'datetime', 'dropoff_zone': 'zone'})\n",
    "    combined_data = pd.concat([pickup_data, dropoff_data])\n",
    "    \n",
    "    # Round datetime to the nearest hour\n",
    "    combined_data['datetime'] = combined_data['datetime'].dt.round('h')\n",
    "    \n",
    "    # Group by hour and zone, summing passenger counts\n",
    "    zone_busy_df = combined_data.groupby(['datetime', 'zone'])['passenger_count'].sum().reset_index()\n",
    "    \n",
    "    return zone_busy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_2021_01 = calculate_zone_busy(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 73636 entries, 0 to 73635\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   datetime         73636 non-null  datetime64[us]\n",
      " 1   zone             73636 non-null  int64         \n",
      " 2   passenger_count  73636 non-null  int32         \n",
      "dtypes: datetime64[us](1), int32(1), int64(1)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "yellow_2021_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>zone</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-13 12:00:00</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-31 14:00:00</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-31 14:00:00</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-31 18:00:00</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-31 18:00:00</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-12-31 18:00:00</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-12-31 18:00:00</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-12-31 19:00:00</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-12-31 19:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-12-31 19:00:00</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  zone  passenger_count\n",
       "0 2020-10-13 12:00:00   234                1\n",
       "1 2020-12-31 14:00:00   170                1\n",
       "2 2020-12-31 14:00:00   226                1\n",
       "3 2020-12-31 18:00:00    48                1\n",
       "4 2020-12-31 18:00:00    68                1\n",
       "5 2020-12-31 18:00:00   142                2\n",
       "6 2020-12-31 18:00:00   239                1\n",
       "7 2020-12-31 19:00:00    48                2\n",
       "8 2020-12-31 19:00:00    90                1\n",
       "9 2020-12-31 19:00:00   233                1"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellow_2021_01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count for each unique value in 'passenger_count' column: in\n",
      "passenger_count\n",
      "1    909754\n",
      "2    153143\n",
      "3     41637\n",
      "5     29616\n",
      "4     15349\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def passenger_counts(dfs):\n",
    "    if isinstance(dfs, pd.DataFrame):\n",
    "        dfs = [dfs]  # Convert single DataFrame to a list of one DataFrame\n",
    "    for df in dfs:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            passenger_count_counts = df['passenger_count'].value_counts()\n",
    "            if not passenger_count_counts.empty:\n",
    "                print(\"Count for each unique value in 'passenger_count' column: in\")\n",
    "                print(passenger_count_counts)\n",
    "\n",
    "passenger_counts(yellow_2021_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to: Datasets\\taxi_other\\yellow_2021_01_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "directory_path = os.path.join(\"Datasets\", \"taxi_other\")\n",
    "\n",
    "\n",
    "# Define the file path\n",
    "file_path = os.path.join(directory_path, \"yellow_2021_01_cleaned.csv\")\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "yellow_2021_01.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"DataFrame saved to:\", file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have 156 parquet files, and 39 of these are \"yellow\" taxi files. This is a lot of data. I want to load the files 1 by 1, give them appropriate names, and clean them. I want to do it 1 by 1 so that not too much memory is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>originating_base_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "      <th>access_a_ride_flag</th>\n",
       "      <th>wav_request_flag</th>\n",
       "      <th>wav_match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02764</td>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-01-31 23:59:00</td>\n",
       "      <td>2021-02-01 00:10:19</td>\n",
       "      <td>2021-02-01 00:10:40</td>\n",
       "      <td>2021-02-01 00:21:09</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>2.060</td>\n",
       "      <td>...</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.79</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02764</td>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-02-01 00:13:35</td>\n",
       "      <td>2021-02-01 00:25:23</td>\n",
       "      <td>2021-02-01 00:27:23</td>\n",
       "      <td>2021-02-01 00:44:01</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>3.150</td>\n",
       "      <td>...</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.01</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>B02510</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-02-01 00:12:55</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-02-01 00:28:38</td>\n",
       "      <td>2021-02-01 00:38:27</td>\n",
       "      <td>39</td>\n",
       "      <td>91</td>\n",
       "      <td>1.776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.91</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>B02510</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-02-01 00:36:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-02-01 00:43:37</td>\n",
       "      <td>2021-02-01 01:23:20</td>\n",
       "      <td>91</td>\n",
       "      <td>228</td>\n",
       "      <td>13.599</td>\n",
       "      <td>...</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.05</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02872</td>\n",
       "      <td>B02872</td>\n",
       "      <td>2021-01-31 23:57:50</td>\n",
       "      <td>2021-02-01 00:08:25</td>\n",
       "      <td>2021-02-01 00:08:42</td>\n",
       "      <td>2021-02-01 00:17:57</td>\n",
       "      <td>126</td>\n",
       "      <td>250</td>\n",
       "      <td>2.620</td>\n",
       "      <td>...</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.53</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02872</td>\n",
       "      <td>B02872</td>\n",
       "      <td>2021-02-01 00:11:48</td>\n",
       "      <td>2021-02-01 00:24:25</td>\n",
       "      <td>2021-02-01 00:26:02</td>\n",
       "      <td>2021-02-01 00:42:51</td>\n",
       "      <td>208</td>\n",
       "      <td>243</td>\n",
       "      <td>6.890</td>\n",
       "      <td>...</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.05</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02872</td>\n",
       "      <td>B02872</td>\n",
       "      <td>2021-02-01 00:39:45</td>\n",
       "      <td>2021-02-01 00:44:57</td>\n",
       "      <td>2021-02-01 00:45:50</td>\n",
       "      <td>2021-02-01 01:02:50</td>\n",
       "      <td>243</td>\n",
       "      <td>220</td>\n",
       "      <td>4.260</td>\n",
       "      <td>...</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.42</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02764</td>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-01-31 23:55:59</td>\n",
       "      <td>2021-02-01 00:04:42</td>\n",
       "      <td>2021-02-01 00:06:42</td>\n",
       "      <td>2021-02-01 00:31:50</td>\n",
       "      <td>49</td>\n",
       "      <td>37</td>\n",
       "      <td>2.950</td>\n",
       "      <td>...</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.29</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02764</td>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-02-01 00:27:54</td>\n",
       "      <td>2021-02-01 00:33:12</td>\n",
       "      <td>2021-02-01 00:34:34</td>\n",
       "      <td>2021-02-01 00:58:13</td>\n",
       "      <td>37</td>\n",
       "      <td>76</td>\n",
       "      <td>3.410</td>\n",
       "      <td>...</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.77</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>B02510</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-01-31 23:56:04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-02-01 00:03:43</td>\n",
       "      <td>2021-02-01 00:39:37</td>\n",
       "      <td>80</td>\n",
       "      <td>241</td>\n",
       "      <td>15.998</td>\n",
       "      <td>...</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.80</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
       "0            HV0003               B02764               B02764   \n",
       "1            HV0003               B02764               B02764   \n",
       "2            HV0005               B02510                 None   \n",
       "3            HV0005               B02510                 None   \n",
       "4            HV0003               B02872               B02872   \n",
       "5            HV0003               B02872               B02872   \n",
       "6            HV0003               B02872               B02872   \n",
       "7            HV0003               B02764               B02764   \n",
       "8            HV0003               B02764               B02764   \n",
       "9            HV0005               B02510                 None   \n",
       "\n",
       "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0 2021-01-31 23:59:00 2021-02-01 00:10:19 2021-02-01 00:10:40   \n",
       "1 2021-02-01 00:13:35 2021-02-01 00:25:23 2021-02-01 00:27:23   \n",
       "2 2021-02-01 00:12:55                 NaT 2021-02-01 00:28:38   \n",
       "3 2021-02-01 00:36:01                 NaT 2021-02-01 00:43:37   \n",
       "4 2021-01-31 23:57:50 2021-02-01 00:08:25 2021-02-01 00:08:42   \n",
       "5 2021-02-01 00:11:48 2021-02-01 00:24:25 2021-02-01 00:26:02   \n",
       "6 2021-02-01 00:39:45 2021-02-01 00:44:57 2021-02-01 00:45:50   \n",
       "7 2021-01-31 23:55:59 2021-02-01 00:04:42 2021-02-01 00:06:42   \n",
       "8 2021-02-01 00:27:54 2021-02-01 00:33:12 2021-02-01 00:34:34   \n",
       "9 2021-01-31 23:56:04                 NaT 2021-02-01 00:03:43   \n",
       "\n",
       "     dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  sales_tax  \\\n",
       "0 2021-02-01 00:21:09            35            39       2.060  ...       1.52   \n",
       "1 2021-02-01 00:44:01            39            35       3.150  ...       2.85   \n",
       "2 2021-02-01 00:38:27            39            91       1.776  ...       1.12   \n",
       "3 2021-02-01 01:23:20            91           228      13.599  ...       2.91   \n",
       "4 2021-02-01 00:17:57           126           250       2.620  ...       1.38   \n",
       "5 2021-02-01 00:42:51           208           243       6.890  ...       1.77   \n",
       "6 2021-02-01 01:02:50           243           220       4.260  ...       3.76   \n",
       "7 2021-02-01 00:31:50            49            37       2.950  ...       2.40   \n",
       "8 2021-02-01 00:58:13            37            76       3.410  ...       2.03   \n",
       "9 2021-02-01 00:39:37            80           241      15.998  ...       4.44   \n",
       "\n",
       "   congestion_surcharge  airport_fee  tips  driver_pay  shared_request_flag  \\\n",
       "0                   0.0          NaN   0.0        9.79                    N   \n",
       "1                   0.0          NaN   0.0       24.01                    N   \n",
       "2                   0.0          NaN   0.0        6.91                    N   \n",
       "3                   0.0          NaN   7.0       35.05                    N   \n",
       "4                   0.0          NaN   0.0        8.53                    N   \n",
       "5                   0.0          NaN   0.0       16.05                    N   \n",
       "6                   0.0          NaN   0.0       25.42                    N   \n",
       "7                   0.0          NaN   0.0       22.29                    N   \n",
       "8                   0.0          NaN   0.0       23.77                    N   \n",
       "9                   0.0          NaN   0.0       35.80                    N   \n",
       "\n",
       "   shared_match_flag  access_a_ride_flag  wav_request_flag wav_match_flag  \n",
       "0                  N                                     N              N  \n",
       "1                  N                                     N              N  \n",
       "2                  N                   N                 N              N  \n",
       "3                  N                   N                 N              N  \n",
       "4                  N                                     N              N  \n",
       "5                  N                                     N              N  \n",
       "6                  N                                     N              N  \n",
       "7                  N                                     N              N  \n",
       "8                  N                                     N              N  \n",
       "9                  N                   N                 N              N  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhvhv_2021_02.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11613942 entries, 0 to 11613941\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Dtype         \n",
      "---  ------                -----         \n",
      " 0   hvfhs_license_num     object        \n",
      " 1   dispatching_base_num  object        \n",
      " 2   originating_base_num  object        \n",
      " 3   request_datetime      datetime64[us]\n",
      " 4   on_scene_datetime     datetime64[us]\n",
      " 5   pickup_datetime       datetime64[us]\n",
      " 6   dropoff_datetime      datetime64[us]\n",
      " 7   PULocationID          int64         \n",
      " 8   DOLocationID          int64         \n",
      " 9   trip_miles            float64       \n",
      " 10  trip_time             int64         \n",
      " 11  base_passenger_fare   float64       \n",
      " 12  tolls                 float64       \n",
      " 13  bcf                   float64       \n",
      " 14  sales_tax             float64       \n",
      " 15  congestion_surcharge  float64       \n",
      " 16  airport_fee           float64       \n",
      " 17  tips                  float64       \n",
      " 18  driver_pay            float64       \n",
      " 19  shared_request_flag   object        \n",
      " 20  shared_match_flag     object        \n",
      " 21  access_a_ride_flag    object        \n",
      " 22  wav_request_flag      object        \n",
      " 23  wav_match_flag        object        \n",
      "dtypes: datetime64[us](4), float64(9), int64(3), object(8)\n",
      "memory usage: 2.1+ GB\n"
     ]
    }
   ],
   "source": [
    "fhvhv_2021_02.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-02-01 00:01:00</td>\n",
       "      <td>2021-02-01 01:33:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00021</td>\n",
       "      <td>2021-02-01 00:55:40</td>\n",
       "      <td>2021-02-01 01:06:20</td>\n",
       "      <td>173.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00021</td>\n",
       "      <td>2021-02-01 00:14:03</td>\n",
       "      <td>2021-02-01 00:28:37</td>\n",
       "      <td>173.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00021</td>\n",
       "      <td>2021-02-01 00:27:48</td>\n",
       "      <td>2021-02-01 00:35:45</td>\n",
       "      <td>82.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-02-01 00:12:50</td>\n",
       "      <td>2021-02-01 00:26:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-02-01 00:00:37</td>\n",
       "      <td>2021-02-01 00:09:35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B00112</td>\n",
       "      <td>2021-02-01 00:30:25</td>\n",
       "      <td>2021-02-01 00:57:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B00149</td>\n",
       "      <td>2021-02-01 00:43:16</td>\n",
       "      <td>2021-02-01 01:03:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B00221</td>\n",
       "      <td>2021-02-01 00:20:45</td>\n",
       "      <td>2021-02-01 00:21:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>244.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B00225</td>\n",
       "      <td>2021-02-01 00:23:27</td>\n",
       "      <td>2021-02-01 00:55:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID  \\\n",
       "0               B00013 2021-02-01 00:01:00 2021-02-01 01:33:00           NaN   \n",
       "1      B00021          2021-02-01 00:55:40 2021-02-01 01:06:20         173.0   \n",
       "2      B00021          2021-02-01 00:14:03 2021-02-01 00:28:37         173.0   \n",
       "3      B00021          2021-02-01 00:27:48 2021-02-01 00:35:45          82.0   \n",
       "4               B00037 2021-02-01 00:12:50 2021-02-01 00:26:38           NaN   \n",
       "5               B00037 2021-02-01 00:00:37 2021-02-01 00:09:35           NaN   \n",
       "6               B00112 2021-02-01 00:30:25 2021-02-01 00:57:23           NaN   \n",
       "7               B00149 2021-02-01 00:43:16 2021-02-01 01:03:16           NaN   \n",
       "8               B00221 2021-02-01 00:20:45 2021-02-01 00:21:15           NaN   \n",
       "9               B00225 2021-02-01 00:23:27 2021-02-01 00:55:46           NaN   \n",
       "\n",
       "   DOlocationID SR_Flag Affiliated_base_number  \n",
       "0           NaN    None                 B00014  \n",
       "1          82.0    None        B00021           \n",
       "2          56.0    None        B00021           \n",
       "3         129.0    None        B00021           \n",
       "4         225.0    None                 B00037  \n",
       "5          61.0    None                 B00037  \n",
       "6          26.0    None                 B00112  \n",
       "7          72.0    None                 B00149  \n",
       "8         244.0    None                 B00221  \n",
       "9         169.0    None                 B00225  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhv_2021_02.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1037692 entries, 0 to 1037691\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count    Dtype         \n",
      "---  ------                  --------------    -----         \n",
      " 0   dispatching_base_num    1037692 non-null  object        \n",
      " 1   pickup_datetime         1037692 non-null  datetime64[us]\n",
      " 2   dropOff_datetime        1037692 non-null  datetime64[us]\n",
      " 3   PUlocationID            153001 non-null   float64       \n",
      " 4   DOlocationID            885340 non-null   float64       \n",
      " 5   SR_Flag                 0 non-null        object        \n",
      " 6   Affiliated_base_number  1037692 non-null  object        \n",
      "dtypes: datetime64[us](2), float64(2), object(3)\n",
      "memory usage: 55.4+ MB\n"
     ]
    }
   ],
   "source": [
    "fhv_2021_02.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for renaming the columns of the 4 collections of datasets to standard names, which will ease the cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renaming_fhv_to_standard(df_list):\n",
    "    for df in df_list:\n",
    "        for columns in df:\n",
    "            df = df.rename(columns={'dropOff_datetime': 'dropoff_datetime', 'PULocationID': 'pickup_zone', 'DOLocationID': 'dropoff_zone'})\n",
    "        df.drop(columns=[\"ehail_fee\", \"trip_type\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data (Columns) Kept:\n",
    "\n",
    "- https://www.nyc.gov/assets/tlc/images/content/pages/about/taxi_zone_map_manhattan.jpg\n",
    "\n",
    "- Yellow = pickup_datetime, dropoff_datetime, passenger_count, pickup_zone and dropoff_zone\n",
    "- https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf \n",
    "\n",
    "- Green = pickup_datetime, dropoff_datetime, passenger_count, pickup_zone, dropoff_zone\n",
    "- https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_green.pdf \n",
    "\n",
    "- FHV = pickup_datetime, dropoff_datetime, pickup_zone, dropoff_zone, passenger_count (added)\n",
    "- https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_fhv.pdf \n",
    "\n",
    "- fhvhv = pickup_datetime, dropoff_datetime, pickup_zone, dropoff_zone, passenger_count (added)\n",
    "- https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_hvfhs.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_fhv_columns(df):\n",
    "        df.drop(columns=[\"Dispatching_base_num\", \"SR_Flag\"], inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_fhvhv_columns(df):\n",
    "    df.drop(columns=[\"Hvfhs_license_num\", \"Dispatching_base_num\", \"originating_base_num\", \"request_datetime\", \"on_scene_datetime\", \"trip_miles\", \"trip_time\", \"base_passenger_fare\", \"tolls\", \"bcf\", \"sales_tax\", \"congestion_surcharge\", \"airport_fee\", \"tips\", \"driver_pay\", \"shared_request_flag\", \"shared_match_flag\", \"access_a_ride_flag\", \"wav_request_flag\", \"wav_match_flag\"], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parquet_files(file_list):\n",
    "    \"\"\"\n",
    "    Load a list of parquet files into pandas DataFrames.\n",
    "    \n",
    "    Parameters:\n",
    "    file_list (list of str): List of file paths to be loaded.\n",
    "    \n",
    "    Returns:\n",
    "    List of pandas DataFrames loaded from the parquet files.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "    for file in file_list:\n",
    "        df = pd.read_parquet(file, engine='pyarrow')\n",
    "        dataframes.append(df)\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_categories = {\n",
    "    \"fhv\": [],\n",
    "    \"fhvhv\": [],\n",
    "    \"green\": [],\n",
    "    \"yellow\": []\n",
    "}\n",
    "for file in all_files:\n",
    "    if \"fhv_\" in file:\n",
    "        file_categories[\"fhv\"].append(file)\n",
    "    elif \"fhvhv_\" in file:\n",
    "        file_categories[\"fhvhv\"].append(file)\n",
    "    elif \"green_\" in file:\n",
    "        file_categories[\"green\"].append(file)\n",
    "    elif \"yellow_\" in file:\n",
    "        file_categories[\"yellow\"].append(file)\n",
    "\n",
    "# Print the sorted file lists\n",
    "print(\"FHV Files:\", file_categories[\"fhv\"])\n",
    "print(\"FHVHV Files:\", file_categories[\"fhvhv\"])\n",
    "print(\"Green Files:\", file_categories[\"green\"])\n",
    "print(\"Yellow Files:\", file_categories[\"yellow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhv_dfs = load_parquet_files(file_categories[\"fhv\"])\n",
    "fhvhv_dfs = load_parquet_files(file_categories[\"fhvhv\"])\n",
    "green_dfs = load_parquet_files(file_categories[\"green\"])\n",
    "yellow_dfs = load_parquet_files(file_categories[\"yellow\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of DataFrames loaded for each category\n",
    "print(f\"FHV DataFrames Loaded: {len(fhv_dfs)}\")\n",
    "print(f\"FHVHV DataFrames Loaded: {len(fhvhv_dfs)}\")\n",
    "print(f\"Green DataFrames Loaded: {len(green_dfs)}\")\n",
    "print(f\"Yellow DataFrames Loaded: {len(yellow_dfs)}\")\n",
    "\n",
    "# Print the first few rows of the first dataframe in each list as a sanity check\n",
    "if fhv_dfs:\n",
    "    print(\"FHV DataFrame Sample:\", fhv_dfs[0].head())\n",
    "if fhvhv_dfs:\n",
    "    print(\"FHVHV DataFrame Sample:\", fhvhv_dfs[0].head())\n",
    "if green_dfs:\n",
    "    print(\"Green DataFrame Sample:\", green_dfs[0].head())\n",
    "if yellow_dfs:\n",
    "    print(\"Yellow DataFrame Sample:\", yellow_dfs[0].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp47350py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
